{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfa8 Freepik AI Orchestrator","text":"<p>Welcome to the Freepik AI Orchestrator documentation! This is a professional AI-powered image generation platform with LLM optimization for the Freepik API, built with Streamlit for a beautiful, interactive user experience.</p>"},{"location":"#what-is-freepik-ai-orchestrator","title":"What is Freepik AI Orchestrator?","text":"<p>The Freepik AI Orchestrator is a comprehensive platform that bridges the gap between user creativity and AI-powered image generation. It leverages Large Language Models (LLMs) to optimize prompts and orchestrates multiple AI models to deliver exceptional image generation results.</p>"},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li> <p> LLM-Powered Prompt Engineering</p> <p>Automatically optimizes prompts for better results using advanced language models</p> </li> <li> <p> Multi-Model Support</p> <p>Supports Mystic, Imagen3, Flux Dev, and Classic Fast models</p> </li> <li> <p> Post-Processing Pipelines</p> <p>Upscaling, relighting, style transfer, and background removal</p> </li> <li> <p> Real-time Analytics</p> <p>Track usage, success rates, and costs with comprehensive dashboards</p> </li> <li> <p> Professional UI</p> <p>Clean Streamlit interface with custom styling and intuitive controls</p> </li> <li> <p> Async Processing</p> <p>Webhook-based result handling for efficient processing</p> </li> <li> <p> Production Ready</p> <p>Docker support, environment management, and scalable architecture</p> </li> <li> <p> Business Intelligence</p> <p>Comprehensive analytics and reporting for business insights</p> </li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<p>Getting Started</p> <p>New to Freepik AI Orchestrator? Start with our Installation Guide and Quick Start tutorial.</p> <p>For Developers</p> <p>Check out our API Reference and Architecture Guide for technical details.</p> <p>For Business Users</p> <p>Learn about our Business Model and Pricing Structure.</p>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    A[User Interface] --&gt; B[LLM Orchestrator]\n    B --&gt; C[Prompt Optimizer]\n    B --&gt; D[Freepik Client]\n    D --&gt; E[Freepik API]\n    E --&gt; F[Image Models]\n    F --&gt; G[Post-Processing]\n    G --&gt; H[Result Storage]\n    H --&gt; I[Analytics Engine]\n\n    subgraph \"AI Models\"\n        F1[Mystic]\n        F2[Imagen3]\n        F3[Flux Dev]\n        F4[Classic Fast]\n    end\n\n    F --&gt; F1\n    F --&gt; F2\n    F --&gt; F3\n    F --&gt; F4\n</code></pre>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>Documentation: You're reading it! \ud83d\udcda</li> <li>Issues: Report bugs and request features on GitHub Issues</li> <li>Discussions: Join the conversation on GitHub Discussions</li> <li>Contributing: Read our Contributing Guide</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License. See the LICENSE file for details.</p> <p>Ready to get started? Head over to the Installation Guide to begin your journey with Freepik AI Orchestrator!</p>"},{"location":"API/","title":"API Reference","text":"<p>Complete API documentation for the Freepik AI Orchestrator platform.</p>"},{"location":"API/#overview","title":"Overview","text":"<p>The Freepik AI Orchestrator API provides programmatic access to our AI-powered image generation platform. The API supports synchronous and asynchronous image generation, workflow execution, and comprehensive management features.</p>"},{"location":"API/#key-features","title":"Key Features","text":"<ul> <li>REST API: Standard HTTP methods and JSON responses</li> <li>Authentication: Secure API key-based authentication</li> <li>Rate Limiting: Built-in rate limiting with clear headers</li> <li>Webhooks: Real-time notifications for async operations</li> <li>Error Handling: Detailed error messages and codes</li> <li>Pagination: Efficient handling of large datasets</li> </ul>"},{"location":"API/#getting-started","title":"Getting Started","text":""},{"location":"API/#base-url","title":"Base URL","text":"<p>All API requests should be made to:</p> <pre><code>https://api.freepik-orchestrator.com/v1\n</code></pre>"},{"location":"API/#authentication","title":"Authentication","text":"<p>Include your API key in the Authorization header:</p> <pre><code>Authorization: Bearer YOUR_API_KEY\n</code></pre>"},{"location":"API/#rate-limits","title":"Rate Limits","text":"<p>API requests are rate limited by plan:</p> Plan Requests/Minute Requests/Hour Free 10 100 Professional 60 1,000 Enterprise 300 10,000 <p>Rate limit headers are included in responses:</p> <pre><code>X-RateLimit-Limit: 60\nX-RateLimit-Remaining: 45\nX-RateLimit-Reset: 1640995200\n</code></pre>"},{"location":"API/#core-endpoints","title":"Core Endpoints","text":""},{"location":"API/#image-generation","title":"Image Generation","text":""},{"location":"API/#generate-image","title":"Generate Image","text":"<p>Create a new image using AI models with LLM optimization.</p> <p>Endpoint: <code>POST /generate</code></p> <p>Parameters:</p> Parameter Type Required Description <code>prompt</code> string Yes Image description <code>model</code> string No AI model (auto, mystic, imagen3, flux_dev, classic_fast) <code>style</code> string No Style preset (photorealistic, artistic, cartoon) <code>aspect_ratio</code> string No Image dimensions (1:1, 16:9, 9:16, 4:3, 3:4) <code>quality_level</code> integer No Quality setting (1-10, default: 8) <code>webhook_url</code> string No Webhook URL for async notifications <code>enhance_prompt</code> boolean No Enable LLM prompt optimization (default: true) <p>Request Example:</p> <pre><code>curl -X POST \"https://api.freepik-orchestrator.com/v1/generate\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"prompt\": \"Professional headshot of a businesswoman in modern office\",\n    \"model\": \"imagen3\",\n    \"style\": \"photorealistic\",\n    \"aspect_ratio\": \"1:1\",\n    \"quality_level\": 9,\n    \"webhook_url\": \"https://your-app.com/webhook\"\n  }'\n</code></pre> <p>Response:</p> <pre><code>{\n  \"task_id\": \"task_12345\",\n  \"model_used\": \"imagen3\", \n  \"status\": \"pending\",\n  \"original_prompt\": \"Professional headshot of a businesswoman in modern office\",\n  \"enhanced_prompt\": \"Professional business headshot of a confident businesswoman...\",\n  \"estimated_completion_time\": 45,\n  \"webhook_callback\": true,\n  \"created_at\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre> <p>For complete API documentation with all endpoints, error handling, and examples, please refer to the full API reference documentation.       \"status\": \"completed\",       \"result_url\": \"https://cdn.freepik.com/step1.jpg\"     },     {       \"step\": 2,       \"action\": \"relight\",       \"status\": \"running\"     }   ] } <pre><code>#### List Available Workflows\nGet a list of available workflow templates.\n\n**Endpoint:** `GET /workflows`\n\n**Response:**\n```json\n{\n  \"workflows\": [\n    {\n      \"id\": \"professional_headshot\",\n      \"name\": \"Professional Headshot\",\n      \"description\": \"High-quality professional headshots with optimal lighting\",\n      \"estimated_time\": \"3-4 minutes\",\n      \"estimated_cost\": \"$1.20\",\n      \"steps_count\": 4\n    }\n  ]\n}\n</code></pre></p>"},{"location":"API/#post-processing","title":"Post-Processing","text":""},{"location":"API/#upscale-image","title":"Upscale Image","text":"<p>Upscale an existing image.</p> <p>Endpoint: <code>POST /post-process/upscale</code></p> <p>Request Body: <pre><code>{\n  \"image_url\": \"https://cdn.freepik.com/original.jpg\",\n  \"scale_factor\": 4,\n  \"webhook_url\": \"https://your-domain.com/webhook\"\n}\n</code></pre></p>"},{"location":"API/#relight-image","title":"Relight Image","text":"<p>Apply professional lighting to an image.</p> <p>Endpoint: <code>POST /post-process/relight</code></p> <p>Request Body: <pre><code>{\n  \"image_url\": \"https://cdn.freepik.com/original.jpg\",\n  \"lighting_style\": \"professional\",\n  \"webhook_url\": \"https://your-domain.com/webhook\"\n}\n</code></pre></p>"},{"location":"API/#remove-background","title":"Remove Background","text":"<p>Remove background from an image.</p> <p>Endpoint: <code>POST /post-process/remove-background</code></p> <p>Request Body: <pre><code>{\n  \"image_url\": \"https://cdn.freepik.com/original.jpg\"\n}\n</code></pre></p> <p>Response (Synchronous): <pre><code>{\n  \"result_url\": \"https://cdn.freepik.com/no-bg.png\",\n  \"processing_time\": 5\n}\n</code></pre></p>"},{"location":"API/#analytics","title":"Analytics","text":""},{"location":"API/#user-analytics","title":"User Analytics","text":"<p>Get analytics for the authenticated user.</p> <p>Endpoint: <code>GET /analytics/user?days=30</code></p> <p>Response: <pre><code>{\n  \"period_days\": 30,\n  \"total_generations\": 156,\n  \"successful_generations\": 148,\n  \"failed_generations\": 8,\n  \"success_rate\": 94.9,\n  \"total_cost_cents\": 4680,\n  \"average_processing_time\": 42,\n  \"models_used\": {\n    \"mystic\": 70,\n    \"imagen3\": 56,\n    \"flux-dev\": 20,\n    \"classic-fast\": 10\n  },\n  \"daily_stats\": [\n    {\n      \"date\": \"2024-01-15\",\n      \"generations\": 12,\n      \"cost_cents\": 360\n    }\n  ]\n}\n</code></pre></p>"},{"location":"API/#webhooks","title":"Webhooks","text":"<p>Webhooks are used to notify your application when asynchronous operations complete.</p>"},{"location":"API/#webhook-payload","title":"Webhook Payload","text":"<pre><code>{\n  \"event\": \"generation.completed\",\n  \"task_id\": \"task_12345\",\n  \"timestamp\": \"2024-01-15T10:30:45Z\",\n  \"data\": {\n    \"status\": \"completed\",\n    \"image_url\": \"https://cdn.freepik.com/result.jpg\",\n    \"thumbnail_url\": \"https://cdn.freepik.com/thumb.jpg\",\n    \"model_used\": \"imagen3\",\n    \"processing_time\": 45\n  }\n}\n</code></pre>"},{"location":"API/#webhook-security","title":"Webhook Security","text":"<p>Webhooks are signed using HMAC-SHA256. Verify the signature using the <code>X-Freepik-Signature</code> header:</p> <pre><code>import hmac\nimport hashlib\n\ndef verify_webhook(payload, signature, secret):\n    expected = hmac.new(\n        secret.encode(),\n        payload,\n        hashlib.sha256\n    ).hexdigest()\n    return hmac.compare_digest(f\"sha256={expected}\", signature)\n</code></pre>"},{"location":"API/#error-handling","title":"Error Handling","text":""},{"location":"API/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"INVALID_MODEL\",\n    \"message\": \"The specified model 'invalid-model' is not supported\",\n    \"details\": {\n      \"supported_models\": [\"mystic\", \"imagen3\", \"flux-dev\", \"classic-fast\"]\n    }\n  }\n}\n</code></pre>"},{"location":"API/#error-codes","title":"Error Codes","text":"<ul> <li><code>INVALID_API_KEY</code> - API key is missing or invalid</li> <li><code>INSUFFICIENT_CREDITS</code> - Account has insufficient credits</li> <li><code>INVALID_MODEL</code> - Specified model is not supported</li> <li><code>PROMPT_TOO_LONG</code> - Prompt exceeds maximum length</li> <li><code>RATE_LIMIT_EXCEEDED</code> - Too many requests</li> <li><code>WEBHOOK_URL_INVALID</code> - Webhook URL is not accessible</li> <li><code>TASK_NOT_FOUND</code> - Task ID does not exist</li> <li><code>WORKFLOW_NOT_FOUND</code> - Workflow ID does not exist</li> </ul>"},{"location":"API/#rate-limits_1","title":"Rate Limits","text":"<ul> <li>Free Tier: 10 requests per day</li> <li>Professional: 1000 requests per hour</li> <li>Enterprise: 10000 requests per hour</li> </ul> <p>Rate limit headers are included in responses: - <code>X-RateLimit-Limit</code>: Request limit per time window - <code>X-RateLimit-Remaining</code>: Requests remaining in current window - <code>X-RateLimit-Reset</code>: Time when rate limit resets (Unix timestamp)</p>"},{"location":"API/#sdks","title":"SDKs","text":""},{"location":"API/#python-sdk","title":"Python SDK","text":"<pre><code>from freepik_orchestrator import FreepikClient\n\nclient = FreepikClient(api_key=\"your-api-key\")\n\n# Generate image\nresult = await client.generate(\n    prompt=\"Professional headshot\",\n    model=\"auto\"\n)\n\n# Execute workflow\nworkflow_result = await client.execute_workflow(\n    \"professional_headshot\",\n    prompt=\"Business portrait\"\n)\n</code></pre>"},{"location":"API/#javascript-sdk","title":"JavaScript SDK","text":"<pre><code>import { FreepikClient } from '@freepik/orchestrator-js';\n\nconst client = new FreepikClient('your-api-key');\n\n// Generate image\nconst result = await client.generate({\n  prompt: 'Professional headshot',\n  model: 'auto'\n});\n\n// Execute workflow\nconst workflowResult = await client.executeWorkflow(\n  'professional_headshot',\n  { prompt: 'Business portrait' }\n);\n</code></pre>"},{"location":"DEPLOYMENT/","title":"Deployment Guide","text":"<p>Complete deployment guide for the Freepik AI Orchestrator across different environments and platforms.</p>"},{"location":"DEPLOYMENT/#overview","title":"Overview","text":"<p>This guide covers deployment strategies from local development to production-grade deployments on cloud platforms. Choose the deployment method that best fits your infrastructure and requirements.</p>"},{"location":"DEPLOYMENT/#prerequisites","title":"Prerequisites","text":"<p>Before deploying, ensure you have:</p> <ul> <li>Docker &amp; Docker Compose: For containerized deployments</li> <li>Domain &amp; SSL Certificate: For production HTTPS access</li> <li>API Keys: Freepik API key and LLM provider credentials</li> <li>Database: PostgreSQL for production (SQLite for development)</li> <li>Cloud Account: AWS, GCP, or Azure for cloud deployments</li> </ul>"},{"location":"DEPLOYMENT/#quick-deployment","title":"Quick Deployment","text":""},{"location":"DEPLOYMENT/#local-development","title":"Local Development","text":"<p>For local development and testing:</p> <pre><code># Clone repository\ngit clone https://github.com/yourusername/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\n\n# Setup environment\ncp .env.example .env\n# Edit .env with your API keys\n\n# Run with Docker Compose\ndocker-compose up --build\n</code></pre> <p>Access the application at <code>http://localhost:8501</code></p>"},{"location":"DEPLOYMENT/#production-quick-start","title":"Production Quick Start","text":"<p>For production deployment:</p> <pre><code># Clone and configure\ngit clone https://github.com/yourusername/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\ncp .env.example .env.production\n\n# Configure production environment\nvim .env.production\n\n# Deploy with production compose\ndocker-compose -f docker-compose.prod.yml up -d\n</code></pre>"},{"location":"DEPLOYMENT/#environment-configuration","title":"Environment Configuration","text":""},{"location":"DEPLOYMENT/#development-environment","title":"Development Environment","text":"<p>Create <code>.env</code> file for development:</p> <pre><code># Application\nAPP_ENV=development\nDEBUG=true\nLOG_LEVEL=DEBUG\n\n# API Keys\nFREEPIK_API_KEY=your_freepik_dev_key\nOPENAI_API_KEY=your_openai_dev_key\n\n# Database\nDATABASE_URL=sqlite:///dev.db\n\n# Streamlit\nSTREAMLIT_SERVER_PORT=8501\nSTREAMLIT_SERVER_ADDRESS=localhost\n</code></pre>"},{"location":"DEPLOYMENT/#production-environment","title":"Production Environment","text":"<p>Create <code>.env.production</code> file:</p> <pre><code># Application\nAPP_ENV=production\nDEBUG=false\nLOG_LEVEL=INFO\nSECRET_KEY=your-super-secret-production-key\n\n# API Keys\nFREEPIK_API_KEY=your_freepik_production_key\nOPENAI_API_KEY=your_openai_production_key\n\n# Database\nDATABASE_URL=postgresql://user:password@db.example.com:5432/freepik_orchestrator\nDB_POOL_SIZE=20\nDB_MAX_OVERFLOW=30\n\n# Redis Cache\nREDIS_URL=redis://redis.example.com:6379/0\nCACHE_DEFAULT_TIMEOUT=3600\n\n# Webhook\nWEBHOOK_URL=https://your-domain.com/webhook\nWEBHOOK_SECRET=your_webhook_secret\n\n# Monitoring\nSENTRY_DSN=https://your-sentry-dsn\nPROMETHEUS_ENABLED=true\n\n# Security\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_PER_MINUTE=60\nENABLE_CORS=false\n</code></pre>"},{"location":"DEPLOYMENT/#docker-deployment","title":"Docker Deployment","text":""},{"location":"DEPLOYMENT/#development-docker-compose","title":"Development Docker Compose","text":"<p>The default <code>docker-compose.yml</code> for development:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    build: .\n    ports:\n      - \"8501:8501\"\n    environment:\n      - APP_ENV=development\n    env_file:\n      - .env\n    volumes:\n      - .:/app\n      - ./data:/app/data\n    depends_on:\n      - db\n\n  db:\n    image: postgres:14\n    environment:\n      POSTGRES_DB: freepik_orchestrator\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n\nvolumes:\n  postgres_data:\n</code></pre>"},{"location":"DEPLOYMENT/#production-docker-compose","title":"Production Docker Compose","text":"<p>Create <code>docker-compose.prod.yml</code> for production:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile.prod\n    restart: unless-stopped\n    environment:\n      - APP_ENV=production\n    env_file:\n      - .env.production\n    depends_on:\n      - db\n      - redis\n    networks:\n      - app-network\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.freepik-orchestrator.rule=Host(`your-domain.com`)\"\n      - \"traefik.http.routers.freepik-orchestrator.tls.certresolver=letsencrypt\"\n\n  db:\n    image: postgres:14\n    restart: unless-stopped\n    environment:\n      POSTGRES_DB: freepik_orchestrator\n      POSTGRES_USER: ${DB_USER}\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./database/migrations:/docker-entrypoint-initdb.d\n    networks:\n      - app-network\n\n  redis:\n    image: redis:7-alpine\n    restart: unless-stopped\n    volumes:\n      - redis_data:/data\n    networks:\n      - app-network\n\n  traefik:\n    image: traefik:v3.0\n    restart: unless-stopped\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./traefik.yml:/etc/traefik/traefik.yml\n      - traefik_certs:/certs\n    networks:\n      - app-network\n\n  prometheus:\n    image: prom/prometheus\n    restart: unless-stopped\n    volumes:\n      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml\n      - prometheus_data:/prometheus\n    networks:\n      - app-network\n\n  grafana:\n    image: grafana/grafana\n    restart: unless-stopped\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}\n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ./monitoring/grafana:/etc/grafana/provisioning\n    networks:\n      - app-network\n\nvolumes:\n  postgres_data:\n  redis_data:\n  traefik_certs:\n  prometheus_data:\n  grafana_data:\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"DEPLOYMENT/#production-dockerfile","title":"Production Dockerfile","text":"<p>Create <code>Dockerfile.prod</code>:</p> <pre><code>FROM python:3.11-slim\n\n# Set working directory\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements and install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Create non-root user\nRUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8501/health || exit 1\n\n# Expose port\nEXPOSE 8501\n\n# Run application\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n</code></pre>"},{"location":"DEPLOYMENT/#cloud-platform-deployments","title":"Cloud Platform Deployments","text":""},{"location":"DEPLOYMENT/#aws-deployment","title":"AWS Deployment","text":""},{"location":"DEPLOYMENT/#aws-ecs-with-fargate","title":"AWS ECS with Fargate","text":"<ol> <li>Create ECS Cluster</li> </ol> <pre><code>aws ecs create-cluster --cluster-name freepik-orchestrator\n</code></pre> <ol> <li>Create Task Definition</li> </ol> <pre><code>{\n  \"family\": \"freepik-orchestrator\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"1024\",\n  \"memory\": \"2048\",\n  \"executionRoleArn\": \"arn:aws:iam::account:role/ecsTaskExecutionRole\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"app\",\n      \"image\": \"your-registry/freepik-orchestrator:latest\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 8501,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"environment\": [\n        {\n          \"name\": \"APP_ENV\",\n          \"value\": \"production\"\n        }\n      ],\n      \"secrets\": [\n        {\n          \"name\": \"FREEPIK_API_KEY\",\n          \"valueFrom\": \"arn:aws:secretsmanager:region:account:secret:freepik-api-key\"\n        }\n      ],\n      \"logConfiguration\": {\n        \"logDriver\": \"awslogs\",\n        \"options\": {\n          \"awslogs-group\": \"/ecs/freepik-orchestrator\",\n          \"awslogs-region\": \"us-east-1\",\n          \"awslogs-stream-prefix\": \"ecs\"\n        }\n      }\n    }\n  ]\n}\n</code></pre> <ol> <li>Create Service</li> </ol> <pre><code>aws ecs create-service \\\n  --cluster freepik-orchestrator \\\n  --service-name freepik-orchestrator-service \\\n  --task-definition freepik-orchestrator \\\n  --desired-count 2 \\\n  --launch-type FARGATE \\\n  --network-configuration \"awsvpcConfiguration={subnets=[subnet-12345],securityGroups=[sg-12345],assignPublicIp=ENABLED}\"\n</code></pre>"},{"location":"DEPLOYMENT/#aws-lambda-api-gateway","title":"AWS Lambda + API Gateway","text":"<p>For serverless deployment:</p> <pre><code># lambda_handler.py\nimport json\nfrom core.llm_orchestrator import LLMOrchestrator\nfrom core.freepik_client import FreepikClient\n\ndef lambda_handler(event, context):\n    try:\n        body = json.loads(event['body'])\n        prompt = body.get('prompt')\n\n        orchestrator = LLMOrchestrator()\n        client = FreepikClient()\n\n        enhanced_prompt = orchestrator.enhance_prompt(prompt)\n        result = client.generate_image(enhanced_prompt)\n\n        return {\n            'statusCode': 200,\n            'body': json.dumps(result)\n        }\n    except Exception as e:\n        return {\n            'statusCode': 500,\n            'body': json.dumps({'error': str(e)})\n        }\n</code></pre>"},{"location":"DEPLOYMENT/#google-cloud-platform","title":"Google Cloud Platform","text":""},{"location":"DEPLOYMENT/#cloud-run-deployment","title":"Cloud Run Deployment","text":"<ol> <li>Build and Push Container</li> </ol> <pre><code># Build image\ndocker build -t gcr.io/your-project/freepik-orchestrator .\n\n# Push to Container Registry\ndocker push gcr.io/your-project/freepik-orchestrator\n</code></pre> <ol> <li>Deploy to Cloud Run</li> </ol> <pre><code>gcloud run deploy freepik-orchestrator \\\n  --image gcr.io/your-project/freepik-orchestrator \\\n  --platform managed \\\n  --region us-central1 \\\n  --set-env-vars APP_ENV=production \\\n  --set-secrets FREEPIK_API_KEY=freepik-api-key:latest \\\n  --allow-unauthenticated\n</code></pre> <ol> <li>Cloud Run YAML Configuration</li> </ol> <pre><code>apiVersion: serving.knative.dev/v1\nkind: Service\nmetadata:\n  name: freepik-orchestrator\n  annotations:\n    run.googleapis.com/ingress: all\nspec:\n  template:\n    metadata:\n      annotations:\n        autoscaling.knative.dev/maxScale: \"10\"\n        run.googleapis.com/cpu-throttling: \"false\"\n    spec:\n      containerConcurrency: 80\n      timeoutSeconds: 300\n      containers:\n      - image: gcr.io/your-project/freepik-orchestrator\n        ports:\n        - containerPort: 8501\n        env:\n        - name: APP_ENV\n          value: production\n        resources:\n          limits:\n            cpu: \"2\"\n            memory: \"4Gi\"\n</code></pre>"},{"location":"DEPLOYMENT/#microsoft-azure","title":"Microsoft Azure","text":""},{"location":"DEPLOYMENT/#azure-container-instances","title":"Azure Container Instances","text":"<pre><code>az container create \\\n  --resource-group myResourceGroup \\\n  --name freepik-orchestrator \\\n  --image your-registry/freepik-orchestrator:latest \\\n  --ports 8501 \\\n  --dns-name-label freepik-orchestrator \\\n  --environment-variables APP_ENV=production \\\n  --secure-environment-variables FREEPIK_API_KEY=your-key\n</code></pre>"},{"location":"DEPLOYMENT/#azure-app-service","title":"Azure App Service","text":"<pre><code># Create App Service Plan\naz appservice plan create \\\n  --name freepik-orchestrator-plan \\\n  --resource-group myResourceGroup \\\n  --sku P1V2 \\\n  --is-linux\n\n# Create Web App\naz webapp create \\\n  --resource-group myResourceGroup \\\n  --plan freepik-orchestrator-plan \\\n  --name freepik-orchestrator \\\n  --deployment-container-image-name your-registry/freepik-orchestrator:latest\n</code></pre>"},{"location":"DEPLOYMENT/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"DEPLOYMENT/#complete-kubernetes-manifests","title":"Complete Kubernetes Manifests","text":""},{"location":"DEPLOYMENT/#namespace","title":"Namespace","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: freepik-orchestrator\n  labels:\n    name: freepik-orchestrator\n</code></pre>"},{"location":"DEPLOYMENT/#configmap","title":"ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\n  namespace: freepik-orchestrator\ndata:\n  APP_ENV: \"production\"\n  LOG_LEVEL: \"INFO\"\n  STREAMLIT_SERVER_PORT: \"8501\"\n  REDIS_URL: \"redis://redis-service:6379/0\"\n</code></pre>"},{"location":"DEPLOYMENT/#secret","title":"Secret","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\n  namespace: freepik-orchestrator\ntype: Opaque\nstringData:\n  FREEPIK_API_KEY: \"your_freepik_api_key\"\n  OPENAI_API_KEY: \"your_openai_key\"\n  SECRET_KEY: \"your-super-secret-key\"\n  DATABASE_URL: \"postgresql://user:pass@postgres-service:5432/freepik_orchestrator\"\n</code></pre>"},{"location":"DEPLOYMENT/#deployment","title":"Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: freepik-orchestrator\n  namespace: freepik-orchestrator\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: freepik-orchestrator\n  template:\n    metadata:\n      labels:\n        app: freepik-orchestrator\n    spec:\n      containers:\n      - name: app\n        image: your-registry/freepik-orchestrator:latest\n        ports:\n        - containerPort: 8501\n        envFrom:\n        - configMapRef:\n            name: app-config\n        - secretRef:\n            name: app-secrets\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8501\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8501\n          initialDelaySeconds: 5\n          periodSeconds: 5\n</code></pre>"},{"location":"DEPLOYMENT/#service","title":"Service","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: freepik-orchestrator-service\n  namespace: freepik-orchestrator\nspec:\n  selector:\n    app: freepik-orchestrator\n  ports:\n  - port: 80\n    targetPort: 8501\n  type: ClusterIP\n</code></pre>"},{"location":"DEPLOYMENT/#ingress","title":"Ingress","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: freepik-orchestrator-ingress\n  namespace: freepik-orchestrator\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"\nspec:\n  tls:\n  - hosts:\n    - your-domain.com\n    secretName: freepik-orchestrator-tls\n  rules:\n  - host: your-domain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: freepik-orchestrator-service\n            port:\n              number: 80\n</code></pre>"},{"location":"DEPLOYMENT/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"DEPLOYMENT/#prometheus-configuration","title":"Prometheus Configuration","text":"<pre><code># monitoring/prometheus.yml\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'freepik-orchestrator'\n    static_configs:\n      - targets: ['app:8501']\n    metrics_path: '/metrics'\n    scrape_interval: 30s\n\n  - job_name: 'postgres'\n    static_configs:\n      - targets: ['db:5432']\n\n  - job_name: 'redis'\n    static_configs:\n      - targets: ['redis:6379']\n</code></pre>"},{"location":"DEPLOYMENT/#grafana-dashboard","title":"Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Freepik AI Orchestrator\",\n    \"panels\": [\n      {\n        \"title\": \"Image Generations\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(freepik_generations_total[5m])\",\n            \"legendFormat\": \"Generations per second\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Success Rate\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(freepik_generations_success_total[5m]) / rate(freepik_generations_total[5m]) * 100\",\n            \"legendFormat\": \"Success Rate %\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"DEPLOYMENT/#security-considerations","title":"Security Considerations","text":""},{"location":"DEPLOYMENT/#network-security","title":"Network Security","text":"<ol> <li>Use HTTPS Only</li> <li>Configure SSL/TLS certificates</li> <li>Redirect HTTP to HTTPS</li> <li> <p>Use HSTS headers</p> </li> <li> <p>Network Isolation</p> </li> <li>Use private networks for database</li> <li>Implement security groups/firewall rules</li> <li> <p>Restrict access to management ports</p> </li> <li> <p>API Security</p> </li> <li>Rate limiting</li> <li>API key rotation</li> <li>Input validation</li> </ol>"},{"location":"DEPLOYMENT/#application-security","title":"Application Security","text":"<pre><code># Security middleware example\nfrom starlette.middleware.cors import CORSMiddleware\nfrom starlette.middleware.authentication import AuthenticationMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://your-domain.com\"],\n    allow_credentials=True,\n    allow_methods=[\"GET\", \"POST\"],\n    allow_headers=[\"*\"],\n)\n\napp.add_middleware(\n    AuthenticationMiddleware,\n    backend=APIKeyAuthenticationBackend()\n)\n</code></pre>"},{"location":"DEPLOYMENT/#secret-management","title":"Secret Management","text":""},{"location":"DEPLOYMENT/#aws-secrets-manager","title":"AWS Secrets Manager","text":"<pre><code>import boto3\n\ndef get_secret(secret_name):\n    client = boto3.client('secretsmanager')\n    response = client.get_secret_value(SecretId=secret_name)\n    return response['SecretString']\n\n# Usage\nfreepik_api_key = get_secret('freepik-api-key')\n</code></pre>"},{"location":"DEPLOYMENT/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<pre><code># Create secret from command line\nkubectl create secret generic app-secrets \\\n  --from-literal=freepik-api-key=your-key \\\n  --from-literal=openai-api-key=your-key \\\n  -n freepik-orchestrator\n</code></pre>"},{"location":"DEPLOYMENT/#scaling-and-performance","title":"Scaling and Performance","text":""},{"location":"DEPLOYMENT/#horizontal-scaling","title":"Horizontal Scaling","text":""},{"location":"DEPLOYMENT/#auto-scaling-configuration","title":"Auto-scaling Configuration","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: freepik-orchestrator-hpa\n  namespace: freepik-orchestrator\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: freepik-orchestrator\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"DEPLOYMENT/#database-scaling","title":"Database Scaling","text":""},{"location":"DEPLOYMENT/#postgresql-high-availability","title":"PostgreSQL High Availability","text":"<pre><code># Using PostgreSQL operator\napiVersion: postgresql.cnpg.io/v1\nkind: Cluster\nmetadata:\n  name: postgres-cluster\n  namespace: freepik-orchestrator\nspec:\n  instances: 3\n  postgresql:\n    parameters:\n      max_connections: \"200\"\n      shared_buffers: \"256MB\"\n      effective_cache_size: \"1GB\"\n\n  storage:\n    size: 100Gi\n    storageClass: fast-ssd\n\n  backup:\n    schedule: \"0 2 * * *\"\n    target: s3\n</code></pre>"},{"location":"DEPLOYMENT/#caching-strategy","title":"Caching Strategy","text":""},{"location":"DEPLOYMENT/#redis-cluster","title":"Redis Cluster","text":"<pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-cluster\n  namespace: freepik-orchestrator\nspec:\n  serviceName: redis-cluster\n  replicas: 6\n  selector:\n    matchLabels:\n      app: redis-cluster\n  template:\n    metadata:\n      labels:\n        app: redis-cluster\n    spec:\n      containers:\n      - name: redis\n        image: redis:7-alpine\n        ports:\n        - containerPort: 6379\n        command:\n        - redis-server\n        - /etc/redis/redis.conf\n        volumeMounts:\n        - name: redis-config\n          mountPath: /etc/redis\n        - name: redis-data\n          mountPath: /data\n  volumeClaimTemplates:\n  - metadata:\n      name: redis-data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 10Gi\n</code></pre>"},{"location":"DEPLOYMENT/#backup-and-disaster-recovery","title":"Backup and Disaster Recovery","text":""},{"location":"DEPLOYMENT/#database-backup","title":"Database Backup","text":"<pre><code>#!/bin/bash\n# backup.sh\n\n# Database backup\npg_dump $DATABASE_URL &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n\n# Upload to S3\naws s3 cp backup_*.sql s3://your-backup-bucket/database/\n\n# Cleanup old local backups\nfind . -name \"backup_*.sql\" -mtime +7 -delete\n</code></pre>"},{"location":"DEPLOYMENT/#application-backup","title":"Application Backup","text":"<pre><code># CronJob for automated backups\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: database-backup\n  namespace: freepik-orchestrator\nspec:\n  schedule: \"0 2 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: postgres:14\n            command:\n            - /bin/bash\n            - -c\n            - |\n              pg_dump $DATABASE_URL | gzip &gt; /backup/backup_$(date +%Y%m%d_%H%M%S).sql.gz\n              aws s3 cp /backup/ s3://your-backup-bucket/ --recursive\n            env:\n            - name: DATABASE_URL\n              valueFrom:\n                secretKeyRef:\n                  name: app-secrets\n                  key: DATABASE_URL\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"DEPLOYMENT/#maintenance-and-updates","title":"Maintenance and Updates","text":""},{"location":"DEPLOYMENT/#rolling-updates","title":"Rolling Updates","text":"<pre><code># Update image version\nkubectl set image deployment/freepik-orchestrator \\\n  app=your-registry/freepik-orchestrator:v1.2.0 \\\n  -n freepik-orchestrator\n\n# Monitor rollout\nkubectl rollout status deployment/freepik-orchestrator -n freepik-orchestrator\n\n# Rollback if needed\nkubectl rollout undo deployment/freepik-orchestrator -n freepik-orchestrator\n</code></pre>"},{"location":"DEPLOYMENT/#database-migrations","title":"Database Migrations","text":"<pre><code># migrations/migrate.py\nfrom alembic import command\nfrom alembic.config import Config\n\ndef run_migrations():\n    alembic_cfg = Config(\"alembic.ini\")\n    command.upgrade(alembic_cfg, \"head\")\n\nif __name__ == \"__main__\":\n    run_migrations()\n</code></pre>"},{"location":"DEPLOYMENT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"DEPLOYMENT/#common-issues","title":"Common Issues","text":""},{"location":"DEPLOYMENT/#application-wont-start","title":"Application Won't Start","text":"<ol> <li> <p>Check environment variables <pre><code>kubectl logs deployment/freepik-orchestrator -n freepik-orchestrator\n</code></pre></p> </li> <li> <p>Verify secrets <pre><code>kubectl get secrets -n freepik-orchestrator\nkubectl describe secret app-secrets -n freepik-orchestrator\n</code></pre></p> </li> <li> <p>Check resource limits <pre><code>kubectl describe pod -l app=freepik-orchestrator -n freepik-orchestrator\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#performance-issues","title":"Performance Issues","text":"<ol> <li> <p>Check resource usage <pre><code>kubectl top pods -n freepik-orchestrator\n</code></pre></p> </li> <li> <p>Review application metrics <pre><code>curl http://your-domain.com/metrics\n</code></pre></p> </li> <li> <p>Database performance <pre><code>-- Check slow queries\nSELECT query, mean_time, calls \nFROM pg_stat_statements \nORDER BY mean_time DESC \nLIMIT 10;\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#health-checks","title":"Health Checks","text":"<pre><code># health.py\nfrom fastapi import APIRouter\nfrom database.db import get_db_connection\nimport redis\n\nrouter = APIRouter()\n\n@router.get(\"/health\")\nasync def health_check():\n    checks = {\n        \"status\": \"healthy\",\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"version\": \"1.0.0\"\n    }\n\n    # Database check\n    try:\n        db = get_db_connection()\n        db.execute(\"SELECT 1\")\n        checks[\"database\"] = \"healthy\"\n    except Exception as e:\n        checks[\"database\"] = f\"unhealthy: {str(e)}\"\n        checks[\"status\"] = \"unhealthy\"\n\n    # Redis check\n    try:\n        r = redis.Redis.from_url(REDIS_URL)\n        r.ping()\n        checks[\"redis\"] = \"healthy\"\n    except Exception as e:\n        checks[\"redis\"] = f\"unhealthy: {str(e)}\"\n\n    return checks\n</code></pre>"},{"location":"DEPLOYMENT/#support-and-documentation","title":"Support and Documentation","text":"<p>For deployment support:</p> <ul> <li>Documentation: docs.freepik-orchestrator.com</li> <li>GitHub Issues: github.com/freepik-ai-orchestrator/issues</li> <li>Discord Community: discord.gg/freepik-ai</li> <li>Enterprise Support: support@freepik-orchestrator.com</li> </ul> <p>Ready to deploy? Start with the Quick Deployment section for your environment!</p> <p>4. Deploy Application <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: freepik-orchestrator\n  namespace: freepik-orchestrator\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: freepik-orchestrator\n  template:\n    metadata:\n      labels:\n        app: freepik-orchestrator\n    spec:\n      containers:\n      - name: app\n        image: freepik-orchestrator:latest\n        ports:\n        - containerPort: 8501\n        envFrom:\n        - configMapRef:\n            name: app-config\n        - secretRef:\n            name: app-secrets\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n</code></pre></p>"},{"location":"DEPLOYMENT/#option-3-cloud-platforms","title":"Option 3: Cloud Platforms","text":""},{"location":"DEPLOYMENT/#heroku","title":"Heroku","text":"<pre><code># Install Heroku CLI\nheroku login\nheroku create your-app-name\n\n# Set environment variables\nheroku config:set FREEPIK_API_KEY=your_key\nheroku config:set OPENAI_API_KEY=your_key\n\n# Deploy\ngit push heroku main\n</code></pre>"},{"location":"DEPLOYMENT/#aws-ecs","title":"AWS ECS","text":"<pre><code># Build and push to ECR\naws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com\ndocker build -t freepik-orchestrator .\ndocker tag freepik-orchestrator:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/freepik-orchestrator:latest\ndocker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/freepik-orchestrator:latest\n\n# Create ECS service\naws ecs create-service --cluster your-cluster --service-name freepik-orchestrator --task-definition freepik-orchestrator:1 --desired-count 2\n</code></pre>"},{"location":"DEPLOYMENT/#google-cloud-run","title":"Google Cloud Run","text":"<pre><code># Build and deploy\ngcloud builds submit --tag gcr.io/PROJECT-ID/freepik-orchestrator\ngcloud run deploy --image gcr.io/PROJECT-ID/freepik-orchestrator --platform managed\n</code></pre>"},{"location":"DEPLOYMENT/#database-setup","title":"Database Setup","text":""},{"location":"DEPLOYMENT/#postgresql-production-setup","title":"PostgreSQL Production Setup","text":"<p>1. Create Database <pre><code>CREATE DATABASE freepik_orchestrator;\nCREATE USER freepik_user WITH PASSWORD 'secure_password';\nGRANT ALL PRIVILEGES ON DATABASE freepik_orchestrator TO freepik_user;\n</code></pre></p> <p>2. Run Migrations <pre><code># Via Docker\ndocker-compose exec app python -c \"\nfrom database.db import db_manager\nimport asyncio\nasyncio.run(db_manager.initialize())\n\"\n</code></pre></p>"},{"location":"DEPLOYMENT/#redis-setup-optional","title":"Redis Setup (Optional)","text":"<p>For caching and session management:</p> <pre><code># Docker\ndocker run -d --name redis -p 6379:6379 redis:alpine\n\n# Or add to docker-compose.yml (already included)\n</code></pre>"},{"location":"DEPLOYMENT/#ssl-and-security","title":"SSL and Security","text":""},{"location":"DEPLOYMENT/#1-reverse-proxy-with-nginx","title":"1. Reverse Proxy with Nginx","text":"<p>Create <code>nginx.conf</code>: <pre><code>upstream app {\n    server 127.0.0.1:8501;\n}\n\nserver {\n    listen 80;\n    server_name yourdomain.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name yourdomain.com;\n\n    ssl_certificate /etc/ssl/certs/yourdomain.com.pem;\n    ssl_certificate_key /etc/ssl/private/yourdomain.com.key;\n\n    location / {\n        proxy_pass http://app;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    location /webhook {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre></p>"},{"location":"DEPLOYMENT/#2-firewall-configuration","title":"2. Firewall Configuration","text":"<pre><code># UFW (Ubuntu)\nsudo ufw allow 22/tcp\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\nsudo ufw enable\n\n# iptables\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\niptables -A INPUT -p tcp --dport 80 -j ACCEPT\niptables -A INPUT -p tcp --dport 443 -j ACCEPT\n</code></pre>"},{"location":"DEPLOYMENT/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"DEPLOYMENT/#1-health-checks","title":"1. Health Checks","text":"<p>The application includes health check endpoints: - <code>GET /health</code> - Basic health check - <code>GET /metrics</code> - Prometheus metrics</p>"},{"location":"DEPLOYMENT/#2-logging-configuration","title":"2. Logging Configuration","text":"<p>Configure centralized logging:</p> <pre><code># docker-compose.override.yml\nversion: '3.8'\nservices:\n  app:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre>"},{"location":"DEPLOYMENT/#3-monitoring-with-prometheus","title":"3. Monitoring with Prometheus","text":"<p>Add monitoring stack:</p> <pre><code># docker-compose.monitoring.yml\nversion: '3.8'\nservices:\n  prometheus:\n    image: prom/prometheus\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n\n  grafana:\n    image: grafana/grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n</code></pre>"},{"location":"DEPLOYMENT/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"DEPLOYMENT/#horizontal-scaling_1","title":"Horizontal Scaling","text":"<ol> <li>Stateless Design: Ensure your application is stateless</li> <li>Database Connection Pooling: Use connection pooling for PostgreSQL</li> <li>Load Balancing: Use a load balancer for multiple instances</li> </ol>"},{"location":"DEPLOYMENT/#vertical-scaling","title":"Vertical Scaling","text":"<p>Adjust resource limits based on usage:</p> <pre><code># docker-compose.yml\nservices:\n  app:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 4G\n        reservations:\n          cpus: '1.0'\n          memory: 2G\n</code></pre>"},{"location":"DEPLOYMENT/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"DEPLOYMENT/#database-backups","title":"Database Backups","text":"<pre><code># Automated daily backups\n#!/bin/bash\nBACKUP_DIR=\"/backups\"\nDATE=$(date +%Y%m%d_%H%M%S)\nPGPASSWORD=password pg_dump -h localhost -U freepik_user freepik_orchestrator &gt; $BACKUP_DIR/backup_$DATE.sql\n\n# Cleanup old backups (keep 7 days)\nfind $BACKUP_DIR -name \"backup_*.sql\" -mtime +7 -delete\n</code></pre>"},{"location":"DEPLOYMENT/#application-data","title":"Application Data","text":"<pre><code># Backup user-generated content\nrsync -av /app/uploads/ /backups/uploads/\n</code></pre>"},{"location":"DEPLOYMENT/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"DEPLOYMENT/#common-issues_1","title":"Common Issues","text":"<ol> <li> <p>Port Already in Use <pre><code>sudo lsof -i :8501\nsudo kill -9 PID\n</code></pre></p> </li> <li> <p>Database Connection Failed <pre><code># Check PostgreSQL status\nsudo systemctl status postgresql\n# Check connection\npsql -h localhost -U freepik_user -d freepik_orchestrator\n</code></pre></p> </li> <li> <p>SSL Certificate Issues <pre><code># Check certificate validity\nopenssl x509 -in /etc/ssl/certs/yourdomain.com.pem -text -noout\n</code></pre></p> </li> <li> <p>Memory Issues <pre><code># Check memory usage\nfree -h\ndocker stats\n</code></pre></p> </li> </ol>"},{"location":"DEPLOYMENT/#log-analysis","title":"Log Analysis","text":"<pre><code># Application logs\ndocker-compose logs -f app\n\n# Database logs\ndocker-compose logs -f postgres\n\n# Specific error patterns\ndocker-compose logs app | grep ERROR\n</code></pre>"},{"location":"DEPLOYMENT/#performance-optimization","title":"Performance Optimization","text":""},{"location":"DEPLOYMENT/#1-database-optimization","title":"1. Database Optimization","text":"<pre><code>-- Add indexes for common queries\nCREATE INDEX idx_tasks_user_status ON freepik_tasks(user_id, status);\nCREATE INDEX idx_tasks_created_at ON freepik_tasks(created_at);\n\n-- Analyze query performance\nEXPLAIN ANALYZE SELECT * FROM freepik_tasks WHERE user_id = 'user123';\n</code></pre>"},{"location":"DEPLOYMENT/#2-application-optimization","title":"2. Application Optimization","text":"<ul> <li>Enable Redis caching for frequent queries</li> <li>Use connection pooling for database connections</li> <li>Implement request rate limiting</li> <li>Optimize image processing pipelines</li> </ul>"},{"location":"DEPLOYMENT/#3-infrastructure-optimization","title":"3. Infrastructure Optimization","text":"<ul> <li>Use CDN for static assets</li> <li>Implement horizontal pod autoscaling (Kubernetes)</li> <li>Use read replicas for database queries</li> <li>Enable gzip compression</li> </ul>"},{"location":"DEPLOYMENT/#security-checklist","title":"Security Checklist","text":"<ul> <li> SSL/TLS certificates configured</li> <li> API keys stored securely (not in code)</li> <li> Database credentials rotated regularly</li> <li> Firewall rules configured</li> <li> Regular security updates applied</li> <li> Webhook signature verification enabled</li> <li> Rate limiting implemented</li> <li> Input validation in place</li> <li> Logging and monitoring configured</li> <li> Backup and recovery tested</li> </ul>"},{"location":"USAGE/","title":"Usage Guide","text":"<p>This comprehensive guide covers all features and capabilities of the Freepik AI Orchestrator platform.</p>"},{"location":"USAGE/#overview","title":"Overview","text":"<p>The Freepik AI Orchestrator is designed to make AI image generation accessible and powerful. Whether you're creating professional content, artistic projects, or commercial materials, this guide will help you master the platform.</p>"},{"location":"USAGE/#user-interface","title":"User Interface","text":""},{"location":"USAGE/#dashboard-layout","title":"Dashboard Layout","text":"<p>The main dashboard is organized into several key sections:</p>"},{"location":"USAGE/#navigation-sidebar","title":"Navigation Sidebar","text":"<ul> <li>Dashboard: Main generation interface</li> <li>Gallery: View all generated images</li> <li>Analytics: Usage statistics and insights</li> <li>Workflows: Pre-built automation templates</li> <li>Settings: Account and preferences</li> </ul>"},{"location":"USAGE/#main-generation-panel","title":"Main Generation Panel","text":"<ul> <li>Prompt Input: Text area for image descriptions</li> <li>Model Selection: Choose AI models</li> <li>Settings Panel: Configure generation parameters</li> <li>Generate Button: Start image creation</li> </ul>"},{"location":"USAGE/#results-area","title":"Results Area","text":"<ul> <li>Image Display: View generated images</li> <li>Metadata Panel: Generation details</li> <li>Download Options: Save in various formats</li> <li>Post-Processing: Enhancement tools</li> </ul>"},{"location":"USAGE/#key-interface-elements","title":"Key Interface Elements","text":""},{"location":"USAGE/#prompt-input-area","title":"Prompt Input Area","text":"<p>The prompt input is your primary tool for communicating with the AI:</p> <p>Features: - Auto-save drafts - Prompt history - Template library - LLM optimization toggle</p> <p>Best Practices: - Be descriptive and specific - Include technical details when needed - Specify artistic style or mood - Mention camera/photography details for realistic images</p>"},{"location":"USAGE/#model-selection","title":"Model Selection","text":"<p>Choose the right AI model for your needs:</p> <p>Auto-Selection (Recommended) - AI analyzes your prompt - Selects optimal model automatically - Balances quality, speed, and cost</p> <p>Manual Selection - Classic Fast: Quick iterations (10-15 seconds) - Flux Dev: Balanced quality and speed (30-45 seconds) - Imagen3: High-quality photorealistic (45-60 seconds) - Mystic: Artistic and creative styles (30-90 seconds)</p>"},{"location":"USAGE/#core-features","title":"Core Features","text":""},{"location":"USAGE/#llm-powered-prompt-enhancement","title":"LLM-Powered Prompt Enhancement","text":"<p>The platform automatically optimizes your prompts using advanced language models:</p>"},{"location":"USAGE/#how-it-works","title":"How It Works","text":"<ol> <li>Analysis: LLM analyzes your input prompt</li> <li>Enhancement: Adds technical and stylistic details</li> <li>Optimization: Structures for best AI model performance</li> <li>Generation: Uses enhanced prompt for image creation</li> </ol>"},{"location":"USAGE/#examples","title":"Examples","text":"<p>Basic Input: <pre><code>business headshot\n</code></pre></p> <p>LLM Enhancement: <pre><code>Professional business headshot of a person, confident expression, \nmodern office background, natural lighting, shot with Canon 5D Mark IV, \n85mm lens, sharp focus, high resolution, professional photography\n</code></pre></p> <p>Artistic Input: <pre><code>cat painting\n</code></pre></p> <p>LLM Enhancement: <pre><code>Digital art painting of a majestic cat, artistic brush strokes, \nvibrant colors, detailed fur texture, expressive eyes, \ncreative composition, high resolution illustration, digital art masterpiece\n</code></pre></p>"},{"location":"USAGE/#advanced-prompt-engineering","title":"Advanced Prompt Engineering","text":""},{"location":"USAGE/#structure-for-success","title":"Structure for Success","text":"<p>Format: Subject + Style + Technical + Mood</p> <p>Example: - Subject: \"Professional businesswoman\" - Style: \"Corporate photography style\" - Technical: \"Shot with 85mm lens, shallow depth of field\" - Mood: \"Confident and approachable expression\"</p> <p>Combined: <pre><code>Professional businesswoman, corporate photography style, \nshot with 85mm lens, shallow depth of field, \nconfident and approachable expression\n</code></pre></p>"},{"location":"USAGE/#negative-prompts","title":"Negative Prompts","text":"<p>Use negative prompts to avoid unwanted elements:</p> <pre><code>Positive: \"Beautiful landscape with mountains and lake\"\nNegative: \"no people, no buildings, no text, no watermarks\"\n</code></pre>"},{"location":"USAGE/#model-deep-dive","title":"Model Deep Dive","text":""},{"location":"USAGE/#classic-fast","title":"Classic Fast","text":"<p>Best For: Quick iterations, testing concepts, simple images Characteristics: - Fastest processing (10-15 seconds) - Good quality for basic needs - Lower computational cost - Ideal for rapid prototyping</p> <p>Use Cases: - Concept testing - Simple graphics - Social media content - Quick mockups</p>"},{"location":"USAGE/#flux-dev","title":"Flux Dev","text":"<p>Best For: Balanced quality and speed, general purpose Characteristics: - Medium processing time (30-45 seconds) - High quality results - Versatile across styles - Good cost-performance ratio</p> <p>Use Cases: - Marketing materials - Blog illustrations - Presentation graphics - General content creation</p>"},{"location":"USAGE/#imagen3","title":"Imagen3","text":"<p>Best For: Photorealistic images, professional photography Characteristics: - Excellent photorealism (45-60 seconds) - Superior detail and accuracy - Natural lighting and textures - Professional quality output</p> <p>Use Cases: - Product photography - Professional headshots - Stock photography - Commercial content</p>"},{"location":"USAGE/#mystic","title":"Mystic","text":"<p>Best For: Artistic styles, creative expression Characteristics: - Variable processing time (30-90 seconds) - Unique artistic capabilities - Creative interpretation - Premium quality artistic output</p> <p>Use Cases: - Concept art - Artistic illustrations - Creative projects - Unique visual styles</p>"},{"location":"USAGE/#workflows","title":"Workflows","text":"<p>Pre-built workflows automate complex multi-step processes for common use cases.</p>"},{"location":"USAGE/#professional-headshots-workflow","title":"Professional Headshots Workflow","text":"<p>Steps: 1. Generate base image with Imagen3 2. Apply professional lighting enhancement 3. Background optimization 4. Upscale to 4K resolution 5. Create multiple lighting variations</p> <p>Configuration: <pre><code>{\n  \"workflow\": \"professional_headshots\",\n  \"prompt\": \"Business professional headshot\",\n  \"settings\": {\n    \"lighting\": \"professional\",\n    \"background\": \"office\",\n    \"upscale\": \"4x\",\n    \"variations\": 3\n  }\n}\n</code></pre></p>"},{"location":"USAGE/#product-photography-workflow","title":"Product Photography Workflow","text":"<p>Steps: 1. Generate product image 2. Remove/replace background 3. Apply studio lighting 4. Create multiple angles 5. Optimize for e-commerce</p> <p>Configuration: <pre><code>{\n  \"workflow\": \"product_photography\",\n  \"prompt\": \"White sneaker product shot\",\n  \"settings\": {\n    \"background\": \"white_studio\",\n    \"lighting\": \"studio\",\n    \"angles\": [\"front\", \"side\", \"three_quarter\"],\n    \"resolution\": \"high\"\n  }\n}\n</code></pre></p>"},{"location":"USAGE/#marketing-materials-workflow","title":"Marketing Materials Workflow","text":"<p>Steps: 1. Generate base design 2. Create style variations 3. Generate multiple aspect ratios 4. Apply brand guidelines 5. Optimize for different platforms</p> <p>Configuration: <pre><code>{\n  \"workflow\": \"marketing_materials\",\n  \"prompt\": \"Summer sale promotion\",\n  \"settings\": {\n    \"brand_colors\": [\"#FF6B6B\", \"#4ECDC4\"],\n    \"formats\": [\"square\", \"story\", \"banner\"],\n    \"variations\": 5\n  }\n}\n</code></pre></p>"},{"location":"USAGE/#post-processing","title":"Post-Processing","text":"<p>Enhance generated images with powerful AI-driven post-processing tools.</p>"},{"location":"USAGE/#upscaling","title":"Upscaling","text":"<p>2x Upscaling - Doubles image resolution - Maintains quality - Fast processing - Ideal for web use</p> <p>4x Upscaling - Quadruples resolution - Premium quality enhancement - Longer processing time - Print-ready quality</p> <p>Smart Enhancement - AI-powered detail improvement - Noise reduction - Sharpness optimization - Automatic quality boost</p>"},{"location":"USAGE/#relighting","title":"Relighting","text":"<p>Transform lighting in generated images:</p> <p>Professional Portrait - Optimized for headshots - Natural skin tones - Professional appearance - Business-appropriate lighting</p> <p>Studio Lighting - Commercial photography style - Dramatic shadows - High contrast - Professional product shots</p> <p>Natural Lighting - Outdoor/window light effect - Soft, even illumination - Warm, natural tones - Lifestyle photography feel</p> <p>Dramatic Lighting - Artistic mood lighting - Strong contrast - Creative shadows - Cinematic effect</p>"},{"location":"USAGE/#background-tools","title":"Background Tools","text":"<p>Remove Background - Create transparent PNG files - Perfect edge detection - Preserve fine details - E-commerce ready</p> <p>Replace Background - Swap backgrounds seamlessly - Maintain lighting consistency - Preserve subject quality - Creative flexibility</p> <p>Blur Background - Create depth-of-field effects - Focus attention on subject - Professional photography look - Adjustable blur intensity</p>"},{"location":"USAGE/#style-transfer","title":"Style Transfer","text":"<p>Artistic Styles - Impressionist painting - Abstract art - Watercolor effect - Oil painting style</p> <p>Photographic Styles - Vintage film look - Black and white - Sepia tone - HDR effect</p> <p>Brand Styles - Consistent visual identity - Custom color palettes - Brand-specific effects - Corporate guidelines</p>"},{"location":"USAGE/#advanced-features","title":"Advanced Features","text":""},{"location":"USAGE/#api-integration","title":"API Integration","text":"<p>Integrate the platform into your applications using our RESTful API.</p>"},{"location":"USAGE/#authentication","title":"Authentication","text":"<pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     https://api.freepik-orchestrator.com/v1/generate\n</code></pre>"},{"location":"USAGE/#basic-generation","title":"Basic Generation","text":"<p>Python Example: <pre><code>import requests\n\ndef generate_image(prompt, model=\"auto\"):\n    headers = {\n        \"Authorization\": f\"Bearer {API_KEY}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"prompt\": prompt,\n        \"model\": model,\n        \"webhook_url\": \"https://your-app.com/webhook\"\n    }\n\n    response = requests.post(\n        \"https://api.freepik-orchestrator.com/v1/generate\",\n        headers=headers,\n        json=data\n    )\n\n    return response.json()\n\n# Usage\nresult = generate_image(\"Professional headshot\")\ntask_id = result[\"task_id\"]\n</code></pre></p> <p>JavaScript Example: <pre><code>async function generateImage(prompt, model = \"auto\") {\n    const response = await fetch('/api/v1/generate', {\n        method: 'POST',\n        headers: {\n            'Authorization': `Bearer ${API_KEY}`,\n            'Content-Type': 'application/json'\n        },\n        body: JSON.stringify({\n            prompt: prompt,\n            model: model\n        })\n    });\n\n    return await response.json();\n}\n\n// Usage\nconst result = await generateImage(\"Professional headshot\");\nconsole.log(result.task_id);\n</code></pre></p>"},{"location":"USAGE/#webhook-integration","title":"Webhook Integration","text":"<p>Receive real-time notifications when images are ready.</p>"},{"location":"USAGE/#setup","title":"Setup","text":"<ol> <li>Provide webhook URL in generation request</li> <li>Implement webhook endpoint in your application</li> <li>Verify webhook signatures for security</li> <li>Handle different event types</li> </ol>"},{"location":"USAGE/#webhook-handler-example","title":"Webhook Handler Example","text":"<p>Python (Flask): <pre><code>import hmac\nimport hashlib\nfrom flask import Flask, request, jsonify\n\napp = Flask(__name__)\nWEBHOOK_SECRET = \"your_webhook_secret\"\n\n@app.route('/webhook', methods=['POST'])\ndef handle_webhook():\n    # Verify signature\n    signature = request.headers.get('X-Freepik-Signature')\n    payload = request.get_data()\n\n    expected = hmac.new(\n        WEBHOOK_SECRET.encode(),\n        payload,\n        hashlib.sha256\n    ).hexdigest()\n\n    if not hmac.compare_digest(f\"sha256={expected}\", signature):\n        return jsonify({\"error\": \"Invalid signature\"}), 401\n\n    # Process webhook\n    data = request.json\n    event_type = data.get('event')\n\n    if event_type == 'generation.completed':\n        task_id = data['data']['task_id']\n        image_url = data['data']['image_url']\n        # Process completed image\n\n    elif event_type == 'generation.failed':\n        task_id = data['data']['task_id']\n        error = data['data']['error']\n        # Handle generation failure\n\n    return jsonify({\"status\": \"ok\"})\n</code></pre></p> <p>Node.js (Express): <pre><code>const express = require('express');\nconst crypto = require('crypto');\nconst app = express();\n\napp.use(express.raw({ type: 'application/json' }));\n\napp.post('/webhook', (req, res) =&gt; {\n    const signature = req.headers['x-freepik-signature'];\n    const payload = req.body;\n\n    const expected = crypto\n        .createHmac('sha256', WEBHOOK_SECRET)\n        .update(payload)\n        .digest('hex');\n\n    if (signature !== `sha256=${expected}`) {\n        return res.status(401).json({ error: 'Invalid signature' });\n    }\n\n    const data = JSON.parse(payload);\n\n    switch (data.event) {\n        case 'generation.completed':\n            handleCompletedGeneration(data.data);\n            break;\n        case 'generation.failed':\n            handleFailedGeneration(data.data);\n            break;\n    }\n\n    res.json({ status: 'ok' });\n});\n</code></pre></p>"},{"location":"USAGE/#batch-processing","title":"Batch Processing","text":"<p>Process multiple images efficiently for high-volume applications.</p>"},{"location":"USAGE/#workflow-batching","title":"Workflow Batching","text":"<pre><code># Process multiple similar requests\nworkflow_requests = [\n    {\"prompt\": \"CEO headshot\", \"identifier\": \"john_doe\"},\n    {\"prompt\": \"CTO headshot\", \"identifier\": \"jane_smith\"},\n    {\"prompt\": \"CFO headshot\", \"identifier\": \"bob_johnson\"}\n]\n\nbatch_results = []\nfor request in workflow_requests:\n    result = client.execute_workflow(\n        \"professional_headshot\",\n        request[\"prompt\"],\n        metadata={\"identifier\": request[\"identifier\"]}\n    )\n    batch_results.append(result)\n</code></pre>"},{"location":"USAGE/#async-processing","title":"Async Processing","text":"<pre><code>// Process multiple requests concurrently\nconst prompts = [\n    \"Mountain landscape at sunset\",\n    \"Ocean waves crashing on rocks\",\n    \"Forest path in autumn\"\n];\n\nconst promises = prompts.map(prompt =&gt; \n    generateImage(prompt, {\n        webhook_url: 'https://your-app.com/webhook'\n    })\n);\n\ntry {\n    const results = await Promise.all(promises);\n    console.log('All generations started:', results);\n} catch (error) {\n    console.error('Batch processing error:', error);\n}\n</code></pre>"},{"location":"USAGE/#best-practices","title":"Best Practices","text":""},{"location":"USAGE/#prompt-writing-guidelines","title":"Prompt Writing Guidelines","text":""},{"location":"USAGE/#be-specific-and-descriptive","title":"Be Specific and Descriptive","text":"<p>Poor Example: <pre><code>person at work\n</code></pre></p> <p>Good Example: <pre><code>Professional businesswoman in modern office, confident posture, \nbusiness attire, natural lighting, working at desk with laptop\n</code></pre></p>"},{"location":"USAGE/#include-technical-photography-details","title":"Include Technical Photography Details","text":"<p>For Realistic Images: <pre><code>Shot with Canon 5D Mark IV, 85mm lens, f/1.8 aperture, \nshallow depth of field, professional lighting setup\n</code></pre></p> <p>For Product Photography: <pre><code>Studio lighting, white background, high resolution, \ncommercial photography, clean composition\n</code></pre></p>"},{"location":"USAGE/#specify-artistic-style","title":"Specify Artistic Style","text":"<p>For Illustrations: <pre><code>Digital art illustration, vibrant colors, detailed artwork, \nconcept art style, trending on ArtStation\n</code></pre></p> <p>For Paintings: <pre><code>Oil painting style, impressionist technique, \nrich textures, artistic brushstrokes\n</code></pre></p>"},{"location":"USAGE/#model-selection-strategy","title":"Model Selection Strategy","text":""},{"location":"USAGE/#decision-matrix","title":"Decision Matrix","text":"Use Case Recommended Model Reason Professional headshots Imagen3 Best photorealism Product photography Imagen3 Commercial quality Marketing graphics Flux Dev Speed + quality balance Concept art Mystic Artistic capabilities Quick iterations Classic Fast Speed General content Auto-selection AI optimization"},{"location":"USAGE/#cost-vs-quality","title":"Cost vs Quality","text":"<p>High Budget Projects: - Use Imagen3 or Mystic - Enable post-processing - Generate multiple variations</p> <p>Medium Budget Projects: - Use Flux Dev - Selective post-processing - Focus on prompt optimization</p> <p>Low Budget Projects: - Use Classic Fast - Optimize prompts carefully - Minimal post-processing</p>"},{"location":"USAGE/#performance-optimization","title":"Performance Optimization","text":""},{"location":"USAGE/#reduce-processing-time","title":"Reduce Processing Time","text":"<ol> <li>Use Classic Fast for testing</li> <li>Optimize prompts before final generation</li> <li>Batch similar requests together</li> <li>Use webhooks for async processing</li> </ol>"},{"location":"USAGE/#improve-quality","title":"Improve Quality","text":"<ol> <li>Iterate on prompts based on results</li> <li>Use appropriate models for content type</li> <li>Apply post-processing selectively</li> <li>Study successful prompts in your use case</li> </ol>"},{"location":"USAGE/#manage-costs","title":"Manage Costs","text":"<ol> <li>Use auto-selection for optimal model choice</li> <li>Cache common results to avoid regeneration</li> <li>Monitor usage in analytics dashboard</li> <li>Set up alerts for usage thresholds</li> </ol>"},{"location":"USAGE/#analytics-and-monitoring","title":"Analytics and Monitoring","text":""},{"location":"USAGE/#usage-dashboard","title":"Usage Dashboard","text":"<p>Track your platform usage with comprehensive analytics:</p>"},{"location":"USAGE/#key-metrics","title":"Key Metrics","text":"<p>Daily Activity - Number of generations - Success/failure rates - Average processing time - Cost per generation</p> <p>Model Performance - Usage by model - Quality ratings - Processing time comparison - Cost analysis</p> <p>Prompt Analysis - Most successful prompts - Common failure patterns - Enhancement effectiveness - Trending keywords</p>"},{"location":"USAGE/#business-intelligence","title":"Business Intelligence","text":"<p>Cost Analysis - Monthly spending trends - Cost per model - ROI calculations - Budget forecasting</p> <p>Quality Metrics - User satisfaction scores - Regeneration rates - Post-processing usage - Success patterns</p>"},{"location":"USAGE/#optimization-insights","title":"Optimization Insights","text":"<p>Use analytics to optimize your usage:</p>"},{"location":"USAGE/#identify-patterns","title":"Identify Patterns","text":"<ol> <li>Best performing prompts for your use case</li> <li>Optimal model selection for different content types</li> <li>Most effective enhancement techniques</li> <li>Cost-efficient workflows</li> </ol>"},{"location":"USAGE/#continuous-improvement","title":"Continuous Improvement","text":"<ol> <li>A/B test different prompts</li> <li>Compare model performance</li> <li>Track quality over time</li> <li>Optimize based on data</li> </ol>"},{"location":"USAGE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"USAGE/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"USAGE/#generation-failures","title":"Generation Failures","text":"<p>Issue: \"Generation Failed\" error Causes &amp; Solutions:</p> <ol> <li>Invalid API Key</li> <li>Verify key in settings</li> <li>Check key permissions</li> <li> <p>Regenerate if necessary</p> </li> <li> <p>Insufficient Credits</p> </li> <li>Check account balance</li> <li>Upgrade plan if needed</li> <li> <p>Monitor usage patterns</p> </li> <li> <p>Content Policy Violation</p> </li> <li>Review prompt content</li> <li>Avoid prohibited subjects</li> <li> <p>Use content guidelines</p> </li> <li> <p>Model Unavailable</p> </li> <li>Try different model</li> <li>Check system status</li> <li>Use auto-selection</li> </ol>"},{"location":"USAGE/#quality-issues","title":"Quality Issues","text":"<p>Issue: Poor quality results Solutions:</p> <ol> <li>Improve Prompt Quality</li> <li>Add more descriptive details</li> <li>Include technical specifications</li> <li> <p>Specify artistic style</p> </li> <li> <p>Try Different Models</p> </li> <li>Test Imagen3 for realism</li> <li>Use Mystic for artistic content</li> <li> <p>Compare results across models</p> </li> <li> <p>Use Post-Processing</p> </li> <li>Apply upscaling</li> <li>Enhance lighting</li> <li> <p>Improve composition</p> </li> <li> <p>Iterate and Refine</p> </li> <li>Analyze successful prompts</li> <li>Build prompt templates</li> <li>Learn from feedback</li> </ol>"},{"location":"USAGE/#performance-issues","title":"Performance Issues","text":"<p>Issue: Slow processing times Solutions:</p> <ol> <li>Choose Faster Models</li> <li>Use Classic Fast for testing</li> <li>Consider Flux Dev for balance</li> <li> <p>Reserve premium models for final output</p> </li> <li> <p>Optimize Workflow</p> </li> <li>Use async processing</li> <li>Implement efficient batching</li> <li> <p>Monitor system load</p> </li> <li> <p>Account Configuration</p> </li> <li>Upgrade for priority processing</li> <li>Check rate limits</li> <li>Optimize API usage</li> </ol>"},{"location":"USAGE/#error-codes","title":"Error Codes","text":"Code Description Solution 400 Bad Request Check request format 401 Unauthorized Verify API key 403 Forbidden Check permissions 429 Rate Limited Reduce request frequency 500 Server Error Contact support"},{"location":"USAGE/#getting-support","title":"Getting Support","text":""},{"location":"USAGE/#self-service-resources","title":"Self-Service Resources","text":"<ol> <li>Documentation: Complete guides and references</li> <li>Status Page: System status and incidents</li> <li>Community Forum: User discussions and tips</li> <li>Video Tutorials: Step-by-step guides</li> </ol>"},{"location":"USAGE/#direct-support","title":"Direct Support","text":"<ol> <li>Email Support: support@freepik-orchestrator.com</li> <li>Live Chat: Available during business hours</li> <li>Discord Community: Real-time help and discussions</li> <li>Enterprise Support: Dedicated support for enterprise customers</li> </ol>"},{"location":"USAGE/#before-contacting-support","title":"Before Contacting Support","text":"<p>Gather the following information:</p> <ol> <li>Account Details: Username, plan type</li> <li>Error Information: Error messages, codes</li> <li>Request Details: Prompts, models used</li> <li>Browser/System Info: For web interface issues</li> <li>API Logs: For integration issues</li> </ol> <p>Ready to create amazing images? Start with the Quick Start Guide or explore our API Reference for integration details!</p>"},{"location":"USAGE/#core-features_1","title":"Core Features","text":""},{"location":"USAGE/#prompt-engineering","title":"Prompt Engineering","text":"<p>The platform automatically optimizes your prompts using AI:</p>"},{"location":"USAGE/#basic-prompts","title":"Basic Prompts","text":"<pre><code>Input: \"business headshot\"\nEnhanced: \"Professional business headshot, confident expression, modern office background, natural lighting, shot with Canon 5D Mark IV, 85mm lens, sharp focus, high resolution\"\n</code></pre>"},{"location":"USAGE/#style-enhancement","title":"Style Enhancement","text":"<pre><code>Input: \"cat painting\"\nEnhanced: \"Digital art painting of a cat, artistic brush strokes, vibrant colors, detailed fur texture, creative composition, high resolution illustration\"\n</code></pre>"},{"location":"USAGE/#model-selection_1","title":"Model Selection","text":""},{"location":"USAGE/#auto-selection-recommended","title":"Auto-Selection (Recommended)","text":"<p>Let AI choose the optimal model based on your prompt: - Analyzes prompt content and style requirements - Considers use case (professional, artistic, commercial) - Selects best model for quality and speed</p>"},{"location":"USAGE/#manual-selection","title":"Manual Selection","text":"<p>Choose specific models for particular needs:</p> <ul> <li>Mystic: Balanced general-purpose model</li> <li>Best for: Mixed content, versatile applications</li> <li>Speed: Medium (30-45 seconds)</li> <li> <p>Quality: High</p> </li> <li> <p>Imagen3: Photorealistic model</p> </li> <li>Best for: Professional photos, portraits, products</li> <li>Speed: Medium (45-60 seconds)</li> <li> <p>Quality: Excellent for realism</p> </li> <li> <p>Flux Dev: Advanced artistic control</p> </li> <li>Best for: Creative concepts, artistic styles, complex compositions</li> <li>Speed: Slower (60-90 seconds)</li> <li> <p>Quality: Excellent for artistic content</p> </li> <li> <p>Classic Fast: Quick iterations</p> </li> <li>Best for: Simple requests, rapid prototyping</li> <li>Speed: Fast (10-15 seconds)</li> <li>Quality: Good for basic needs</li> </ul>"},{"location":"USAGE/#workflows_1","title":"Workflows","text":"<p>Pre-built workflows automate complex multi-step processes:</p>"},{"location":"USAGE/#professional-headshots","title":"Professional Headshots","text":"<ol> <li>Generate base image with Imagen3</li> <li>Apply professional lighting</li> <li>Upscale to 4K resolution</li> <li>Create lighting variations</li> </ol> <p>Use for: LinkedIn profiles, corporate websites, professional portfolios</p>"},{"location":"USAGE/#product-photography","title":"Product Photography","text":"<ol> <li>Generate product image</li> <li>Remove background</li> <li>Apply studio lighting</li> <li>Create multiple angles</li> <li>Upscale for e-commerce</li> </ol> <p>Use for: Online stores, catalogs, marketing materials</p>"},{"location":"USAGE/#marketing-materials","title":"Marketing Materials","text":"<ol> <li>Generate base design</li> <li>Create style variations</li> <li>Generate multiple aspect ratios</li> <li>Apply brand overlays</li> </ol> <p>Use for: Social media, advertisements, promotional content</p>"},{"location":"USAGE/#post-processing_1","title":"Post-Processing","text":"<p>Enhance generated images with additional AI tools:</p>"},{"location":"USAGE/#upscaling_1","title":"Upscaling","text":"<ul> <li>2x Upscale: Double image resolution</li> <li>4x Upscale: Quadruple resolution for print quality</li> <li>Smart enhancement: AI-powered detail improvement</li> </ul>"},{"location":"USAGE/#relighting_1","title":"Relighting","text":"<ul> <li>Professional portrait: Optimized for headshots</li> <li>Studio lighting: Commercial photography style</li> <li>Natural lighting: Outdoor/window light effect</li> <li>Dramatic lighting: Artistic mood lighting</li> </ul>"},{"location":"USAGE/#background-tools_1","title":"Background Tools","text":"<ul> <li>Remove background: Create transparent PNG files</li> <li>Replace background: Swap backgrounds while maintaining subject</li> <li>Blur background: Create depth-of-field effects</li> </ul>"},{"location":"USAGE/#style-transfer_1","title":"Style Transfer","text":"<ul> <li>Artistic styles: Apply painting styles (impressionist, abstract, etc.)</li> <li>Photographic styles: Film styles, vintage effects</li> <li>Brand styles: Consistent visual identity</li> </ul>"},{"location":"USAGE/#advanced-usage","title":"Advanced Usage","text":""},{"location":"USAGE/#api-integration_1","title":"API Integration","text":"<p>Integrate the platform into your applications:</p>"},{"location":"USAGE/#python-example","title":"Python Example","text":"<pre><code>import requests\n\napi_key = \"your-api-key\"\nheaders = {\"Authorization\": f\"Bearer {api_key}\"}\n\n# Generate image\nresponse = requests.post(\n    \"https://api.freepik-orchestrator.com/v1/generate\",\n    headers=headers,\n    json={\n        \"prompt\": \"professional headshot\",\n        \"model\": \"auto\",\n        \"webhook_url\": \"https://your-app.com/webhook\"\n    }\n)\n\ntask_id = response.json()[\"task_id\"]\n</code></pre>"},{"location":"USAGE/#javascript-example","title":"JavaScript Example","text":"<pre><code>const response = await fetch('https://api.freepik-orchestrator.com/v1/generate', {\n  method: 'POST',\n  headers: {\n    'Authorization': 'Bearer your-api-key',\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    prompt: 'professional headshot',\n    model: 'auto'\n  })\n});\n\nconst result = await response.json();\n</code></pre>"},{"location":"USAGE/#webhook-integration_1","title":"Webhook Integration","text":"<p>Receive real-time notifications when images are ready:</p>"},{"location":"USAGE/#webhook-setup","title":"Webhook Setup","text":"<ol> <li>Provide webhook URL in generation request</li> <li>Verify webhook signature for security</li> <li>Handle different event types</li> </ol>"},{"location":"USAGE/#example-webhook-handler-python","title":"Example Webhook Handler (Python)","text":"<pre><code>import hmac\nimport hashlib\nfrom flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/webhook', methods=['POST'])\ndef handle_webhook():\n    signature = request.headers.get('X-Freepik-Signature')\n    payload = request.get_data()\n\n    # Verify signature\n    expected = hmac.new(\n        WEBHOOK_SECRET.encode(),\n        payload,\n        hashlib.sha256\n    ).hexdigest()\n\n    if not hmac.compare_digest(f\"sha256={expected}\", signature):\n        return \"Invalid signature\", 401\n\n    data = request.json\n    if data['event'] == 'generation.completed':\n        image_url = data['data']['image_url']\n        # Process completed image\n\n    return \"OK\"\n</code></pre>"},{"location":"USAGE/#batch-processing_1","title":"Batch Processing","text":"<p>Process multiple images efficiently:</p>"},{"location":"USAGE/#using-workflows","title":"Using Workflows","text":"<pre><code>workflow_requests = [\n    {\"prompt\": \"CEO headshot\", \"name\": \"john_doe\"},\n    {\"prompt\": \"CTO headshot\", \"name\": \"jane_smith\"},\n    {\"prompt\": \"CFO headshot\", \"name\": \"bob_johnson\"}\n]\n\nfor request in workflow_requests:\n    response = client.execute_workflow(\n        \"professional_headshot\",\n        request[\"prompt\"]\n    )\n    # Track by name for identification\n</code></pre>"},{"location":"USAGE/#async-processing_1","title":"Async Processing","text":"<pre><code>const promises = prompts.map(prompt =&gt; \n    client.generate({\n        prompt: prompt,\n        webhook_url: 'https://your-app.com/webhook'\n    })\n);\n\nconst results = await Promise.all(promises);\n</code></pre>"},{"location":"USAGE/#best-practices_1","title":"Best Practices","text":""},{"location":"USAGE/#prompt-writing","title":"Prompt Writing","text":""},{"location":"USAGE/#be-specific","title":"Be Specific","text":"<pre><code>\u274c \"person at work\"\n\u2705 \"professional businesswoman in modern office, confident posture, business attire, natural lighting\"\n</code></pre>"},{"location":"USAGE/#include-technical-details","title":"Include Technical Details","text":"<pre><code>\u274c \"high quality photo\"\n\u2705 \"shot with Canon 5D Mark IV, 85mm lens, shallow depth of field, professional lighting, sharp focus\"\n</code></pre>"},{"location":"USAGE/#specify-style","title":"Specify Style","text":"<pre><code>\u274c \"artistic image\"\n\u2705 \"digital art illustration, vibrant colors, detailed, concept art style\"\n</code></pre>"},{"location":"USAGE/#model-selection-guidelines","title":"Model Selection Guidelines","text":""},{"location":"USAGE/#choose-imagen3-for","title":"Choose Imagen3 for:","text":"<ul> <li>Professional photography</li> <li>Product images</li> <li>Realistic portraits</li> <li>Commercial content</li> </ul>"},{"location":"USAGE/#choose-flux-dev-for","title":"Choose Flux Dev for:","text":"<ul> <li>Artistic illustrations</li> <li>Creative concepts</li> <li>Complex compositions</li> <li>Stylized content</li> </ul>"},{"location":"USAGE/#choose-mystic-for","title":"Choose Mystic for:","text":"<ul> <li>General purpose needs</li> <li>Mixed content types</li> <li>Balanced results</li> <li>Unknown requirements</li> </ul>"},{"location":"USAGE/#choose-classic-fast-for","title":"Choose Classic Fast for:","text":"<ul> <li>Quick iterations</li> <li>Simple concepts</li> <li>Draft versions</li> <li>High-volume processing</li> </ul>"},{"location":"USAGE/#cost-optimization","title":"Cost Optimization","text":""},{"location":"USAGE/#use-auto-selection","title":"Use Auto-Selection","text":"<p>Let AI choose the most cost-effective model for your needs.</p>"},{"location":"USAGE/#batch-similar-requests","title":"Batch Similar Requests","text":"<p>Group similar prompts to optimize processing.</p>"},{"location":"USAGE/#use-appropriate-quality-settings","title":"Use Appropriate Quality Settings","text":"<p>Higher quality costs more but provides better results.</p>"},{"location":"USAGE/#cache-common-results","title":"Cache Common Results","text":"<p>Store frequently used images to avoid regeneration.</p>"},{"location":"USAGE/#quality-optimization","title":"Quality Optimization","text":""},{"location":"USAGE/#iterate-on-prompts","title":"Iterate on Prompts","text":"<p>Start simple and refine based on results.</p>"},{"location":"USAGE/#use-post-processing","title":"Use Post-Processing","text":"<p>Enhance results with upscaling and relighting.</p>"},{"location":"USAGE/#compare-models","title":"Compare Models","text":"<p>Test different models for your specific use case.</p>"},{"location":"USAGE/#leverage-workflows","title":"Leverage Workflows","text":"<p>Use predefined workflows for consistent quality.</p>"},{"location":"USAGE/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"USAGE/#common-issues","title":"Common Issues","text":""},{"location":"USAGE/#generation-failed-error","title":"\"Generation Failed\" Error","text":"<ul> <li>Check your API key validity</li> <li>Verify account has sufficient credits</li> <li>Ensure prompt meets content guidelines</li> <li>Try a different model if auto-selection fails</li> </ul>"},{"location":"USAGE/#webhook-not-received-issue","title":"\"Webhook Not Received\" Issue","text":"<ul> <li>Verify webhook URL is accessible</li> <li>Check webhook signature verification</li> <li>Ensure HTTPS is used for webhook URLs</li> <li>Test webhook endpoint independently</li> </ul>"},{"location":"USAGE/#poor-quality-results","title":"\"Poor Quality Results\"","text":"<ul> <li>Refine prompt with more specific details</li> <li>Try different models for your use case</li> <li>Use post-processing to enhance results</li> <li>Check quality settings in preferences</li> </ul>"},{"location":"USAGE/#slow-processing-times","title":"\"Slow Processing Times\"","text":"<ul> <li>Consider using Classic Fast for simple requests</li> <li>Avoid peak usage hours if possible</li> <li>Use async processing with webhooks</li> <li>Upgrade to higher tier for priority processing</li> </ul>"},{"location":"USAGE/#getting-help","title":"Getting Help","text":""},{"location":"USAGE/#support-channels","title":"Support Channels","text":"<ul> <li>Email: support@freepik-orchestrator.com</li> <li>Discord: Community server</li> <li>Documentation: Full documentation</li> <li>Status Page: System status</li> </ul>"},{"location":"USAGE/#before-contacting-support_1","title":"Before Contacting Support","text":"<ul> <li>Check the status page for known issues</li> <li>Review your API key and account status</li> <li>Try the request again with simpler parameters</li> <li>Gather error messages and request IDs</li> </ul>"},{"location":"USAGE/#billing-and-limits","title":"Billing and Limits","text":""},{"location":"USAGE/#usage-tracking","title":"Usage Tracking","text":"<p>Monitor your usage in the Analytics tab: - Daily generations: Track daily usage against limits - Model breakdown: See which models you use most - Cost analysis: Understand spending patterns - Success rates: Monitor generation success rates</p>"},{"location":"USAGE/#plan-limits","title":"Plan Limits","text":""},{"location":"USAGE/#free-tier","title":"Free Tier","text":"<ul> <li>10 generations per day</li> <li>All models available</li> <li>Basic support</li> <li>No commercial use</li> </ul>"},{"location":"USAGE/#professional-tier","title":"Professional Tier","text":"<ul> <li>Unlimited generations</li> <li>Priority processing</li> <li>Email support</li> <li>Commercial use allowed</li> <li>Advanced analytics</li> </ul>"},{"location":"USAGE/#enterprise-tier","title":"Enterprise Tier","text":"<ul> <li>Volume discounts</li> <li>Custom workflows</li> <li>Dedicated support</li> <li>White-label options</li> <li>SLA guarantees</li> </ul>"},{"location":"USAGE/#upgrade-benefits","title":"Upgrade Benefits","text":"<p>Upgrading provides: - Higher rate limits - Faster processing - Better support - Advanced features - Commercial usage rights</p> <p>Ready to get started? Create your account and begin generating amazing AI images with the Freepik AI Orchestrator!</p>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>This guide covers all configuration options available in the Freepik AI Orchestrator.</p>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>The application uses environment variables for configuration. These can be set in a <code>.env</code> file or directly in your environment.</p>"},{"location":"configuration/#core-configuration","title":"Core Configuration","text":""},{"location":"configuration/#freepik-api-settings","title":"Freepik API Settings","text":"Variable Description Required Default <code>FREEPIK_API_KEY</code> Your Freepik API key Yes - <code>FREEPIK_BASE_URL</code> Freepik API base URL No <code>https://api.freepik.com</code> <code>FREEPIK_TIMEOUT</code> API request timeout (seconds) No <code>30</code> <code>FREEPIK_RETRY_COUNT</code> Number of retry attempts No <code>3</code>"},{"location":"configuration/#llm-provider-settings","title":"LLM Provider Settings","text":"<p>Choose one of the following LLM providers:</p>"},{"location":"configuration/#openai-configuration","title":"OpenAI Configuration","text":"Variable Description Required Default <code>OPENAI_API_KEY</code> OpenAI API key Yes* - <code>OPENAI_MODEL</code> Model to use No <code>gpt-4</code> <code>OPENAI_MAX_TOKENS</code> Maximum tokens per request No <code>1000</code> <code>OPENAI_TEMPERATURE</code> Response creativity (0-1) No <code>0.7</code>"},{"location":"configuration/#anthropic-configuration","title":"Anthropic Configuration","text":"Variable Description Required Default <code>ANTHROPIC_API_KEY</code> Anthropic API key Yes* - <code>ANTHROPIC_MODEL</code> Model to use No <code>claude-3-sonnet-20240229</code> <code>ANTHROPIC_MAX_TOKENS</code> Maximum tokens per request No <code>1000</code> <p>*One LLM provider is required</p>"},{"location":"configuration/#application-settings","title":"Application Settings","text":""},{"location":"configuration/#general-settings","title":"General Settings","text":"Variable Description Required Default <code>APP_ENV</code> Environment (development/production) No <code>development</code> <code>DEBUG</code> Enable debug mode No <code>false</code> <code>LOG_LEVEL</code> Logging level No <code>INFO</code> <code>SECRET_KEY</code> Application secret key No Auto-generated"},{"location":"configuration/#database-configuration","title":"Database Configuration","text":"Variable Description Required Default <code>DATABASE_URL</code> Database connection string No <code>sqlite:///freepik_orchestrator.db</code> <code>DB_POOL_SIZE</code> Connection pool size No <code>5</code> <code>DB_MAX_OVERFLOW</code> Maximum overflow connections No <code>10</code>"},{"location":"configuration/#streamlit-configuration","title":"Streamlit Configuration","text":"Variable Description Required Default <code>STREAMLIT_SERVER_PORT</code> Server port No <code>8501</code> <code>STREAMLIT_SERVER_ADDRESS</code> Server address No <code>0.0.0.0</code> <code>STREAMLIT_BROWSER_GATHER_USAGE_STATS</code> Collect usage stats No <code>false</code> <code>STREAMLIT_SERVER_ENABLE_CORS</code> Enable CORS No <code>false</code>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#webhook-settings","title":"Webhook Settings","text":"Variable Description Required Default <code>WEBHOOK_URL</code> Webhook endpoint URL No - <code>WEBHOOK_SECRET</code> Webhook secret for verification No - <code>WEBHOOK_TIMEOUT</code> Webhook timeout (seconds) No <code>30</code>"},{"location":"configuration/#caching-configuration","title":"Caching Configuration","text":"Variable Description Required Default <code>CACHE_TYPE</code> Cache backend (memory/redis) No <code>memory</code> <code>REDIS_URL</code> Redis connection URL No - <code>CACHE_DEFAULT_TIMEOUT</code> Default cache timeout (seconds) No <code>300</code>"},{"location":"configuration/#rate-limiting","title":"Rate Limiting","text":"Variable Description Required Default <code>RATE_LIMIT_ENABLED</code> Enable rate limiting No <code>true</code> <code>RATE_LIMIT_PER_MINUTE</code> Requests per minute No <code>60</code> <code>RATE_LIMIT_PER_HOUR</code> Requests per hour No <code>1000</code>"},{"location":"configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"configuration/#streamlit-configuration_1","title":"Streamlit Configuration","text":"<p>Create a <code>.streamlit/config.toml</code> file for Streamlit-specific settings:</p> <pre><code>[server]\nport = 8501\naddress = \"0.0.0.0\"\nenableCORS = false\nenableXsrfProtection = true\n\n[browser]\ngatherUsageStats = false\n\n[theme]\nprimaryColor = \"#FF6B6B\"\nbackgroundColor = \"#FFFFFF\"\nsecondaryBackgroundColor = \"#F0F2F6\"\ntextColor = \"#262730\"\n</code></pre>"},{"location":"configuration/#logging-configuration","title":"Logging Configuration","text":"<p>Create a <code>logging.yaml</code> file for detailed logging configuration:</p> <pre><code>version: 1\ndisable_existing_loggers: false\n\nformatters:\n  default:\n    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n  detailed:\n    format: '%(asctime)s - %(name)s - %(levelname)s - %(module)s - %(funcName)s - %(message)s'\n\nhandlers:\n  console:\n    class: logging.StreamHandler\n    level: INFO\n    formatter: default\n    stream: ext://sys.stdout\n\n  file:\n    class: logging.handlers.RotatingFileHandler\n    level: DEBUG\n    formatter: detailed\n    filename: logs/app.log\n    maxBytes: 10485760  # 10MB\n    backupCount: 5\n\nroot:\n  level: INFO\n  handlers: [console, file]\n\nloggers:\n  freepik_orchestrator:\n    level: DEBUG\n    handlers: [console, file]\n    propagate: false\n\n  streamlit:\n    level: WARNING\n    handlers: [console]\n    propagate: false\n</code></pre>"},{"location":"configuration/#model-configuration","title":"Model Configuration","text":""},{"location":"configuration/#image-generation-models","title":"Image Generation Models","text":"<p>Configure available models in your application:</p> <pre><code># config/models.py\nAVAILABLE_MODELS = {\n    \"mystic\": {\n        \"name\": \"Mystic\",\n        \"description\": \"High-quality artistic images\",\n        \"max_resolution\": \"1024x1024\",\n        \"pricing_tier\": \"premium\"\n    },\n    \"imagen3\": {\n        \"name\": \"Imagen 3\",\n        \"description\": \"Google's latest image model\",\n        \"max_resolution\": \"1536x1536\",\n        \"pricing_tier\": \"premium\"\n    },\n    \"flux_dev\": {\n        \"name\": \"Flux Dev\",\n        \"description\": \"Fast development model\",\n        \"max_resolution\": \"1024x1024\",\n        \"pricing_tier\": \"standard\"\n    },\n    \"classic_fast\": {\n        \"name\": \"Classic Fast\",\n        \"description\": \"Quick generation model\",\n        \"max_resolution\": \"512x512\",\n        \"pricing_tier\": \"basic\"\n    }\n}\n</code></pre>"},{"location":"configuration/#post-processing-configuration","title":"Post-Processing Configuration","text":"<pre><code># config/post_processing.py\nPOST_PROCESSING_OPTIONS = {\n    \"upscaling\": {\n        \"enabled\": True,\n        \"max_scale\": 4,\n        \"algorithms\": [\"esrgan\", \"real_esrgan\", \"waifu2x\"]\n    },\n    \"background_removal\": {\n        \"enabled\": True,\n        \"models\": [\"u2net\", \"silueta\"]\n    },\n    \"style_transfer\": {\n        \"enabled\": True,\n        \"styles\": [\"artistic\", \"photographic\", \"cartoon\"]\n    },\n    \"relighting\": {\n        \"enabled\": True,\n        \"presets\": [\"natural\", \"dramatic\", \"soft\"]\n    }\n}\n</code></pre>"},{"location":"configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"configuration/#api-key-management","title":"API Key Management","text":"<p>For production deployments, consider using a secrets management system:</p> <pre><code># Using AWS Secrets Manager\nexport FREEPIK_API_KEY=$(aws secretsmanager get-secret-value --secret-id freepik-api-key --query SecretString --output text)\n\n# Using Azure Key Vault\nexport FREEPIK_API_KEY=$(az keyvault secret show --vault-name your-vault --name freepik-api-key --query value -o tsv)\n\n# Using HashiCorp Vault\nexport FREEPIK_API_KEY=$(vault kv get -field=api_key secret/freepik)\n</code></pre>"},{"location":"configuration/#https-configuration","title":"HTTPS Configuration","text":"<p>For production, enable HTTPS:</p> <pre><code># .streamlit/config.toml\n[server]\nenableCORS = false\nenableXsrfProtection = true\nsslCertFile = \"/path/to/cert.pem\"\nsslKeyFile = \"/path/to/key.pem\"\n</code></pre>"},{"location":"configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"configuration/#database-optimization","title":"Database Optimization","text":"<p>For PostgreSQL in production:</p> <pre><code># Environment variables\nDATABASE_URL=postgresql://user:password@localhost:5432/freepik_orchestrator\nDB_POOL_SIZE=20\nDB_MAX_OVERFLOW=30\nDB_POOL_TIMEOUT=30\nDB_POOL_RECYCLE=3600\n</code></pre>"},{"location":"configuration/#caching-configuration_1","title":"Caching Configuration","text":"<p>For Redis caching:</p> <pre><code># Environment variables\nCACHE_TYPE=redis\nREDIS_URL=redis://localhost:6379/0\nCACHE_DEFAULT_TIMEOUT=3600\nCACHE_KEY_PREFIX=freepik_orchestrator:\n</code></pre>"},{"location":"configuration/#async-configuration","title":"Async Configuration","text":"<pre><code># Webhook and async processing\nWEBHOOK_WORKERS=4\nASYNC_TIMEOUT=300\nMAX_CONCURRENT_REQUESTS=10\n</code></pre>"},{"location":"configuration/#monitoring-configuration","title":"Monitoring Configuration","text":""},{"location":"configuration/#metrics-and-analytics","title":"Metrics and Analytics","text":"<pre><code># Monitoring settings\nENABLE_METRICS=true\nMETRICS_PORT=9090\nPROMETHEUS_ENABLED=true\nGRAFANA_DASHBOARD_URL=http://localhost:3000\n</code></pre>"},{"location":"configuration/#health-checks","title":"Health Checks","text":"<pre><code># Health check configuration\nHEALTH_CHECK_ENABLED=true\nHEALTH_CHECK_INTERVAL=30\nHEALTH_CHECK_TIMEOUT=10\n</code></pre>"},{"location":"configuration/#validation","title":"Validation","text":"<p>Validate your configuration with the built-in validator:</p> <pre><code>python -c \"from config.validator import validate_config; validate_config()\"\n</code></pre> <p>This will check: - Required environment variables - API key validity - Database connectivity - LLM provider accessibility</p>"},{"location":"configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"configuration/#development-environment","title":"Development Environment","text":"<pre><code># .env for development\nAPP_ENV=development\nDEBUG=true\nLOG_LEVEL=DEBUG\nFREEPIK_API_KEY=your_dev_key\nOPENAI_API_KEY=your_openai_key\nDATABASE_URL=sqlite:///dev.db\nSTREAMLIT_SERVER_PORT=8501\n</code></pre>"},{"location":"configuration/#production-environment","title":"Production Environment","text":"<pre><code># .env for production\nAPP_ENV=production\nDEBUG=false\nLOG_LEVEL=INFO\nFREEPIK_API_KEY=your_prod_key\nOPENAI_API_KEY=your_openai_key\nDATABASE_URL=postgresql://user:pass@db:5432/freepik_orchestrator\nCACHE_TYPE=redis\nREDIS_URL=redis://redis:6379/0\nRATE_LIMIT_ENABLED=true\nWEBHOOK_URL=https://your-domain.com/webhook\n</code></pre>"},{"location":"configuration/#next-steps","title":"Next Steps","text":"<p>With your configuration complete:</p> <ol> <li>Test Configuration: Run the configuration validator</li> <li>Start Application: Launch the application with your settings</li> <li>Monitor: Set up monitoring and logging</li> <li>Optimize: Tune performance based on usage patterns</li> </ol> <p>For detailed usage instructions, see the Usage Guide.</p>"},{"location":"features/","title":"Features Overview","text":"<p>Explore the comprehensive features that make the Freepik AI Orchestrator a powerful platform for AI image generation.</p>"},{"location":"features/#core-features","title":"Core Features","text":""},{"location":"features/#llm-powered-prompt-enhancement","title":"\ud83e\udd16 LLM-Powered Prompt Enhancement","text":"<p>Transform simple prompts into detailed, optimized descriptions that generate better results.</p>"},{"location":"features/#how-it-works","title":"How It Works","text":"<ol> <li>Prompt Analysis: Advanced language models analyze your input</li> <li>Context Enhancement: Adds relevant technical and artistic details</li> <li>Style Optimization: Adjusts language for specific AI models</li> <li>Quality Improvement: Ensures prompts follow best practices</li> </ol>"},{"location":"features/#example-transformations","title":"Example Transformations","text":"<p>Business Use Case: - Input: \"team meeting\" - Enhanced: \"Professional business meeting in modern conference room, diverse team of executives discussing strategy, natural lighting, shot with Canon 5D Mark IV, 35mm lens, corporate photography style, high resolution\"</p> <p>Creative Use Case: - Input: \"fantasy castle\" - Enhanced: \"Majestic medieval fantasy castle on mountain peak, ethereal mist, dramatic golden hour lighting, cinematic composition, detailed architecture, fantasy art style, high resolution digital painting\"</p>"},{"location":"features/#multi-model-support","title":"\ud83c\udfaf Multi-Model Support","text":"<p>Choose from industry-leading AI models or let our system select the best one for your needs.</p>"},{"location":"features/#available-models","title":"Available Models","text":"<p>Imagen3 - Specialty: Photorealistic images - Best For: Professional photography, portraits, products - Processing Time: 45-60 seconds - Quality: Exceptional realism</p> <p>Mystic - Specialty: Artistic and creative content - Best For: Concept art, illustrations, unique styles - Processing Time: 30-90 seconds - Quality: Premium artistic output</p> <p>Flux Dev - Specialty: Balanced quality and speed - Best For: General content, marketing materials - Processing Time: 30-45 seconds - Quality: High-quality versatile results</p> <p>Classic Fast - Specialty: Rapid generation - Best For: Quick iterations, testing concepts - Processing Time: 10-15 seconds - Quality: Good for basic needs</p>"},{"location":"features/#auto-selection-intelligence","title":"Auto-Selection Intelligence","text":"<p>Our AI automatically selects the optimal model based on:</p> <ul> <li>Prompt content and style requirements</li> <li>Quality vs speed preferences</li> <li>Use case analysis (business, artistic, commercial)</li> <li>Historical performance data</li> </ul>"},{"location":"features/#advanced-post-processing","title":"\ud83d\udd04 Advanced Post-Processing","text":"<p>Enhance your generated images with professional-grade post-processing tools.</p>"},{"location":"features/#upscaling-technology","title":"Upscaling Technology","text":"<p>AI-Powered Enhancement - 2x Upscaling: Perfect for web and digital use - 4x Upscaling: Print-ready quality enhancement - Smart Enhancement: Automatic detail improvement and noise reduction</p> <p>Technical Features - Edge-preserving algorithms - Texture enhancement - Color fidelity maintenance - Batch processing support</p>"},{"location":"features/#relighting-capabilities","title":"Relighting Capabilities","text":"<p>Professional Lighting Presets - Portrait Lighting: Optimized for headshots and people - Studio Lighting: Commercial photography style - Natural Lighting: Outdoor and ambient effects - Dramatic Lighting: Artistic and cinematic moods</p> <p>Custom Lighting Control - Intensity adjustment - Direction modification - Color temperature control - Shadow enhancement</p>"},{"location":"features/#background-tools","title":"Background Tools","text":"<p>Remove Background - High-precision edge detection - Hair and fine detail preservation - Transparent PNG output - E-commerce ready results</p> <p>Replace Background - Seamless background swapping - Lighting consistency maintenance - Perspective matching - Creative flexibility</p> <p>Blur Background - Professional depth-of-field effects - Adjustable blur intensity - Subject focus enhancement - Portrait photography style</p>"},{"location":"features/#style-transfer","title":"Style Transfer","text":"<p>Artistic Styles - Impressionist painting effects - Abstract art transformations - Watercolor and oil painting styles - Custom artistic filters</p> <p>Photographic Styles - Vintage film looks - Black and white conversion - Sepia and retro effects - HDR and cinematic styles</p>"},{"location":"features/#real-time-analytics","title":"\ud83d\udcca Real-Time Analytics","text":"<p>Comprehensive analytics and insights to optimize your usage and track performance.</p>"},{"location":"features/#usage-metrics","title":"Usage Metrics","text":"<p>Generation Statistics - Daily, weekly, and monthly generation counts - Success and failure rates - Average processing times - Model usage distribution</p> <p>Quality Metrics - User satisfaction scores - Regeneration rates - Post-processing usage - Enhancement effectiveness</p> <p>Cost Analysis - Spending trends and patterns - Cost per model breakdown - ROI calculations - Budget forecasting</p>"},{"location":"features/#performance-insights","title":"Performance Insights","text":"<p>Prompt Analysis - Most successful prompt patterns - Common failure reasons - Enhancement effectiveness - Trending keywords and styles</p> <p>Model Performance - Speed vs quality comparisons - Success rates by model - User preference data - Optimization recommendations</p>"},{"location":"features/#professional-user-interface","title":"\ud83c\udfa8 Professional User Interface","text":"<p>Intuitive and powerful interface designed for both beginners and professionals.</p>"},{"location":"features/#dashboard-features","title":"Dashboard Features","text":"<p>Generation Workspace - Clean, uncluttered design - Real-time preview capabilities - Drag-and-drop functionality - Keyboard shortcuts</p> <p>Gallery Management - Organized image collections - Advanced search and filtering - Batch operations - Export options</p> <p>Settings Panel - Customizable preferences - Quality presets - Workflow configurations - Account management</p>"},{"location":"features/#mobile-responsiveness","title":"Mobile Responsiveness","text":"<ul> <li>Fully responsive design</li> <li>Touch-optimized controls</li> <li>Mobile-specific features</li> <li>Cross-platform compatibility</li> </ul>"},{"location":"features/#async-processing","title":"\u26a1 Async Processing","text":"<p>Efficient handling of image generation with real-time updates and notifications.</p>"},{"location":"features/#webhook-integration","title":"Webhook Integration","text":"<p>Real-Time Notifications - Generation completion alerts - Failure notifications - Progress updates - Custom event handling</p> <p>Security Features - Signature verification - HTTPS requirements - Rate limiting - Error handling</p>"},{"location":"features/#queue-management","title":"Queue Management","text":"<p>Intelligent Queuing - Priority-based processing - Load balancing - Automatic retry logic - Status tracking</p> <p>Batch Processing - Multiple image generation - Workflow automation - Bulk operations - Progress monitoring</p>"},{"location":"features/#production-ready-architecture","title":"\ud83d\udd12 Production-Ready Architecture","text":"<p>Built for scale with enterprise-grade security and reliability.</p>"},{"location":"features/#security-features","title":"Security Features","text":"<p>Authentication &amp; Authorization - API key management - Role-based access control - Rate limiting - Input validation</p> <p>Data Protection - Encryption in transit and at rest - Secure API endpoints - Privacy compliance - Audit logging</p>"},{"location":"features/#scalability","title":"Scalability","text":"<p>Infrastructure - Microservices architecture - Container-based deployment - Auto-scaling capabilities - Load balancing</p> <p>Performance Optimization - Caching layers - CDN integration - Database optimization - Resource management</p>"},{"location":"features/#advanced-features","title":"Advanced Features","text":""},{"location":"features/#workflow-automation","title":"\ud83d\udd27 Workflow Automation","text":"<p>Pre-built workflows for common use cases and custom automation capabilities.</p>"},{"location":"features/#professional-workflows","title":"Professional Workflows","text":"<p>Headshot Generation 1. Generate base image with optimal model 2. Apply professional lighting 3. Background optimization 4. Upscale to high resolution 5. Create multiple variations</p> <p>Product Photography 1. Generate product image 2. Remove/replace background 3. Apply studio lighting 4. Multiple angle generation 5. E-commerce optimization</p> <p>Marketing Materials 1. Generate base design 2. Brand guideline application 3. Multiple format creation 4. Platform optimization 5. Batch processing</p>"},{"location":"features/#custom-workflow-builder","title":"Custom Workflow Builder","text":"<p>Visual Editor - Drag-and-drop workflow design - Conditional logic support - Parameter configuration - Testing and validation</p> <p>Integration Capabilities - API endpoint triggers - Webhook notifications - External service integration - Custom scripting support</p>"},{"location":"features/#api-integration","title":"\ud83d\udd0c API Integration","text":"<p>Comprehensive REST API for seamless integration with your applications.</p>"},{"location":"features/#developer-tools","title":"Developer Tools","text":"<p>SDKs and Libraries - Python SDK with full feature support - JavaScript/Node.js SDK - REST API documentation - Code examples and tutorials</p> <p>Testing Tools - API sandbox environment - Request/response testing - Performance monitoring - Error simulation</p>"},{"location":"features/#enterprise-features","title":"Enterprise Features","text":"<p>White-Label Solutions - Custom branding options - Domain customization - Feature configuration - Dedicated infrastructure</p> <p>SLA Guarantees - Uptime commitments - Performance benchmarks - Support response times - Escalation procedures</p>"},{"location":"features/#business-intelligence","title":"\ud83d\udcc8 Business Intelligence","text":"<p>Advanced analytics and reporting for business optimization.</p>"},{"location":"features/#revenue-analytics","title":"Revenue Analytics","text":"<p>Subscription Metrics - Customer acquisition costs - Lifetime value analysis - Churn rate tracking - Revenue forecasting</p> <p>Usage Patterns - Feature adoption rates - User engagement metrics - Geographic distribution - Device and platform analysis</p>"},{"location":"features/#optimization-insights","title":"Optimization Insights","text":"<p>Cost Efficiency - Resource utilization analysis - Cost optimization recommendations - Performance vs cost analysis - Budget allocation guidance</p> <p>Quality Improvements - User feedback analysis - Error pattern identification - Enhancement suggestions - Success factor analysis</p>"},{"location":"features/#integration-ecosystem","title":"Integration Ecosystem","text":""},{"location":"features/#third-party-integrations","title":"\ud83d\udd17 Third-Party Integrations","text":"<p>Seamless integration with popular tools and platforms.</p>"},{"location":"features/#design-tools","title":"Design Tools","text":"<p>Adobe Creative Suite - Photoshop plugin integration - Illustrator workflow support - After Effects compatibility - Creative Cloud sync</p> <p>Figma &amp; Sketch - Design system integration - Asset management - Collaborative workflows - Version control</p>"},{"location":"features/#business-platforms","title":"Business Platforms","text":"<p>E-commerce - Shopify app integration - WooCommerce plugins - Magento extensions - Amazon marketplace tools</p> <p>Content Management - WordPress plugins - Drupal modules - Contentful integration - Headless CMS support</p> <p>Marketing Automation - HubSpot integration - Salesforce connectivity - Mailchimp campaign tools - Social media scheduling</p>"},{"location":"features/#cloud-platform-support","title":"\ud83c\udf10 Cloud Platform Support","text":"<p>Deploy and scale on major cloud platforms.</p>"},{"location":"features/#supported-platforms","title":"Supported Platforms","text":"<p>Amazon Web Services (AWS) - ECS/Fargate deployment - Lambda serverless functions - S3 storage integration - CloudWatch monitoring</p> <p>Google Cloud Platform (GCP) - Cloud Run deployment - Cloud Functions integration - Cloud Storage support - Stackdriver monitoring</p> <p>Microsoft Azure - Container Instances - App Service deployment - Blob Storage integration - Application Insights</p> <p>Kubernetes - Helm chart support - Auto-scaling configurations - Service mesh integration - Monitoring stack</p>"},{"location":"features/#getting-the-most-from-features","title":"Getting the Most from Features","text":""},{"location":"features/#best-practices","title":"\ud83d\udca1 Best Practices","text":""},{"location":"features/#prompt-optimization","title":"Prompt Optimization","text":"<p>Structure Your Prompts 1. Start with the main subject 2. Add descriptive details 3. Include technical specifications 4. Specify style and mood 5. Add quality indicators</p> <p>Use Enhancement Effectively - Enable LLM optimization for complex prompts - Review enhanced prompts to learn patterns - Build a library of successful prompts - Iterate based on results</p>"},{"location":"features/#model-selection-strategy","title":"Model Selection Strategy","text":"<p>Choose Based on Use Case - Imagen3: Professional photography, portraits, products - Mystic: Artistic content, creative projects, unique styles - Flux Dev: Marketing materials, general content, presentations - Classic Fast: Quick iterations, testing, simple graphics</p> <p>Quality vs Speed Trade-offs - Use faster models for testing and iteration - Reserve premium models for final production - Consider batch processing for efficiency - Monitor usage and costs</p>"},{"location":"features/#post-processing-workflow","title":"Post-Processing Workflow","text":"<p>Layered Approach 1. Generate base image with optimal model 2. Apply necessary corrections 3. Enhance with upscaling if needed 4. Add style effects last 5. Optimize for final use case</p> <p>Quality Control - Always review results before post-processing - Use appropriate enhancement levels - Maintain original quality when possible - Test different combinations</p>"},{"location":"features/#use-case-scenarios","title":"\ud83c\udfaf Use Case Scenarios","text":""},{"location":"features/#business-applications","title":"Business Applications","text":"<p>Marketing Campaigns - Social media content creation - Ad creative generation - Brand asset development - Campaign variation testing</p> <p>Corporate Communications - Internal presentation graphics - Website imagery - Product documentation - Training materials</p> <p>E-commerce - Product photography alternatives - Lifestyle imagery creation - Category page graphics - Marketing collateral</p>"},{"location":"features/#creative-projects","title":"Creative Projects","text":"<p>Content Creation - Blog post illustrations - Video thumbnails - Podcast artwork - Newsletter graphics</p> <p>Artistic Endeavors - Concept art development - Style exploration - Creative inspiration - Portfolio development</p> <p>Education and Training - Educational illustrations - Training material graphics - Presentation visuals - Course content assets</p> <p>Ready to explore these features? Start with our Quick Start Guide or dive into the Usage Guide for detailed instructions!</p>"},{"location":"installation/","title":"Installation Guide","text":"<p>This guide will walk you through setting up the Freepik AI Orchestrator on your local machine or server.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing the Freepik AI Orchestrator, ensure you have the following prerequisites:</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.11 or higher</li> <li>Operating System: Windows 10+, macOS 10.14+, or Linux (Ubuntu 18.04+)</li> <li>Memory: Minimum 4GB RAM (8GB recommended)</li> <li>Storage: At least 2GB free disk space</li> </ul>"},{"location":"installation/#api-keys-required","title":"API Keys Required","text":"<p>You'll need the following API keys to use the platform:</p> <ol> <li>Freepik API Key - Get it from Freepik Developer Portal</li> <li>LLM API Key - One of the following:</li> <li>OpenAI API Key (recommended)</li> <li>Anthropic API Key</li> <li>Other compatible LLM provider</li> </ol>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":"<p>Choose the installation method that best fits your needs:</p> Local InstallationDocker InstallationDevelopment Setup"},{"location":"installation/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\n</code></pre>"},{"location":"installation/#step-2-create-virtual-environment","title":"Step 2: Create Virtual Environment","text":"<pre><code># Create virtual environment\npython -m venv venv\n\n# Activate virtual environment\n# On Windows:\nvenv\\Scripts\\activate\n# On macOS/Linux:\nsource venv/bin/activate\n</code></pre>"},{"location":"installation/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"installation/#step-4-set-up-environment-variables","title":"Step 4: Set Up Environment Variables","text":"<pre><code># Copy the example environment file\ncp .env.example .env\n\n# Edit the .env file with your API keys\n# Use your preferred text editor\nnano .env  # or vim .env or code .env\n</code></pre>"},{"location":"installation/#step-5-initialize-database","title":"Step 5: Initialize Database","text":"<pre><code>python -c \"from database.db import init_db; init_db()\"\n</code></pre>"},{"location":"installation/#step-6-run-the-application","title":"Step 6: Run the Application","text":"<pre><code>streamlit run app.py\n</code></pre>"},{"location":"installation/#step-1-clone-the-repository_1","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/yourusername/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\n</code></pre>"},{"location":"installation/#step-2-set-up-environment-variables","title":"Step 2: Set Up Environment Variables","text":"<pre><code>cp .env.example .env\n# Edit .env with your API keys\n</code></pre>"},{"location":"installation/#step-3-build-and-run-with-docker-compose","title":"Step 3: Build and Run with Docker Compose","text":"<pre><code>docker-compose up --build\n</code></pre> <p>The application will be available at <code>http://localhost:8501</code></p>"},{"location":"installation/#step-1-clone-and-setup","title":"Step 1: Clone and Setup","text":"<pre><code>git clone https://github.com/yourusername/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\npython -m venv venv\nsource venv/bin/activate  # or venv\\Scripts\\activate on Windows\n</code></pre>"},{"location":"installation/#step-2-install-development-dependencies","title":"Step 2: Install Development Dependencies","text":"<pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt  # Additional dev tools\n</code></pre>"},{"location":"installation/#step-3-install-pre-commit-hooks","title":"Step 3: Install Pre-commit Hooks","text":"<pre><code>pre-commit install\n</code></pre>"},{"location":"installation/#step-4-run-tests","title":"Step 4: Run Tests","text":"<pre><code>pytest tests/\n</code></pre>"},{"location":"installation/#environment-configuration","title":"Environment Configuration","text":"<p>Create a <code>.env</code> file in the project root with the following variables:</p> <pre><code># Freepik API Configuration\nFREEPIK_API_KEY=your_freepik_api_key_here\nFREEPIK_BASE_URL=https://api.freepik.com\n\n# LLM Configuration (choose one)\nOPENAI_API_KEY=your_openai_api_key_here\nANTHROPIC_API_KEY=your_anthropic_api_key_here\n\n# Application Configuration\nAPP_ENV=development\nDEBUG=true\nLOG_LEVEL=INFO\n\n# Database Configuration\nDATABASE_URL=sqlite:///freepik_orchestrator.db\n\n# Webhook Configuration (optional)\nWEBHOOK_URL=https://your-webhook-url.com/webhook\nWEBHOOK_SECRET=your_webhook_secret\n\n# UI Configuration\nSTREAMLIT_SERVER_PORT=8501\nSTREAMLIT_SERVER_ADDRESS=0.0.0.0\n</code></pre>"},{"location":"installation/#verification","title":"Verification","text":"<p>After installation, verify that everything is working correctly:</p>"},{"location":"installation/#1-check-application-startup","title":"1. Check Application Startup","text":"<p>Navigate to <code>http://localhost:8501</code> in your browser. You should see the Freepik AI Orchestrator interface.</p>"},{"location":"installation/#2-test-api-connection","title":"2. Test API Connection","text":"<p>In the application interface: 1. Try generating a simple image with a basic prompt 2. Check that the LLM optimization is working 3. Verify that images are being generated successfully</p>"},{"location":"installation/#3-run-health-check","title":"3. Run Health Check","text":"<pre><code># If running locally\ncurl http://localhost:8501/health\n\n# Should return status 200 with application info\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#common-issues","title":"Common Issues","text":""},{"location":"installation/#port-already-in-use","title":"Port Already in Use","text":"<p>If port 8501 is already in use:</p> <pre><code># Find the process using the port\nnetstat -tulpn | grep 8501\n\n# Kill the process (replace PID with actual process ID)\nkill -9 PID\n\n# Or run on a different port\nstreamlit run app.py --server.port 8502\n</code></pre>"},{"location":"installation/#api-key-issues","title":"API Key Issues","text":"<ol> <li>Freepik API Key Invalid: Verify your key at the Freepik Developer Portal</li> <li>LLM API Key Invalid: Check your OpenAI/Anthropic dashboard</li> <li>Rate Limits: Ensure you have sufficient API quota</li> </ol>"},{"location":"installation/#dependencies-issues","title":"Dependencies Issues","text":"<pre><code># Clear pip cache and reinstall\npip cache purge\npip install -r requirements.txt --force-reinstall\n</code></pre>"},{"location":"installation/#database-issues","title":"Database Issues","text":"<pre><code># Reset database\nrm freepik_orchestrator.db\npython -c \"from database.db import init_db; init_db()\"\n</code></pre>"},{"location":"installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the Troubleshooting Guide</li> <li>Search existing GitHub Issues</li> <li>Create a new issue with detailed error information</li> <li>Join our Discord Community for real-time help</li> </ol>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>Now that you have the Freepik AI Orchestrator installed:</p> <ol> <li>Configuration: Review the Configuration Guide</li> <li>Quick Start: Follow the Quick Start Tutorial</li> <li>Usage: Learn about Features and Usage</li> </ol> <p>Congratulations! You're ready to start generating amazing images with AI! \ud83c\udf89</p>"},{"location":"quickstart/","title":"Quick Start Tutorial","text":"<p>Get up and running with the Freepik AI Orchestrator in just a few minutes! This tutorial will guide you through your first image generation.</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before starting this tutorial, make sure you have:</p> <ul> <li>Completed the Installation</li> <li>Configured your API keys</li> <li>Application running at <code>http://localhost:8501</code></li> </ul>"},{"location":"quickstart/#your-first-image-generation","title":"Your First Image Generation","text":""},{"location":"quickstart/#step-1-access-the-application","title":"Step 1: Access the Application","text":"<p>Open your web browser and navigate to: <pre><code>http://localhost:8501\n</code></pre></p> <p>You should see the Freepik AI Orchestrator welcome screen.</p>"},{"location":"quickstart/#step-2-enter-a-basic-prompt","title":"Step 2: Enter a Basic Prompt","text":"<p>In the main interface:</p> <ol> <li>Locate the \"Prompt\" text area</li> <li>Enter a simple prompt like:    <pre><code>A beautiful sunset over a mountain lake\n</code></pre></li> </ol>"},{"location":"quickstart/#step-3-choose-your-model","title":"Step 3: Choose Your Model","text":"<ol> <li>Find the \"Model Selection\" dropdown</li> <li>For your first generation, choose \"Classic Fast\" (fastest option)</li> <li>Keep other settings at their defaults for now</li> </ol>"},{"location":"quickstart/#step-4-generate-your-image","title":"Step 4: Generate Your Image","text":"<ol> <li>Click the \"Generate Image\" button</li> <li>Watch as the LLM optimizes your prompt</li> <li>Wait for the image generation to complete (usually 10-30 seconds)</li> </ol>"},{"location":"quickstart/#step-5-view-your-results","title":"Step 5: View Your Results","text":"<p>Once generation is complete, you'll see:</p> <ul> <li>Original Prompt: Your input</li> <li>Optimized Prompt: LLM-enhanced version</li> <li>Generated Image: Your AI-created artwork</li> <li>Metadata: Generation details and statistics</li> </ul>"},{"location":"quickstart/#exploring-features","title":"Exploring Features","text":"<p>Now that you've generated your first image, let's explore more features:</p>"},{"location":"quickstart/#llm-prompt-optimization","title":"LLM Prompt Optimization","text":"<p>The platform automatically enhances your prompts. Try these examples:</p>"},{"location":"quickstart/#basic-prompt","title":"Basic Prompt","text":"<pre><code>dog in park\n</code></pre>"},{"location":"quickstart/#llm-optimized-result","title":"LLM-Optimized Result","text":"<pre><code>A friendly golden retriever playing in a sunny park with green grass, \ntall trees in the background, natural lighting, high quality photography, \nvibrant colors, joyful atmosphere\n</code></pre>"},{"location":"quickstart/#model-comparison","title":"Model Comparison","text":"<p>Try the same prompt with different models:</p> <ol> <li>Classic Fast: Quick results, good for testing</li> <li>Flux Dev: Balanced speed and quality</li> <li>Imagen3: High quality, slower generation</li> <li>Mystic: Artistic style, premium quality</li> </ol>"},{"location":"quickstart/#advanced-settings","title":"Advanced Settings","text":"<p>Experiment with these settings:</p>"},{"location":"quickstart/#image-dimensions","title":"Image Dimensions","text":"<ul> <li>Square: 1024x1024 (default)</li> <li>Portrait: 768x1024</li> <li>Landscape: 1024x768</li> <li>Custom: Set your own dimensions</li> </ul>"},{"location":"quickstart/#style-parameters","title":"Style Parameters","text":"<ul> <li>Artistic Style: Realistic, Artistic, Cartoon, etc.</li> <li>Color Palette: Vibrant, Muted, Monochrome</li> <li>Lighting: Natural, Dramatic, Soft</li> </ul>"},{"location":"quickstart/#post-processing","title":"Post-Processing","text":"<ul> <li>Upscaling: Increase resolution</li> <li>Background Removal: Isolate subjects</li> <li>Style Transfer: Apply artistic filters</li> </ul>"},{"location":"quickstart/#step-by-step-walkthrough","title":"Step-by-Step Walkthrough","text":"<p>Let's create a more complex image with advanced features:</p>"},{"location":"quickstart/#step-1-advanced-prompt","title":"Step 1: Advanced Prompt","text":"<pre><code>A cyberpunk city at night with neon lights\n</code></pre>"},{"location":"quickstart/#step-2-model-selection","title":"Step 2: Model Selection","text":"<p>Choose \"Imagen3\" for high quality</p>"},{"location":"quickstart/#step-3-configure-settings","title":"Step 3: Configure Settings","text":"<ul> <li>Dimensions: 1024x768 (landscape)</li> <li>Style: Sci-fi/Futuristic</li> <li>Lighting: Dramatic</li> <li>Color Palette: Vibrant neons</li> </ul>"},{"location":"quickstart/#step-4-enable-post-processing","title":"Step 4: Enable Post-Processing","text":"<ul> <li>Check \"Enhance Resolution\"</li> <li>Select \"Dramatic Lighting\" filter</li> </ul>"},{"location":"quickstart/#step-5-generate-and-review","title":"Step 5: Generate and Review","text":"<ol> <li>Click \"Generate Image\"</li> <li>Review the optimized prompt</li> <li>Examine the generated image</li> <li>Check the analytics panel</li> </ol>"},{"location":"quickstart/#understanding-the-interface","title":"Understanding the Interface","text":""},{"location":"quickstart/#main-sections","title":"Main Sections","text":""},{"location":"quickstart/#1-prompt-input-area","title":"1. Prompt Input Area","text":"<ul> <li>Text Area: Enter your image description</li> <li>Enhance Button: Manually trigger LLM optimization</li> <li>Prompt History: Access previous prompts</li> </ul>"},{"location":"quickstart/#2-model-settings-panel","title":"2. Model &amp; Settings Panel","text":"<ul> <li>Model Selector: Choose AI model</li> <li>Dimension Controls: Set image size</li> <li>Style Options: Customize appearance</li> <li>Advanced Settings: Fine-tune parameters</li> </ul>"},{"location":"quickstart/#3-generation-controls","title":"3. Generation Controls","text":"<ul> <li>Generate Button: Start image creation</li> <li>Stop Button: Cancel ongoing generation</li> <li>Queue Status: View generation progress</li> </ul>"},{"location":"quickstart/#4-results-area","title":"4. Results Area","text":"<ul> <li>Image Display: View generated images</li> <li>Metadata Panel: Generation details</li> <li>Download Options: Save images</li> <li>Share Controls: Export or share results</li> </ul>"},{"location":"quickstart/#5-analytics-dashboard","title":"5. Analytics Dashboard","text":"<ul> <li>Usage Statistics: Track your generations</li> <li>Cost Tracking: Monitor API usage</li> <li>Performance Metrics: Generation times and success rates</li> </ul>"},{"location":"quickstart/#navigation-tips","title":"Navigation Tips","text":""},{"location":"quickstart/#sidebar-menu","title":"Sidebar Menu","text":"<ul> <li>Dashboard: Main generation interface</li> <li>Gallery: View all generated images</li> <li>Analytics: Detailed statistics</li> <li>Settings: Configure preferences</li> <li>Help: Documentation and support</li> </ul>"},{"location":"quickstart/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<ul> <li><code>Ctrl + Enter</code>: Generate image</li> <li><code>Ctrl + S</code>: Save current image</li> <li><code>Ctrl + H</code>: Show/hide help panel</li> <li><code>Esc</code>: Cancel generation</li> </ul>"},{"location":"quickstart/#best-practices","title":"Best Practices","text":""},{"location":"quickstart/#writing-effective-prompts","title":"Writing Effective Prompts","text":""},{"location":"quickstart/#be-descriptive","title":"Be Descriptive","text":"<p>Good: \"A majestic white horse galloping through a field of wildflowers at sunset\" Bad: \"horse running\"</p>"},{"location":"quickstart/#include-style-information","title":"Include Style Information","text":"<p>Good: \"Portrait photo of a person, professional lighting, studio quality\" Bad: \"person photo\"</p>"},{"location":"quickstart/#specify-technical-details","title":"Specify Technical Details","text":"<p>Good: \"High resolution, 4K quality, detailed textures, photorealistic\" Bad: \"good quality\"</p>"},{"location":"quickstart/#model-selection-guide","title":"Model Selection Guide","text":""},{"location":"quickstart/#when-to-use-each-model","title":"When to Use Each Model","text":"<p>Classic Fast - Quick tests and iterations - Simple images - Development and prototyping</p> <p>Flux Dev - Balanced quality and speed - General purpose generation - Medium complexity images</p> <p>Imagen3 - High-quality results needed - Complex scenes - Final production images</p> <p>Mystic - Artistic and creative styles - Unique aesthetic requirements - Premium quality outputs</p>"},{"location":"quickstart/#optimization-tips","title":"Optimization Tips","text":""},{"location":"quickstart/#prompt-engineering","title":"Prompt Engineering","text":"<ol> <li>Start simple, then add details</li> <li>Use the LLM optimization feature</li> <li>Study the optimized prompts to learn</li> <li>Build a library of effective prompts</li> </ol>"},{"location":"quickstart/#workflow-efficiency","title":"Workflow Efficiency","text":"<ol> <li>Use prompt history for similar requests</li> <li>Save successful configurations</li> <li>Batch similar generations</li> <li>Monitor usage to optimize costs</li> </ol>"},{"location":"quickstart/#common-use-cases","title":"Common Use Cases","text":""},{"location":"quickstart/#marketing-materials","title":"Marketing Materials","text":"<pre><code>Professional product photography of a smartphone on a clean white background, \nstudio lighting, high resolution, commercial quality\n</code></pre>"},{"location":"quickstart/#social-media-content","title":"Social Media Content","text":"<pre><code>Vibrant lifestyle photo of friends having coffee in a modern caf\u00e9, \nnatural lighting, candid moment, Instagram-style\n</code></pre>"},{"location":"quickstart/#concept-art","title":"Concept Art","text":"<pre><code>Fantasy landscape with floating islands, magical waterfalls, \nethereal lighting, digital art style, highly detailed\n</code></pre>"},{"location":"quickstart/#business-presentations","title":"Business Presentations","text":"<pre><code>Modern office meeting room with diverse team collaborating, \nprofessional atmosphere, clean and minimal design\n</code></pre>"},{"location":"quickstart/#troubleshooting-quick-issues","title":"Troubleshooting Quick Issues","text":""},{"location":"quickstart/#generation-fails","title":"Generation Fails","text":"<ol> <li>Check your API key configuration</li> <li>Verify internet connection</li> <li>Try a simpler prompt</li> <li>Switch to a different model</li> </ol>"},{"location":"quickstart/#slow-performance","title":"Slow Performance","text":"<ol> <li>Use \"Classic Fast\" for testing</li> <li>Reduce image dimensions</li> <li>Simplify post-processing options</li> <li>Check server load in analytics</li> </ol>"},{"location":"quickstart/#poor-quality-results","title":"Poor Quality Results","text":"<ol> <li>Use more descriptive prompts</li> <li>Try LLM optimization</li> <li>Switch to higher-quality models</li> <li>Adjust style parameters</li> </ol>"},{"location":"quickstart/#interface-issues","title":"Interface Issues","text":"<ol> <li>Refresh the browser page</li> <li>Clear browser cache</li> <li>Try a different browser</li> <li>Check browser console for errors</li> </ol>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've successfully generated your first images with the Freepik AI Orchestrator. Here's what to explore next:</p>"},{"location":"quickstart/#learn-more","title":"Learn More","text":"<ul> <li>Detailed Usage Guide: Comprehensive feature documentation</li> <li>API Reference: Technical integration details</li> <li>Configuration: Advanced setup options</li> </ul>"},{"location":"quickstart/#advanced-features","title":"Advanced Features","text":"<ul> <li>Batch Processing: Generate multiple images at once</li> <li>Webhook Integration: Automate workflows</li> <li>Custom Models: Train and deploy your own models</li> <li>API Integration: Embed in your applications</li> </ul>"},{"location":"quickstart/#get-involved","title":"Get Involved","text":"<ul> <li>Contributing Guide: Help improve the platform</li> <li>GitHub Issues: Report bugs or request features</li> <li>Discord Community: Connect with other users</li> </ul> <p>Happy generating! \ud83c\udfa8\u2728</p>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Comprehensive troubleshooting guide for common issues with the Freepik AI Orchestrator.</p>"},{"location":"troubleshooting/#quick-diagnostics","title":"Quick Diagnostics","text":""},{"location":"troubleshooting/#system-health-check","title":"System Health Check","text":"<p>Before diving into specific issues, run these quick checks:</p> <ol> <li> <p>Application Status <pre><code>curl http://localhost:8501/health\n</code></pre></p> </li> <li> <p>API Connectivity <pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n     https://api.freepik-orchestrator.com/v1/health\n</code></pre></p> </li> <li> <p>Database Connection</p> </li> <li>Check if database is accessible</li> <li>Verify connection string</li> <li> <p>Test with simple query</p> </li> <li> <p>Environment Variables <pre><code># Check if required variables are set\necho $FREEPIK_API_KEY\necho $OPENAI_API_KEY\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"troubleshooting/#1-application-wont-start","title":"1. Application Won't Start","text":""},{"location":"troubleshooting/#issue-port-8501-already-in-use","title":"Issue: \"Port 8501 already in use\"","text":"<p>Symptoms: - Error message about port being occupied - Application fails to start - Cannot access web interface</p> <p>Solutions:</p> <p>Option A: Kill existing process <pre><code># Find process using port 8501\nnetstat -tulpn | grep 8501\n# Or on Windows\nnetstat -ano | findstr 8501\n\n# Kill the process (replace PID with actual ID)\nkill -9 PID\n# Or on Windows\ntaskkill /PID PID /F\n</code></pre></p> <p>Option B: Use different port <pre><code>streamlit run app.py --server.port 8502\n</code></pre></p> <p>Option C: Update configuration <pre><code># .streamlit/config.toml\n[server]\nport = 8502\n</code></pre></p>"},{"location":"troubleshooting/#issue-import-errors-or-module-not-found","title":"Issue: \"Import errors\" or \"Module not found\"","text":"<p>Symptoms: - Python import errors on startup - Missing module messages - Application crashes during initialization</p> <p>Solutions:</p> <ol> <li> <p>Check Python version <pre><code>python --version  # Should be 3.11+\n</code></pre></p> </li> <li> <p>Reinstall dependencies <pre><code>pip install -r requirements.txt --force-reinstall\n</code></pre></p> </li> <li> <p>Check virtual environment <pre><code># Activate virtual environment\nsource venv/bin/activate  # Linux/Mac\nvenv\\Scripts\\activate     # Windows\n\n# Verify installation\npip list\n</code></pre></p> </li> <li> <p>Clear Python cache <pre><code>find . -type d -name \"__pycache__\" -delete\nfind . -name \"*.pyc\" -delete\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#issue-environment-variables-not-found","title":"Issue: \"Environment variables not found\"","text":"<p>Symptoms: - Missing API key errors - Configuration errors - Application starts but features don't work</p> <p>Solutions:</p> <ol> <li> <p>Verify .env file exists <pre><code>ls -la .env\ncat .env  # Check contents\n</code></pre></p> </li> <li> <p>Check file format <pre><code># Correct format\nFREEPIK_API_KEY=your_key_here\nOPENAI_API_KEY=your_openai_key\n\n# Incorrect (avoid spaces around =)\nFREEPIK_API_KEY = your_key_here\n</code></pre></p> </li> <li> <p>Load environment manually <pre><code>from dotenv import load_dotenv\nload_dotenv()\nimport os\nprint(os.getenv('FREEPIK_API_KEY'))\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#2-image-generation-issues","title":"2. Image Generation Issues","text":""},{"location":"troubleshooting/#issue-generation-failed-errors","title":"Issue: \"Generation failed\" errors","text":"<p>Symptoms: - Images fail to generate - Error messages in UI - API returns 500 errors</p> <p>Diagnostic Steps:</p> <ol> <li> <p>Check API key validity <pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n     https://api.freepik.com/v1/account\n</code></pre></p> </li> <li> <p>Verify prompt content</p> </li> <li>Check for prohibited content</li> <li>Ensure prompt is not empty</li> <li> <p>Try simpler prompts</p> </li> <li> <p>Test different models</p> </li> <li>Switch from auto to specific model</li> <li>Try Classic Fast for testing</li> <li>Compare results across models</li> </ol> <p>Common Solutions:</p> <p>Invalid API Key <pre><code># Verify in Python\nimport os\nfrom core.freepik_client import FreepikClient\n\napi_key = os.getenv('FREEPIK_API_KEY')\nprint(f\"API Key: {api_key[:10]}...\")  # Show first 10 chars\n\nclient = FreepikClient(api_key)\n# Test connection\n</code></pre></p> <p>Content Policy Violations - Remove sensitive content from prompts - Avoid copyrighted material references - Use general descriptions instead of specific people</p> <p>Rate Limiting <pre><code># Add delays between requests\nimport time\ntime.sleep(2)  # Wait 2 seconds between generations\n</code></pre></p>"},{"location":"troubleshooting/#issue-poor-quality-results","title":"Issue: \"Poor quality results\"","text":"<p>Symptoms: - Generated images don't match expectations - Low quality or distorted results - Inconsistent outputs</p> <p>Optimization Strategies:</p> <ol> <li> <p>Improve prompt quality <pre><code># Poor prompt\n\"person\"\n\n# Better prompt\n\"Professional headshot of a businesswoman, confident expression, \nmodern office background, natural lighting, high resolution\"\n</code></pre></p> </li> <li> <p>Use LLM enhancement</p> </li> <li>Enable prompt optimization</li> <li>Review enhanced prompts</li> <li> <p>Learn from successful patterns</p> </li> <li> <p>Try different models</p> </li> <li>Imagen3 for photorealism</li> <li>Mystic for artistic content</li> <li> <p>Flux Dev for balanced results</p> </li> <li> <p>Adjust quality settings <pre><code>generation_params = {\n    \"quality_level\": 9,  # Higher quality (1-10)\n    \"style\": \"photorealistic\",\n    \"enhance_prompt\": True\n}\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#issue-slow-generation-times","title":"Issue: \"Slow generation times\"","text":"<p>Symptoms: - Long wait times for results - Timeouts - Poor user experience</p> <p>Solutions:</p> <ol> <li>Choose faster models</li> <li>Use Classic Fast for testing</li> <li>Reserve premium models for final output</li> <li> <p>Consider batch processing</p> </li> <li> <p>Optimize infrastructure <pre><code># docker-compose.yml\nservices:\n  app:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 4G\n</code></pre></p> </li> <li> <p>Use async processing <pre><code># Generate with webhook\nresult = client.generate_async(\n    prompt=\"Your prompt\",\n    webhook_url=\"https://your-app.com/webhook\"\n)\n</code></pre></p> </li> <li> <p>Monitor system resources <pre><code># Check CPU and memory usage\nhtop\n# Or\ndocker stats\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#3-database-issues","title":"3. Database Issues","text":""},{"location":"troubleshooting/#issue-database-connection-failed","title":"Issue: \"Database connection failed\"","text":"<p>Symptoms: - Application crashes on database access - Connection timeout errors - Data not persisting</p> <p>Diagnostic Steps:</p> <ol> <li> <p>Test database connection <pre><code># For PostgreSQL\npsql $DATABASE_URL -c \"SELECT 1;\"\n\n# For SQLite\nsqlite3 freepik_orchestrator.db \".tables\"\n</code></pre></p> </li> <li> <p>Check database URL format <pre><code># PostgreSQL\nDATABASE_URL=postgresql://user:password@host:port/database\n\n# SQLite\nDATABASE_URL=sqlite:///path/to/database.db\n</code></pre></p> </li> <li> <p>Verify database exists <pre><code>from database.db import init_db\ninit_db()  # Create tables if they don't exist\n</code></pre></p> </li> </ol> <p>Solutions:</p> <p>Connection Issues <pre><code># Test connection in Python\nimport psycopg2\nfrom sqlalchemy import create_engine\n\n# Test SQLAlchemy connection\nengine = create_engine(DATABASE_URL)\nwith engine.connect() as conn:\n    result = conn.execute(\"SELECT 1\")\n    print(result.fetchone())\n</code></pre></p> <p>Migration Issues <pre><code># Reset database (development only)\nrm freepik_orchestrator.db  # SQLite\npython -c \"from database.db import init_db; init_db()\"\n</code></pre></p> <p>Permission Issues <pre><code># Check file permissions (SQLite)\nls -la freepik_orchestrator.db\nchmod 664 freepik_orchestrator.db\n</code></pre></p>"},{"location":"troubleshooting/#issue-slow-database-queries","title":"Issue: \"Slow database queries\"","text":"<p>Symptoms: - Application responds slowly - Database timeouts - High CPU usage</p> <p>Solutions:</p> <ol> <li> <p>Add database indexes <pre><code>CREATE INDEX idx_task_id ON generations(task_id);\nCREATE INDEX idx_created_at ON generations(created_at);\n</code></pre></p> </li> <li> <p>Optimize queries <pre><code># Use pagination\nfrom sqlalchemy import desc\n\nresults = session.query(Generation)\\\n    .order_by(desc(Generation.created_at))\\\n    .limit(50)\\\n    .offset(page * 50)\n</code></pre></p> </li> <li> <p>Connection pooling <pre><code>from sqlalchemy import create_engine\n\nengine = create_engine(\n    DATABASE_URL,\n    pool_size=20,\n    max_overflow=30,\n    pool_timeout=30\n)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#4-ui-and-interface-issues","title":"4. UI and Interface Issues","text":""},{"location":"troubleshooting/#issue-streamlit-interface-not-loading","title":"Issue: \"Streamlit interface not loading\"","text":"<p>Symptoms: - Blank page or loading indefinitely - JavaScript errors in browser console - UI components not responding</p> <p>Solutions:</p> <ol> <li>Clear browser cache</li> <li>Hard refresh (Ctrl+F5)</li> <li>Clear browser cache and cookies</li> <li> <p>Try incognito/private mode</p> </li> <li> <p>Check browser compatibility</p> </li> <li>Use modern browsers (Chrome, Firefox, Safari, Edge)</li> <li>Disable browser extensions</li> <li> <p>Check for JavaScript errors in console</p> </li> <li> <p>Verify Streamlit configuration <pre><code># .streamlit/config.toml\n[server]\nenableCORS = false\nenableXsrfProtection = true\n\n[browser]\ngatherUsageStats = false\n</code></pre></p> </li> <li> <p>Restart application <pre><code># Stop application\nCtrl+C\n\n# Clear Streamlit cache\nstreamlit cache clear\n\n# Restart\nstreamlit run app.py\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#issue-ui-components-not-working","title":"Issue: \"UI components not working\"","text":"<p>Symptoms: - Buttons don't respond - Form submissions fail - State not updating</p> <p>Solutions:</p> <ol> <li> <p>Check Streamlit version <pre><code>pip show streamlit\npip install streamlit --upgrade\n</code></pre></p> </li> <li> <p>Review session state <pre><code># Debug session state\nimport streamlit as st\nst.write(st.session_state)\n</code></pre></p> </li> <li> <p>Clear session state <pre><code># Add to app\nif st.button(\"Clear Session\"):\n    for key in st.session_state.keys():\n        del st.session_state[key]\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#5-api-integration-issues","title":"5. API Integration Issues","text":""},{"location":"troubleshooting/#issue-api-requests-failing","title":"Issue: \"API requests failing\"","text":"<p>Symptoms: - 401 Unauthorized errors - 429 Rate limit errors - Connection timeouts</p> <p>Diagnostic Steps:</p> <ol> <li> <p>Test API directly <pre><code>curl -X POST \"https://api.freepik-orchestrator.com/v1/generate\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"prompt\": \"test image\"}'\n</code></pre></p> </li> <li> <p>Check API key format <pre><code># Verify API key format\nimport re\napi_key = \"your_api_key\"\nif re.match(r'^[a-zA-Z0-9_-]+$', api_key):\n    print(\"API key format looks correct\")\n</code></pre></p> </li> </ol> <p>Solutions:</p> <p>Authentication Issues <pre><code># Verify API key is being sent\nimport requests\n\nheaders = {\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n}\n\n# Log headers (remove in production)\nprint(f\"Headers: {headers}\")\n</code></pre></p> <p>Rate Limiting <pre><code># Implement exponential backoff\nimport time\nimport random\n\ndef retry_with_backoff(func, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            return func()\n        except requests.exceptions.HTTPError as e:\n            if e.response.status_code == 429:\n                delay = (2 ** attempt) + random.uniform(0, 1)\n                time.sleep(delay)\n            else:\n                raise\n</code></pre></p> <p>Connection Issues <pre><code># Add timeout and retry logic\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\nsession = requests.Session()\nretry_strategy = Retry(\n    total=3,\n    backoff_factor=1,\n    status_forcelist=[429, 500, 502, 503, 504],\n)\nadapter = HTTPAdapter(max_retries=retry_strategy)\nsession.mount(\"http://\", adapter)\nsession.mount(\"https://\", adapter)\n</code></pre></p>"},{"location":"troubleshooting/#6-webhook-issues","title":"6. Webhook Issues","text":""},{"location":"troubleshooting/#issue-webhooks-not-being-received","title":"Issue: \"Webhooks not being received\"","text":"<p>Symptoms: - No webhook notifications - Missing completion callbacks - Async operations not updating</p> <p>Diagnostic Steps:</p> <ol> <li> <p>Test webhook endpoint <pre><code># Test if your webhook URL is accessible\ncurl -X POST \"https://your-app.com/webhook\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"test\": \"data\"}'\n</code></pre></p> </li> <li> <p>Check webhook logs <pre><code># Check server logs for webhook attempts\ntail -f /var/log/nginx/access.log | grep webhook\n</code></pre></p> </li> </ol> <p>Solutions:</p> <p>URL Accessibility - Ensure webhook URL is publicly accessible - Use HTTPS (required for webhooks) - Check firewall and security group settings</p> <p>Signature Verification <pre><code>import hmac\nimport hashlib\n\ndef verify_webhook_signature(payload, signature, secret):\n    expected = hmac.new(\n        secret.encode(),\n        payload,\n        hashlib.sha256\n    ).hexdigest()\n\n    return hmac.compare_digest(f\"sha256={expected}\", signature)\n\n# In your webhook handler\nif not verify_webhook_signature(request.body, request.headers['X-Signature'], WEBHOOK_SECRET):\n    return \"Invalid signature\", 401\n</code></pre></p> <p>Webhook Handler Example <pre><code>from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\n@app.route('/webhook', methods=['POST'])\ndef handle_webhook():\n    try:\n        data = request.json\n        event_type = data.get('event')\n\n        if event_type == 'generation.completed':\n            # Handle completed generation\n            handle_generation_complete(data['data'])\n        elif event_type == 'generation.failed':\n            # Handle failed generation\n            handle_generation_failed(data['data'])\n\n        return jsonify({\"status\": \"ok\"})\n    except Exception as e:\n        print(f\"Webhook error: {e}\")\n        return jsonify({\"error\": str(e)}), 500\n</code></pre></p>"},{"location":"troubleshooting/#performance-optimization","title":"Performance Optimization","text":""},{"location":"troubleshooting/#1-slow-application-performance","title":"1. Slow Application Performance","text":"<p>Symptoms: - High response times - UI lag - Resource exhaustion</p> <p>Solutions:</p> <ol> <li> <p>Profile application <pre><code># Add performance monitoring\nimport time\nimport functools\n\ndef timing_decorator(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"{func.__name__} took {end-start:.2f} seconds\")\n        return result\n    return wrapper\n</code></pre></p> </li> <li> <p>Optimize database queries <pre><code># Use connection pooling\nfrom sqlalchemy.pool import QueuePool\n\nengine = create_engine(\n    DATABASE_URL,\n    poolclass=QueuePool,\n    pool_size=10,\n    max_overflow=20\n)\n</code></pre></p> </li> <li> <p>Implement caching <pre><code>import streamlit as st\n\n@st.cache_data\ndef expensive_computation(data):\n    # Cached function\n    return processed_data\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#2-high-memory-usage","title":"2. High Memory Usage","text":"<p>Symptoms: - Out of memory errors - System slowdowns - Container restarts</p> <p>Solutions:</p> <ol> <li> <p>Monitor memory usage <pre><code># Check memory usage\nfree -h\ndocker stats\n</code></pre></p> </li> <li> <p>Optimize image handling <pre><code>from PIL import Image\n\n# Resize images before processing\ndef optimize_image(image_path, max_size=(1024, 1024)):\n    with Image.open(image_path) as img:\n        img.thumbnail(max_size, Image.Resampling.LANCZOS)\n        return img\n</code></pre></p> </li> <li> <p>Clean up resources <pre><code># Proper resource cleanup\ntry:\n    # Process image\n    pass\nfinally:\n    # Clean up temporary files\n    if os.path.exists(temp_file):\n        os.remove(temp_file)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#error-code-reference","title":"Error Code Reference","text":""},{"location":"troubleshooting/#http-status-codes","title":"HTTP Status Codes","text":"Code Description Common Causes Solutions 400 Bad Request Invalid prompt, malformed JSON Check request format 401 Unauthorized Invalid API key Verify API key 403 Forbidden Insufficient permissions Check account status 429 Too Many Requests Rate limit exceeded Implement backoff 500 Internal Server Error Server issues Contact support"},{"location":"troubleshooting/#application-error-codes","title":"Application Error Codes","text":"Code Description Solutions <code>FREEPIK_001</code> API key invalid Update API key <code>FREEPIK_002</code> Prompt too long Shorten prompt <code>FREEPIK_003</code> Model unavailable Try different model <code>FREEPIK_004</code> Content policy violation Modify prompt <code>FREEPIK_005</code> Generation timeout Try again or use faster model"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"troubleshooting/#self-service-options","title":"Self-Service Options","text":"<ol> <li>Check System Status</li> <li>Visit status.freepik-orchestrator.com</li> <li> <p>Check for known issues</p> </li> <li> <p>Search Documentation</p> </li> <li>Use site search</li> <li>Check FAQ section</li> <li> <p>Review API documentation</p> </li> <li> <p>Community Support</p> </li> <li>GitHub Discussions</li> <li>Discord Community</li> <li>Stack Overflow (tag: freepik-orchestrator)</li> </ol>"},{"location":"troubleshooting/#contact-support","title":"Contact Support","text":"<p>Before contacting support, gather this information:</p> <ol> <li>System Information</li> <li>Operating system and version</li> <li>Python version</li> <li>Application version</li> <li> <p>Browser (if UI issue)</p> </li> <li> <p>Error Details</p> </li> <li>Complete error messages</li> <li>Steps to reproduce</li> <li>Screenshots or logs</li> <li> <p>Time when issue occurred</p> </li> <li> <p>Configuration</p> </li> <li>Environment variables (without sensitive data)</li> <li>Configuration files</li> <li>Network setup (if relevant)</li> </ol> <p>Support Channels: - Email: support@freepik-orchestrator.com - Discord: Live chat support - Enterprise: Dedicated support portal</p>"},{"location":"troubleshooting/#emergency-support","title":"Emergency Support","text":"<p>For critical production issues:</p> <ol> <li>Enterprise customers: Use priority support channel</li> <li>Include \"URGENT\" in subject line</li> <li>Provide full system impact assessment</li> <li>Include business impact statement</li> </ol> <p>Remember: Most issues can be resolved quickly with the right diagnostic information. Take time to gather details before reaching out for help.</p>"},{"location":"api/client/","title":"API Client Reference","text":"<p>This page provides comprehensive documentation for the Freepik AI Orchestrator API client libraries and usage patterns.</p>"},{"location":"api/client/#python-client","title":"Python Client","text":""},{"location":"api/client/#installation","title":"Installation","text":"<pre><code>pip install freepik-ai-orchestrator-client\n</code></pre>"},{"location":"api/client/#basic-usage","title":"Basic Usage","text":"<pre><code>from freepik_ai_orchestrator import OrchestrationClient\n\n# Initialize client\nclient = OrchestrationClient(\n    base_url=\"http://localhost:8000\",\n    api_key=\"your-api-key\"\n)\n\n# Generate content\nresponse = client.generate(\n    prompt=\"A beautiful sunset over mountains\",\n    model=\"dall-e-3\",\n    style=\"photorealistic\"\n)\n\nprint(f\"Generated image URL: {response.image_url}\")\n</code></pre>"},{"location":"api/client/#client-configuration","title":"Client Configuration","text":"<pre><code>client = OrchestrationClient(\n    base_url=\"https://your-domain.com\",\n    api_key=\"your-api-key\",\n    timeout=30,\n    max_retries=3,\n    retry_backoff=2.0\n)\n</code></pre>"},{"location":"api/client/#authentication","title":"Authentication","text":""},{"location":"api/client/#api-key-authentication","title":"API Key Authentication","text":"<pre><code>client = OrchestrationClient(\n    base_url=\"http://localhost:8000\",\n    api_key=\"sk-your-api-key-here\"\n)\n</code></pre>"},{"location":"api/client/#bearer-token-authentication","title":"Bearer Token Authentication","text":"<pre><code>client = OrchestrationClient(\n    base_url=\"http://localhost:8000\",\n    bearer_token=\"your-bearer-token\"\n)\n</code></pre>"},{"location":"api/client/#api-methods","title":"API Methods","text":""},{"location":"api/client/#content-generation","title":"Content Generation","text":""},{"location":"api/client/#generate","title":"<code>generate()</code>","text":"<p>Generate AI content using various models.</p> <pre><code>response = client.generate(\n    prompt=\"Your creative prompt\",\n    model=\"dall-e-3\",\n    style=\"photorealistic\",\n    size=\"1024x1024\",\n    quality=\"hd\",\n    metadata={\n        \"campaign\": \"summer-2024\",\n        \"brand\": \"your-brand\"\n    }\n)\n</code></pre> <p>Parameters: - <code>prompt</code> (str): The text prompt for generation - <code>model</code> (str): Model to use (dall-e-3, midjourney, stable-diffusion, etc.) - <code>style</code> (str, optional): Art style preference - <code>size</code> (str, optional): Output dimensions - <code>quality</code> (str, optional): Quality setting - <code>metadata</code> (dict, optional): Additional metadata</p> <p>Returns: - <code>GenerationResponse</code> object with image URLs, metadata, and analytics</p>"},{"location":"api/client/#generate_batch","title":"<code>generate_batch()</code>","text":"<p>Generate multiple variations or images in a single request.</p> <pre><code>responses = client.generate_batch(\n    prompts=[\"Prompt 1\", \"Prompt 2\", \"Prompt 3\"],\n    model=\"dall-e-3\",\n    batch_size=3\n)\n</code></pre>"},{"location":"api/client/#model-management","title":"Model Management","text":""},{"location":"api/client/#list_models","title":"<code>list_models()</code>","text":"<p>Get available AI models and their capabilities.</p> <pre><code>models = client.list_models()\nfor model in models:\n    print(f\"{model.name}: {model.description}\")\n</code></pre>"},{"location":"api/client/#get_model_info","title":"<code>get_model_info()</code>","text":"<p>Get detailed information about a specific model.</p> <pre><code>model_info = client.get_model_info(\"dall-e-3\")\nprint(f\"Max resolution: {model_info.max_resolution}\")\nprint(f\"Supported styles: {model_info.supported_styles}\")\n</code></pre>"},{"location":"api/client/#analytics-and-monitoring","title":"Analytics and Monitoring","text":""},{"location":"api/client/#get_usage_stats","title":"<code>get_usage_stats()</code>","text":"<p>Retrieve usage statistics and analytics.</p> <pre><code>stats = client.get_usage_stats(\n    start_date=\"2024-01-01\",\n    end_date=\"2024-01-31\"\n)\nprint(f\"Total generations: {stats.total_generations}\")\nprint(f\"Cost: ${stats.total_cost}\")\n</code></pre>"},{"location":"api/client/#get_generation_history","title":"<code>get_generation_history()</code>","text":"<p>Get history of past generations.</p> <pre><code>history = client.get_generation_history(\n    limit=50,\n    filter_by_model=\"dall-e-3\"\n)\n</code></pre>"},{"location":"api/client/#response-objects","title":"Response Objects","text":""},{"location":"api/client/#generationresponse","title":"GenerationResponse","text":"<pre><code>class GenerationResponse:\n    id: str                    # Unique generation ID\n    image_url: str            # Generated image URL\n    thumbnail_url: str        # Thumbnail URL\n    prompt: str               # Original prompt\n    model: str                # Model used\n    style: str                # Style applied\n    size: str                 # Image dimensions\n    quality: str              # Quality setting\n    metadata: dict            # Additional metadata\n    created_at: datetime      # Generation timestamp\n    processing_time: float    # Time taken to generate\n    cost: float               # Cost of generation\n</code></pre>"},{"location":"api/client/#modelinfo","title":"ModelInfo","text":"<pre><code>class ModelInfo:\n    name: str                 # Model name\n    description: str          # Model description\n    max_resolution: str       # Maximum supported resolution\n    supported_styles: list    # Available styles\n    pricing_per_image: float  # Cost per generation\n    average_time: float       # Average processing time\n</code></pre>"},{"location":"api/client/#error-handling","title":"Error Handling","text":"<pre><code>from freepik_ai_orchestrator.exceptions import (\n    OrchestrationError,\n    AuthenticationError,\n    RateLimitError,\n    ModelNotAvailableError\n)\n\ntry:\n    response = client.generate(\n        prompt=\"Beautiful landscape\",\n        model=\"dall-e-3\"\n    )\nexcept AuthenticationError:\n    print(\"Invalid API key\")\nexcept RateLimitError as e:\n    print(f\"Rate limit exceeded. Retry after: {e.retry_after}\")\nexcept ModelNotAvailableError:\n    print(\"Requested model is not available\")\nexcept OrchestrationError as e:\n    print(f\"Generation failed: {e.message}\")\n</code></pre>"},{"location":"api/client/#async-client","title":"Async Client","text":"<p>For high-throughput applications, use the async client:</p> <pre><code>import asyncio\nfrom freepik_ai_orchestrator import AsyncOrchestrationClient\n\nasync def generate_async():\n    client = AsyncOrchestrationClient(\n        base_url=\"http://localhost:8000\",\n        api_key=\"your-api-key\"\n    )\n\n    response = await client.generate(\n        prompt=\"Async generation test\",\n        model=\"dall-e-3\"\n    )\n\n    await client.close()\n    return response\n\n# Run async generation\nresponse = asyncio.run(generate_async())\n</code></pre>"},{"location":"api/client/#javascripttypescript-client","title":"JavaScript/TypeScript Client","text":""},{"location":"api/client/#installation_1","title":"Installation","text":"<pre><code>npm install @freepik/ai-orchestrator-client\n</code></pre>"},{"location":"api/client/#basic-usage_1","title":"Basic Usage","text":"<pre><code>import { OrchestrationClient } from '@freepik/ai-orchestrator-client';\n\nconst client = new OrchestrationClient({\n  baseUrl: 'http://localhost:8000',\n  apiKey: 'your-api-key'\n});\n\n// Generate content\nconst response = await client.generate({\n  prompt: 'A beautiful sunset over mountains',\n  model: 'dall-e-3',\n  style: 'photorealistic'\n});\n\nconsole.log('Generated image URL:', response.imageUrl);\n</code></pre>"},{"location":"api/client/#typescript-types","title":"TypeScript Types","text":"<pre><code>interface GenerationRequest {\n  prompt: string;\n  model: string;\n  style?: string;\n  size?: string;\n  quality?: string;\n  metadata?: Record&lt;string, any&gt;;\n}\n\ninterface GenerationResponse {\n  id: string;\n  imageUrl: string;\n  thumbnailUrl: string;\n  prompt: string;\n  model: string;\n  style: string;\n  size: string;\n  quality: string;\n  metadata: Record&lt;string, any&gt;;\n  createdAt: Date;\n  processingTime: number;\n  cost: number;\n}\n</code></pre>"},{"location":"api/client/#curl-examples","title":"cURL Examples","text":""},{"location":"api/client/#generate-image","title":"Generate Image","text":"<pre><code>curl -X POST \"http://localhost:8000/api/v1/generate\" \\\n  -H \"Authorization: Bearer your-api-key\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"prompt\": \"A beautiful sunset over mountains\",\n    \"model\": \"dall-e-3\",\n    \"style\": \"photorealistic\",\n    \"size\": \"1024x1024\"\n  }'\n</code></pre>"},{"location":"api/client/#list-models","title":"List Models","text":"<pre><code>curl -X GET \"http://localhost:8000/api/v1/models\" \\\n  -H \"Authorization: Bearer your-api-key\"\n</code></pre>"},{"location":"api/client/#get-generation-history","title":"Get Generation History","text":"<pre><code>curl -X GET \"http://localhost:8000/api/v1/generations?limit=10\" \\\n  -H \"Authorization: Bearer your-api-key\"\n</code></pre>"},{"location":"api/client/#best-practices","title":"Best Practices","text":""},{"location":"api/client/#1-connection-pooling","title":"1. Connection Pooling","text":"<p>Use connection pooling for better performance:</p> <pre><code>client = OrchestrationClient(\n    base_url=\"http://localhost:8000\",\n    api_key=\"your-api-key\",\n    max_connections=10,\n    keep_alive=True\n)\n</code></pre>"},{"location":"api/client/#2-retry-logic","title":"2. Retry Logic","text":"<p>Implement exponential backoff for retries:</p> <pre><code>import time\nimport random\n\ndef generate_with_retry(client, prompt, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            return client.generate(prompt=prompt, model=\"dall-e-3\")\n        except RateLimitError as e:\n            if attempt == max_retries - 1:\n                raise\n            wait_time = (2 ** attempt) + random.uniform(0, 1)\n            time.sleep(wait_time)\n</code></pre>"},{"location":"api/client/#3-batch-processing","title":"3. Batch Processing","text":"<p>Use batch processing for multiple generations:</p> <pre><code># Process multiple prompts efficiently\nprompts = [\"Prompt 1\", \"Prompt 2\", \"Prompt 3\"]\nresponses = client.generate_batch(prompts=prompts, model=\"dall-e-3\")\n</code></pre>"},{"location":"api/client/#4-resource-cleanup","title":"4. Resource Cleanup","text":"<p>Always clean up resources:</p> <pre><code>try:\n    response = client.generate(prompt=\"Test\", model=\"dall-e-3\")\nfinally:\n    client.close()\n</code></pre>"},{"location":"api/client/#client-libraries","title":"Client Libraries","text":"Language Package Repository Python <code>freepik-ai-orchestrator-client</code> GitHub JavaScript/TypeScript <code>@freepik/ai-orchestrator-client</code> GitHub PHP <code>freepik/ai-orchestrator-php</code> GitHub Ruby <code>freepik-ai-orchestrator</code> GitHub"},{"location":"api/client/#support","title":"Support","text":"<p>For client-specific issues: - Check the API documentation - Review troubleshooting guide - Open an issue on the respective client library repository</p>"},{"location":"api/core/","title":"Core API Reference","text":"<p>Technical reference for the core modules and classes of the Freepik AI Orchestrator.</p>"},{"location":"api/core/#core-modules","title":"Core Modules","text":""},{"location":"api/core/#corellm_orchestrator","title":"<code>core.llm_orchestrator</code>","text":"<p>The main orchestrator that handles LLM-powered prompt enhancement and model selection.</p>"},{"location":"api/core/#class-llmorchestrator","title":"Class: <code>LLMOrchestrator</code>","text":"<p>Description: Main class for orchestrating LLM interactions and prompt optimization.</p> <p>Constructor: <pre><code>LLMOrchestrator(\n    provider: str = \"openai\",\n    model: str = \"gpt-4\",\n    temperature: float = 0.7\n)\n</code></pre></p> <p>Parameters: - <code>provider</code> (str): LLM provider (\"openai\" or \"anthropic\") - <code>model</code> (str): Specific model to use - <code>temperature</code> (float): Creativity level (0.0-1.0)</p> <p>Methods:</p>"},{"location":"api/core/#enhance_promptprompt-str-str","title":"<code>enhance_prompt(prompt: str) -&gt; str</code>","text":"<p>Enhance a user prompt with LLM optimization.</p> <p>Parameters: - <code>prompt</code> (str): Original user prompt</p> <p>Returns: - <code>str</code>: Enhanced prompt with technical and artistic details</p> <p>Example: <pre><code>orchestrator = LLMOrchestrator()\nenhanced = orchestrator.enhance_prompt(\"business headshot\")\nprint(enhanced)\n# Output: \"Professional business headshot of a person, confident expression...\"\n</code></pre></p>"},{"location":"api/core/#select_optimal_modelprompt-str-requirements-dict-str","title":"<code>select_optimal_model(prompt: str, requirements: dict) -&gt; str</code>","text":"<p>Automatically select the best AI model for a given prompt.</p> <p>Parameters: - <code>prompt</code> (str): Enhanced prompt text - <code>requirements</code> (dict): Generation requirements (quality, speed, style)</p> <p>Returns: - <code>str</code>: Recommended model name</p> <p>Example: <pre><code>model = orchestrator.select_optimal_model(\n    prompt=\"Professional headshot...\",\n    requirements={\"quality\": \"high\", \"style\": \"photorealistic\"}\n)\nprint(model)  # Output: \"imagen3\"\n</code></pre></p>"},{"location":"api/core/#corefreepik_client","title":"<code>core.freepik_client</code>","text":"<p>Client for interacting with the Freepik API.</p>"},{"location":"api/core/#class-freepikclient","title":"Class: <code>FreepikClient</code>","text":"<p>Description: Handles all interactions with the Freepik API for image generation.</p> <p>Constructor: <pre><code>FreepikClient(\n    api_key: str,\n    base_url: str = \"https://api.freepik.com\",\n    timeout: int = 30\n)\n</code></pre></p> <p>Parameters: - <code>api_key</code> (str): Freepik API key - <code>base_url</code> (str): API base URL - <code>timeout</code> (int): Request timeout in seconds</p> <p>Methods:</p>"},{"location":"api/core/#generate_imageprompt-str-kwargs-dict","title":"<code>generate_image(prompt: str, **kwargs) -&gt; dict</code>","text":"<p>Generate an image using the Freepik API.</p> <p>Parameters: - <code>prompt</code> (str): Image description - <code>model</code> (str, optional): AI model to use - <code>aspect_ratio</code> (str, optional): Image dimensions - <code>quality_level</code> (int, optional): Quality setting (1-10)</p> <p>Returns: - <code>dict</code>: Generation response with task_id and status</p> <p>Example: <pre><code>client = FreepikClient(api_key=\"your_key\")\nresult = client.generate_image(\n    prompt=\"Professional headshot\",\n    model=\"imagen3\",\n    quality_level=9\n)\n</code></pre></p>"},{"location":"api/core/#get_generation_statustask_id-str-dict","title":"<code>get_generation_status(task_id: str) -&gt; dict</code>","text":"<p>Check the status of a generation task.</p> <p>Parameters: - <code>task_id</code> (str): Task identifier from generation request</p> <p>Returns: - <code>dict</code>: Task status and results</p>"},{"location":"api/core/#download_imageimage_url-str-save_path-str-str","title":"<code>download_image(image_url: str, save_path: str) -&gt; str</code>","text":"<p>Download generated image to local filesystem.</p> <p>Parameters: - <code>image_url</code> (str): URL of generated image - <code>save_path</code> (str): Local path to save image</p> <p>Returns: - <code>str</code>: Path to saved image file</p>"},{"location":"api/core/#corepost_processor","title":"<code>core.post_processor</code>","text":"<p>Post-processing utilities for image enhancement.</p>"},{"location":"api/core/#class-postprocessor","title":"Class: <code>PostProcessor</code>","text":"<p>Description: Handles image post-processing operations like upscaling and enhancement.</p> <p>Methods:</p>"},{"location":"api/core/#upscale_imageimage_path-str-scale_factor-int-2-str","title":"<code>upscale_image(image_path: str, scale_factor: int = 2) -&gt; str</code>","text":"<p>Upscale an image using AI enhancement.</p> <p>Parameters: - <code>image_path</code> (str): Path to input image - <code>scale_factor</code> (int): Scaling factor (2 or 4)</p> <p>Returns: - <code>str</code>: Path to upscaled image</p>"},{"location":"api/core/#remove_backgroundimage_path-str-str","title":"<code>remove_background(image_path: str) -&gt; str</code>","text":"<p>Remove background from an image.</p> <p>Parameters: - <code>image_path</code> (str): Path to input image</p> <p>Returns: - <code>str</code>: Path to image with removed background</p>"},{"location":"api/core/#apply_relightingimage_path-str-style-str-professional-str","title":"<code>apply_relighting(image_path: str, style: str = \"professional\") -&gt; str</code>","text":"<p>Apply lighting effects to an image.</p> <p>Parameters: - <code>image_path</code> (str): Path to input image - <code>style</code> (str): Lighting style (\"professional\", \"dramatic\", \"natural\")</p> <p>Returns: - <code>str</code>: Path to relit image</p>"},{"location":"api/core/#configuration-classes","title":"Configuration Classes","text":""},{"location":"api/core/#configsettings","title":"<code>config.settings</code>","text":""},{"location":"api/core/#class-settings","title":"Class: <code>Settings</code>","text":"<p>Description: Application configuration management using Pydantic.</p> <p>Attributes: - <code>freepik_api_key</code> (str): Freepik API key - <code>openai_api_key</code> (str, optional): OpenAI API key - <code>anthropic_api_key</code> (str, optional): Anthropic API key - <code>database_url</code> (str): Database connection string - <code>redis_url</code> (str, optional): Redis connection string - <code>environment</code> (str): Environment name (\"development\", \"production\") - <code>debug</code> (bool): Debug mode flag</p> <p>Example: <pre><code>from config.settings import Settings\n\nsettings = Settings()\nprint(settings.freepik_api_key)\n</code></pre></p>"},{"location":"api/core/#database-models","title":"Database Models","text":""},{"location":"api/core/#databasemodels","title":"<code>database.models</code>","text":""},{"location":"api/core/#class-generation","title":"Class: <code>Generation</code>","text":"<p>Description: Database model for image generation records.</p> <p>Fields: - <code>id</code> (int): Primary key - <code>task_id</code> (str): Unique task identifier - <code>user_id</code> (str): User identifier - <code>original_prompt</code> (str): User's original prompt - <code>enhanced_prompt</code> (str): LLM-enhanced prompt - <code>model_used</code> (str): AI model used for generation - <code>status</code> (str): Generation status - <code>image_url</code> (str, optional): URL of generated image - <code>created_at</code> (datetime): Creation timestamp - <code>completed_at</code> (datetime, optional): Completion timestamp</p> <p>Methods:</p>"},{"location":"api/core/#createcls-kwargs-generation","title":"<code>create(cls, **kwargs) -&gt; Generation</code>","text":"<p>Create a new generation record.</p>"},{"location":"api/core/#get_by_task_idcls-task_id-str-generation","title":"<code>get_by_task_id(cls, task_id: str) -&gt; Generation</code>","text":"<p>Retrieve generation by task ID.</p>"},{"location":"api/core/#update_statusself-status-str-kwargs-none","title":"<code>update_status(self, status: str, **kwargs) -&gt; None</code>","text":"<p>Update generation status and related fields.</p>"},{"location":"api/core/#utility-functions","title":"Utility Functions","text":""},{"location":"api/core/#utilsprompt_templates","title":"<code>utils.prompt_templates</code>","text":""},{"location":"api/core/#function-get_templatecategory-str-str","title":"Function: <code>get_template(category: str) -&gt; str</code>","text":"<p>Get a prompt template for a specific category.</p> <p>Parameters: - <code>category</code> (str): Template category (\"business\", \"artistic\", \"product\")</p> <p>Returns: - <code>str</code>: Prompt template string</p> <p>Example: <pre><code>from utils.prompt_templates import get_template\n\ntemplate = get_template(\"business\")\nprompt = template.format(subject=\"headshot\", style=\"professional\")\n</code></pre></p>"},{"location":"api/core/#utilsimage_utils","title":"<code>utils.image_utils</code>","text":""},{"location":"api/core/#function-validate_image_urlurl-str-bool","title":"Function: <code>validate_image_url(url: str) -&gt; bool</code>","text":"<p>Validate if a URL points to a valid image.</p>"},{"location":"api/core/#function-get_image_dimensionsimage_path-str-tuple","title":"Function: <code>get_image_dimensions(image_path: str) -&gt; tuple</code>","text":"<p>Get image dimensions.</p> <p>Returns: - <code>tuple</code>: (width, height) in pixels</p>"},{"location":"api/core/#function-optimize_image_sizeimage_path-str-max_size_mb-int-10-str","title":"Function: <code>optimize_image_size(image_path: str, max_size_mb: int = 10) -&gt; str</code>","text":"<p>Optimize image file size while maintaining quality.</p>"},{"location":"api/core/#error-classes","title":"Error Classes","text":""},{"location":"api/core/#exceptionsfreepikorchestratorerror","title":"<code>exceptions.FreepikOrchestratorError</code>","text":"<p>Base exception class for all application errors.</p>"},{"location":"api/core/#exceptionsapierror","title":"<code>exceptions.APIError</code>","text":"<p>Raised when API requests fail.</p> <p>Attributes: - <code>status_code</code> (int): HTTP status code - <code>error_code</code> (str): Application error code - <code>message</code> (str): Error message</p>"},{"location":"api/core/#exceptionsgenerationerror","title":"<code>exceptions.GenerationError</code>","text":"<p>Raised when image generation fails.</p>"},{"location":"api/core/#exceptionsconfigurationerror","title":"<code>exceptions.ConfigurationError</code>","text":"<p>Raised when configuration is invalid or missing.</p>"},{"location":"api/core/#usage-examples","title":"Usage Examples","text":""},{"location":"api/core/#complete-generation-workflow","title":"Complete Generation Workflow","text":"<pre><code>from core.llm_orchestrator import LLMOrchestrator\nfrom core.freepik_client import FreepikClient\nfrom core.post_processor import PostProcessor\n\n# Initialize components\norchestrator = LLMOrchestrator()\nclient = FreepikClient(api_key=\"your_key\")\nprocessor = PostProcessor()\n\n# Generate image\nprompt = \"business headshot\"\nenhanced_prompt = orchestrator.enhance_prompt(prompt)\nmodel = orchestrator.select_optimal_model(enhanced_prompt, {\"quality\": \"high\"})\n\nresult = client.generate_image(\n    prompt=enhanced_prompt,\n    model=model\n)\n\n# Wait for completion (in practice, use webhooks)\nimport time\nwhile True:\n    status = client.get_generation_status(result[\"task_id\"])\n    if status[\"status\"] == \"completed\":\n        break\n    time.sleep(5)\n\n# Download and process\nimage_path = client.download_image(\n    status[\"image_url\"], \n    \"output/generated_image.jpg\"\n)\n\n# Apply post-processing\nupscaled_path = processor.upscale_image(image_path, scale_factor=2)\nrelit_path = processor.apply_relighting(upscaled_path, style=\"professional\")\n</code></pre>"},{"location":"api/core/#async-generation-with-webhooks","title":"Async Generation with Webhooks","text":"<pre><code>import asyncio\nfrom core.llm_orchestrator import LLMOrchestrator\nfrom core.freepik_client import FreepikClient\n\nasync def generate_with_webhook():\n    orchestrator = LLMOrchestrator()\n    client = FreepikClient(api_key=\"your_key\")\n\n    enhanced_prompt = orchestrator.enhance_prompt(\"mountain landscape\")\n\n    result = client.generate_image(\n        prompt=enhanced_prompt,\n        webhook_url=\"https://your-app.com/webhook\"\n    )\n\n    print(f\"Generation started: {result['task_id']}\")\n    return result[\"task_id\"]\n\n# Webhook handler (Flask example)\nfrom flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/webhook', methods=['POST'])\ndef handle_webhook():\n    data = request.json\n    if data['event'] == 'generation.completed':\n        print(f\"Generation {data['data']['task_id']} completed!\")\n        print(f\"Image URL: {data['data']['image_url']}\")\n    return \"OK\"\n</code></pre> <p>For more detailed examples and advanced usage patterns, see the Usage Guide and API Reference.</p>"},{"location":"business/model/","title":"Business Model and Strategy","text":"<p>This document outlines the business model, value proposition, and strategic considerations for the Freepik AI Orchestrator platform.</p>"},{"location":"business/model/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Business Overview</li> <li>Value Proposition</li> <li>Target Market</li> <li>Revenue Model</li> <li>Competitive Landscape</li> <li>Business Strategy</li> <li>Market Opportunities</li> <li>Implementation Roadmap</li> <li>Success Metrics</li> <li>Risk Assessment</li> </ul>"},{"location":"business/model/#business-overview","title":"Business Overview","text":""},{"location":"business/model/#vision","title":"Vision","text":"<p>To democratize AI-powered content creation by providing a unified, intelligent orchestration platform that seamlessly integrates multiple AI models and services.</p>"},{"location":"business/model/#mission","title":"Mission","text":"<p>Empower businesses and creators to generate high-quality visual content efficiently through intelligent AI model selection, optimization, and post-processing capabilities.</p>"},{"location":"business/model/#core-value-proposition","title":"Core Value Proposition","text":"<p>Unified AI Content Generation Platform that:</p> <ul> <li>Simplifies multi-model AI integration</li> <li>Optimizes cost and performance automatically  </li> <li>Scales from individual creators to enterprise teams</li> <li>Enhances output quality through intelligent post-processing</li> <li>Provides comprehensive analytics and insights</li> </ul>"},{"location":"business/model/#value-proposition","title":"Value Proposition","text":""},{"location":"business/model/#for-individual-creators","title":"For Individual Creators","text":"<p>Problem Solved: - Complex setup and management of multiple AI services - Lack of optimization for cost and quality - Limited technical knowledge for advanced features</p> <p>Value Delivered: - One-click access to multiple AI models - Automatic cost optimization - Enhanced output quality through post-processing - Simple, intuitive interface</p> <p>Key Benefits: - Time Savings: 70% reduction in setup and management time - Cost Efficiency: 40% lower costs through intelligent routing - Quality Enhancement: 25% better output through post-processing - Ease of Use: No technical expertise required</p>"},{"location":"business/model/#for-small-to-medium-businesses","title":"For Small to Medium Businesses","text":"<p>Problem Solved: - Resource constraints for AI implementation - Need for scalable content generation - Lack of AI expertise in-house - Integration complexity with existing workflows</p> <p>Value Delivered: - Scalable AI content generation infrastructure - Team collaboration features - API integration capabilities - Usage analytics and cost management</p> <p>Key Benefits: - Scalability: Support for 10-100 team members - Integration: API-first architecture for workflow integration - Cost Control: Detailed usage tracking and budgeting - Team Productivity: Collaborative content creation workflows</p>"},{"location":"business/model/#for-enterprise-customers","title":"For Enterprise Customers","text":"<p>Problem Solved: - Enterprise-grade security and compliance requirements - Need for custom model training and deployment - Integration with existing enterprise systems - Governance and audit requirements</p> <p>Value Delivered: - Enterprise security and compliance features - Custom model deployment capabilities - SSO and RBAC integration - Comprehensive audit trails and reporting</p> <p>Key Benefits: - Security: SOC 2, GDPR, and enterprise compliance - Customization: Custom model training and deployment - Integration: Enterprise system integration (CRM, DAM, etc.) - Governance: Complete audit trails and access controls</p>"},{"location":"business/model/#target-market","title":"Target Market","text":""},{"location":"business/model/#primary-segments","title":"Primary Segments","text":""},{"location":"business/model/#1-digital-marketing-agencies","title":"1. Digital Marketing Agencies","text":"<p>Market Size: $37.8B (Digital Marketing Market) Target Characteristics: - 10-500 employees - High content generation needs - Multiple client management - Performance-driven culture</p> <p>Use Cases: - Social media content creation - Ad creative generation - Campaign asset development - Client presentation materials</p> <p>Value Drivers: - Increased client capacity - Faster campaign delivery - Improved creative quality - Better profit margins</p>"},{"location":"business/model/#2-e-commerce-companies","title":"2. E-commerce Companies","text":"<p>Market Size: $26.7T (Global E-commerce Market) Target Characteristics: - Product catalog management - Marketing content needs - Seasonal campaigns - Multiple sales channels</p> <p>Use Cases: - Product photography enhancement - Marketing banner creation - Social media content - Seasonal campaign assets</p> <p>Value Drivers: - Reduced photography costs - Faster time-to-market - Improved conversion rates - Scalable content production</p>"},{"location":"business/model/#3-media-and-entertainment","title":"3. Media and Entertainment","text":"<p>Market Size: $2.3T (Global Media Market) Target Characteristics: - Content creation companies - Publishers and media houses - Streaming platforms - Game development studios</p> <p>Use Cases: - Concept art generation - Marketing materials - Storyboard creation - Asset development</p> <p>Value Drivers: - Accelerated creative process - Cost reduction in pre-production - Enhanced creative possibilities - Faster iteration cycles</p>"},{"location":"business/model/#secondary-segments","title":"Secondary Segments","text":""},{"location":"business/model/#1-educational-institutions","title":"1. Educational Institutions","text":"<p>Use Cases: - Educational material creation - Research visualization - Student project support - Course content development</p>"},{"location":"business/model/#2-non-profit-organizations","title":"2. Non-Profit Organizations","text":"<p>Use Cases: - Campaign materials - Awareness content - Event marketing - Fundraising assets</p>"},{"location":"business/model/#3-healthcare-organizations","title":"3. Healthcare Organizations","text":"<p>Use Cases: - Patient education materials - Medical illustration - Training content - Public health campaigns</p>"},{"location":"business/model/#revenue-model","title":"Revenue Model","text":""},{"location":"business/model/#pricing-strategy","title":"Pricing Strategy","text":""},{"location":"business/model/#freemium-model","title":"Freemium Model","text":"<p>Free Tier: - 50 generations per month - Basic models (DALL-E 2, Stable Diffusion) - Standard quality - Community support</p> <p>Pro Tier ($29/month): - 500 generations per month - Premium models (DALL-E 3, Midjourney) - High-quality outputs - Priority support - Basic analytics</p> <p>Business Tier ($99/month): - 2,000 generations per month - All available models - Team collaboration (up to 10 users) - Advanced analytics - API access - Email support</p> <p>Enterprise Tier (Custom pricing): - Unlimited generations - Custom model deployment - Enterprise security features - Dedicated support - SLA guarantees - Custom integrations</p>"},{"location":"business/model/#revenue-streams","title":"Revenue Streams","text":""},{"location":"business/model/#1-subscription-revenue-primary","title":"1. Subscription Revenue (Primary)","text":"<p>Projected Split: - Free: 70% of users (conversion funnel) - Pro: 25% of paid users - Business: 60% of paid users - Enterprise: 15% of paid users</p> <p>Expected Metrics: - Average Revenue Per User (ARPU): $65/month - Customer Lifetime Value (CLV): $2,340 - Churn Rate: &lt;5% monthly</p>"},{"location":"business/model/#2-usage-based-revenue","title":"2. Usage-Based Revenue","text":"<p>Pay-per-Generation: - Overage charges beyond plan limits - Premium model access - High-resolution outputs - Rush processing fees</p> <p>API Revenue: - Per-call pricing for API usage - Volume discounts for high usage - Developer program revenue share</p>"},{"location":"business/model/#3-enterprise-services","title":"3. Enterprise Services","text":"<p>Professional Services: - Custom model training: $50,000-$200,000 - Integration consulting: $150-$300/hour - Training and workshops: $5,000-$25,000</p> <p>Support Services: - Dedicated support: $2,000-$10,000/month - SLA agreements: 20-50% premium - Priority processing: $0.10-$0.50 per generation</p>"},{"location":"business/model/#4-marketplace-revenue","title":"4. Marketplace Revenue","text":"<p>Model Marketplace: - Revenue share from third-party models (30%) - Premium model licensing - Custom style marketplace</p> <p>Template and Asset Store: - Revenue share from creators (30%) - Exclusive content licensing - Brand partnership revenue</p>"},{"location":"business/model/#financial-projections","title":"Financial Projections","text":""},{"location":"business/model/#year-1","title":"Year 1","text":"<ul> <li>Revenue: $2.5M</li> <li>Users: 100,000 (5,000 paid)</li> <li>ARPU: $65/month</li> <li>Growth Rate: 15% MoM</li> </ul>"},{"location":"business/model/#year-2","title":"Year 2","text":"<ul> <li>Revenue: $12M</li> <li>Users: 500,000 (25,000 paid)</li> <li>ARPU: $72/month</li> <li>Growth Rate: 10% MoM</li> </ul>"},{"location":"business/model/#year-3","title":"Year 3","text":"<ul> <li>Revenue: $45M</li> <li>Users: 1,500,000 (75,000 paid)</li> <li>ARPU: $85/month</li> <li>Growth Rate: 8% MoM</li> </ul>"},{"location":"business/model/#competitive-landscape","title":"Competitive Landscape","text":""},{"location":"business/model/#direct-competitors","title":"Direct Competitors","text":""},{"location":"business/model/#1-individual-ai-platforms","title":"1. Individual AI Platforms","text":"<p>OpenAI (DALL-E) - Strengths: Advanced models, brand recognition - Weaknesses: Limited integration, high costs - Market Position: Premium AI provider</p> <p>Midjourney - Strengths: High-quality artistic outputs - Weaknesses: Discord-only interface, limited automation - Market Position: Artist-focused platform</p> <p>Stability AI - Strengths: Open-source models, cost-effective - Weaknesses: Technical complexity, limited support - Market Position: Developer-focused platform</p>"},{"location":"business/model/#2-content-creation-platforms","title":"2. Content Creation Platforms","text":"<p>Canva - Strengths: Ease of use, large user base - Weaknesses: Limited AI capabilities - Market Position: Design platform adding AI</p> <p>Adobe Creative Cloud - Strengths: Professional tools, enterprise adoption - Weaknesses: High complexity, cost - Market Position: Professional creative suite</p> <p>Figma - Strengths: Collaboration features, web-based - Weaknesses: Limited AI integration - Market Position: Design collaboration platform</p>"},{"location":"business/model/#competitive-advantages","title":"Competitive Advantages","text":""},{"location":"business/model/#1-multi-model-orchestration","title":"1. Multi-Model Orchestration","text":"<p>Unique Value: - Single interface for multiple AI models - Intelligent model selection and routing - Cost optimization across providers</p> <p>Barrier to Entry: - Complex integration requirements - Vendor relationship management - Technical expertise needed</p>"},{"location":"business/model/#2-intelligent-post-processing","title":"2. Intelligent Post-Processing","text":"<p>Unique Value: - Automatic quality enhancement - Style consistency across generations - Brand guideline compliance</p> <p>Barrier to Entry: - Advanced computer vision expertise - Large training datasets required - Continuous model improvement needed</p>"},{"location":"business/model/#3-business-intelligence","title":"3. Business Intelligence","text":"<p>Unique Value: - Comprehensive usage analytics - Cost optimization insights - Performance benchmarking</p> <p>Barrier to Entry: - Data science expertise required - Large-scale data processing infrastructure - Business intelligence domain knowledge</p>"},{"location":"business/model/#business-strategy","title":"Business Strategy","text":""},{"location":"business/model/#go-to-market-strategy","title":"Go-to-Market Strategy","text":""},{"location":"business/model/#phase-1-product-market-fit-months-1-6","title":"Phase 1: Product-Market Fit (Months 1-6)","text":"<p>Objectives: - Validate core value proposition - Achieve 1,000 active users - Optimize user onboarding - Gather product feedback</p> <p>Tactics: - Launch beta program with select users - Content marketing and SEO - Product Hunt and tech community launches - Direct outreach to target segments</p> <p>Success Metrics: - User retention &gt; 60% at 30 days - Net Promoter Score &gt; 50 - Product-market fit score &gt; 40%</p>"},{"location":"business/model/#phase-2-growth-and-scale-months-7-18","title":"Phase 2: Growth and Scale (Months 7-18)","text":"<p>Objectives: - Scale to 50,000 users - Launch paid tiers - Expand feature set - Build partner ecosystem</p> <p>Tactics: - Performance marketing (Google, Facebook) - Partnership with design tools - Influencer and creator programs - Enterprise sales development</p> <p>Success Metrics: - Monthly recurring revenue &gt; $500K - Customer acquisition cost &lt; $50 - Monthly growth rate &gt; 20%</p>"},{"location":"business/model/#phase-3-market-leadership-months-19-36","title":"Phase 3: Market Leadership (Months 19-36)","text":"<p>Objectives: - Achieve market leadership position - International expansion - Enterprise focus - Strategic acquisitions</p> <p>Tactics: - International market expansion - Enterprise sales team - Strategic partnerships - Acquisition of complementary technologies</p> <p>Success Metrics: - Annual recurring revenue &gt; $20M - Market share &gt; 15% - Enterprise customers &gt; 100</p>"},{"location":"business/model/#strategic-partnerships","title":"Strategic Partnerships","text":""},{"location":"business/model/#technology-partners","title":"Technology Partners","text":"<p>AI Model Providers: - Revenue sharing agreements - Early access to new models - Co-development opportunities</p> <p>Cloud Infrastructure: - Preferred pricing agreements - Technical integration support - Joint go-to-market initiatives</p> <p>Integration Partners: - API partnerships with design tools - Workflow automation platforms - Enterprise software vendors</p>"},{"location":"business/model/#channel-partners","title":"Channel Partners","text":"<p>Agencies and Consultants: - Partner program with revenue sharing - Training and certification programs - Co-marketing opportunities</p> <p>System Integrators: - Enterprise implementation partnerships - Technical training programs - Joint solution development</p>"},{"location":"business/model/#international-expansion","title":"International Expansion","text":""},{"location":"business/model/#phase-1-english-speaking-markets","title":"Phase 1: English-Speaking Markets","text":"<ul> <li>United Kingdom</li> <li>Australia</li> <li>Canada</li> </ul>"},{"location":"business/model/#phase-2-european-markets","title":"Phase 2: European Markets","text":"<ul> <li>Germany</li> <li>France</li> <li>Netherlands</li> </ul>"},{"location":"business/model/#phase-3-emerging-markets","title":"Phase 3: Emerging Markets","text":"<ul> <li>India</li> <li>Brazil</li> <li>Southeast Asia</li> </ul>"},{"location":"business/model/#market-opportunities","title":"Market Opportunities","text":""},{"location":"business/model/#emerging-trends","title":"Emerging Trends","text":""},{"location":"business/model/#1-ai-democratization","title":"1. AI Democratization","text":"<p>Opportunity: Growing demand for accessible AI tools Market Impact: 10x increase in AI adoption among SMBs Our Position: Leading accessible AI platform</p>"},{"location":"business/model/#2-remote-work-growth","title":"2. Remote Work Growth","text":"<p>Opportunity: Increased need for digital content creation Market Impact: 40% growth in content creation tools Our Position: Cloud-first collaboration platform</p>"},{"location":"business/model/#3-personalization-at-scale","title":"3. Personalization at Scale","text":"<p>Opportunity: Demand for personalized content Market Impact: $1.8T personalization market Our Position: AI-powered personalization engine</p>"},{"location":"business/model/#4-sustainable-content-creation","title":"4. Sustainable Content Creation","text":"<p>Opportunity: Eco-friendly content production Market Impact: Reduced physical asset creation Our Position: Digital-first content generation</p>"},{"location":"business/model/#adjacent-markets","title":"Adjacent Markets","text":""},{"location":"business/model/#1-video-generation","title":"1. Video Generation","text":"<p>Market Size: $15B (Video Content Market) Entry Strategy: Partnership with video AI providers Timeline: Year 2-3</p>"},{"location":"business/model/#2-voice-and-audio","title":"2. Voice and Audio","text":"<p>Market Size: $8B (Audio Content Market) Entry Strategy: Acquisition or licensing Timeline: Year 3-4</p>"},{"location":"business/model/#3-3d-and-arvr","title":"3. 3D and AR/VR","text":"<p>Market Size: $31B (AR/VR Market) Entry Strategy: Technology partnership Timeline: Year 2-4</p>"},{"location":"business/model/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"business/model/#technical-roadmap","title":"Technical Roadmap","text":""},{"location":"business/model/#q1-2024-foundation","title":"Q1 2024: Foundation","text":"<ul> <li> Core orchestration platform</li> <li> Basic model integrations (3-5 models)</li> <li> Simple web interface</li> <li> User authentication and billing</li> </ul>"},{"location":"business/model/#q2-2024-enhancement","title":"Q2 2024: Enhancement","text":"<ul> <li> Advanced post-processing</li> <li> Team collaboration features</li> <li> API launch</li> <li> Mobile responsiveness</li> </ul>"},{"location":"business/model/#q3-2024-intelligence","title":"Q3 2024: Intelligence","text":"<ul> <li> Intelligent model selection</li> <li> Analytics dashboard</li> <li> Workflow automation</li> <li> Enterprise security features</li> </ul>"},{"location":"business/model/#q4-2024-scale","title":"Q4 2024: Scale","text":"<ul> <li> Advanced enterprise features</li> <li> International deployment</li> <li> Performance optimizations</li> <li> Advanced integrations</li> </ul>"},{"location":"business/model/#business-roadmap","title":"Business Roadmap","text":""},{"location":"business/model/#q1-2024-launch","title":"Q1 2024: Launch","text":"<ul> <li> Beta customer acquisition</li> <li> Pricing model validation</li> <li> Initial fundraising</li> <li> Team expansion (5-10 people)</li> </ul>"},{"location":"business/model/#q2-2024-growth","title":"Q2 2024: Growth","text":"<ul> <li> Public launch</li> <li> Marketing campaign execution</li> <li> Partnership development</li> <li> Series A preparation</li> </ul>"},{"location":"business/model/#q3-2024-scale","title":"Q3 2024: Scale","text":"<ul> <li> Enterprise sales launch</li> <li> International expansion planning</li> <li> Strategic partnerships</li> <li> Series A funding</li> </ul>"},{"location":"business/model/#q4-2024-leadership","title":"Q4 2024: Leadership","text":"<ul> <li> Market leadership position</li> <li> Acquisition strategy</li> <li> IPO preparation</li> <li> Global expansion</li> </ul>"},{"location":"business/model/#success-metrics","title":"Success Metrics","text":""},{"location":"business/model/#key-performance-indicators-kpis","title":"Key Performance Indicators (KPIs)","text":""},{"location":"business/model/#growth-metrics","title":"Growth Metrics","text":"<ul> <li>Monthly Active Users (MAU): Target 100K by end of Year 1</li> <li>Monthly Recurring Revenue (MRR): Target $2M by end of Year 1</li> <li>Customer Acquisition Cost (CAC): Target &lt;$50 for self-serve</li> <li>Lifetime Value (LTV): Target &gt;$2,000 average</li> <li>LTV/CAC Ratio: Target &gt;3:1</li> </ul>"},{"location":"business/model/#product-metrics","title":"Product Metrics","text":"<ul> <li>User Retention: &gt;70% at 30 days, &gt;40% at 90 days</li> <li>Feature Adoption: &gt;80% use core features within 7 days</li> <li>Generation Success Rate: &gt;95% successful generations</li> <li>Average Session Length: &gt;15 minutes</li> <li>Net Promoter Score (NPS): Target &gt;50</li> </ul>"},{"location":"business/model/#business-metrics","title":"Business Metrics","text":"<ul> <li>Revenue Growth: &gt;20% month-over-month</li> <li>Gross Margin: &gt;70% for SaaS revenue</li> <li>Churn Rate: &lt;5% monthly for paid customers</li> <li>Expansion Revenue: &gt;120% net revenue retention</li> <li>Market Share: &gt;10% in target segments</li> </ul>"},{"location":"business/model/#operational-metrics","title":"Operational Metrics","text":""},{"location":"business/model/#technical-performance","title":"Technical Performance","text":"<ul> <li>System Uptime: &gt;99.9% availability</li> <li>Response Time: &lt;2 seconds average</li> <li>Generation Speed: &lt;30 seconds average</li> <li>Error Rate: &lt;1% of requests</li> <li>Scalability: Support 10,000 concurrent users</li> </ul>"},{"location":"business/model/#customer-success","title":"Customer Success","text":"<ul> <li>Support Response Time: &lt;4 hours for paid customers</li> <li>Resolution Time: &lt;24 hours for critical issues</li> <li>Customer Satisfaction: &gt;4.5/5.0 rating</li> <li>Onboarding Completion: &gt;80% complete setup</li> <li>Training Effectiveness: &gt;90% feature adoption post-training</li> </ul>"},{"location":"business/model/#risk-assessment","title":"Risk Assessment","text":""},{"location":"business/model/#technology-risks","title":"Technology Risks","text":""},{"location":"business/model/#model-dependency-risk","title":"Model Dependency Risk","text":"<p>Risk: Over-reliance on third-party AI models Mitigation:  - Diversified model portfolio - Strategic partnerships - Custom model development capability</p>"},{"location":"business/model/#performance-risk","title":"Performance Risk","text":"<p>Risk: System performance under high load Mitigation: - Robust infrastructure architecture - Performance testing and monitoring - Auto-scaling capabilities</p>"},{"location":"business/model/#security-risk","title":"Security Risk","text":"<p>Risk: Data breaches or unauthorized access Mitigation: - Enterprise-grade security measures - Regular security audits - Compliance certifications</p>"},{"location":"business/model/#market-risks","title":"Market Risks","text":""},{"location":"business/model/#competition-risk","title":"Competition Risk","text":"<p>Risk: Large tech companies entering market Mitigation: - Strong differentiation strategy - Strategic partnerships - Rapid innovation cycle</p>"},{"location":"business/model/#economic-risk","title":"Economic Risk","text":"<p>Risk: Economic downturn affecting customer spending Mitigation: - Diverse customer base - Multiple pricing tiers - Cost optimization focus</p>"},{"location":"business/model/#regulatory-risk","title":"Regulatory Risk","text":"<p>Risk: AI regulation affecting operations Mitigation: - Proactive compliance strategy - Industry engagement - Flexible architecture</p>"},{"location":"business/model/#business-risks","title":"Business Risks","text":""},{"location":"business/model/#talent-risk","title":"Talent Risk","text":"<p>Risk: Difficulty hiring and retaining key talent Mitigation: - Competitive compensation packages - Strong company culture - Remote work flexibility</p>"},{"location":"business/model/#funding-risk","title":"Funding Risk","text":"<p>Risk: Inability to raise sufficient capital Mitigation: - Strong revenue growth - Multiple funding sources - Capital efficiency focus</p>"},{"location":"business/model/#execution-risk","title":"Execution Risk","text":"<p>Risk: Failure to execute on strategic plan Mitigation: - Experienced leadership team - Clear accountability structures - Regular performance reviews</p> <p>This comprehensive business model provides a framework for building and scaling the Freepik AI Orchestrator into a market-leading platform while managing risks and maximizing opportunities in the rapidly growing AI content generation market.</p>"},{"location":"business/pricing/","title":"Pricing Structure and Plans","text":"<p>This document details the comprehensive pricing strategy, plans, and billing structure for the Freepik AI Orchestrator platform.</p>"},{"location":"business/pricing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Pricing Philosophy</li> <li>Pricing Plans</li> <li>Usage-Based Pricing</li> <li>Enterprise Pricing</li> <li>Add-On Services</li> <li>Billing and Payment</li> <li>Pricing Calculator</li> <li>Migration and Upgrades</li> <li>Regional Pricing</li> <li>Educational and Non-Profit Discounts</li> </ul>"},{"location":"business/pricing/#pricing-philosophy","title":"Pricing Philosophy","text":""},{"location":"business/pricing/#value-based-pricing","title":"Value-Based Pricing","text":"<p>Our pricing is designed to align with the value delivered to customers:</p> <ul> <li>Transparent: Clear, predictable pricing structure</li> <li>Scalable: Plans grow with customer needs</li> <li>Fair: Pay for what you use model</li> <li>Accessible: Entry-level options for all users</li> <li>Flexible: Multiple billing options and add-ons</li> </ul>"},{"location":"business/pricing/#pricing-principles","title":"Pricing Principles","text":"<ol> <li>Value Alignment: Price reflects delivered value</li> <li>Usage Transparency: Clear usage tracking and billing</li> <li>Growth Friendly: Pricing encourages platform adoption</li> <li>Customer Success: Pricing supports customer growth</li> <li>Market Competitive: Competitive with alternatives</li> </ol>"},{"location":"business/pricing/#pricing-plans","title":"Pricing Plans","text":""},{"location":"business/pricing/#free-plan-creator","title":"Free Plan - \"Creator\"","text":"<p>Price: $0/month</p> <p>Ideal For: Individual creators, students, hobby projects</p> <p>Features:</p> <ul> <li>50 AI generations per month</li> <li>Access to basic models (DALL-E 2, Stable Diffusion)</li> <li>Standard quality outputs (512x512, 1024x1024)</li> <li>Basic post-processing</li> <li>Community support</li> <li>Freepik watermark on outputs</li> <li>Personal use license</li> </ul> <p>Limitations:</p> <ul> <li>No commercial use</li> <li>Standard processing priority</li> <li>Limited model selection</li> <li>No API access</li> <li>No team features</li> </ul> <p>Value Proposition: Free way to explore AI content generation</p>"},{"location":"business/pricing/#starter-plan-pro-creator","title":"Starter Plan - \"Pro Creator\"","text":"<p>Price: $19/month (billed monthly) or $190/year (save 17%)</p> <p>Ideal For: Freelancers, small businesses, content creators</p> <p>Features:</p> <ul> <li>300 AI generations per month</li> <li>Access to premium models (DALL-E 3, Midjourney)</li> <li>High-quality outputs (up to 2048x2048)</li> <li>Advanced post-processing options</li> <li>Email support (48-hour response)</li> <li>No watermarks</li> <li>Commercial use license</li> <li>Basic usage analytics</li> </ul> <p>Included Add-ons:</p> <ul> <li>10 high-resolution upscales</li> <li>5 style transfer operations</li> <li>2 custom style training sessions</li> </ul> <p>Value Proposition: Professional-grade AI generation for individual creators</p>"},{"location":"business/pricing/#professional-plan-business","title":"Professional Plan - \"Business\"","text":"<p>Price: $79/month (billed monthly) or $790/year (save 17%)</p> <p>Ideal For: Growing businesses, marketing teams, agencies</p> <p>Features:</p> <ul> <li>1,500 AI generations per month</li> <li>Access to all available models</li> <li>Ultra-high quality outputs (up to 4096x4096)</li> <li>Advanced post-processing suite</li> <li>Priority support (24-hour response)</li> <li>Team collaboration (up to 5 users)</li> <li>Basic API access (1,000 calls/month)</li> <li>Advanced analytics and insights</li> <li>Brand consistency tools</li> <li>Batch processing</li> </ul> <p>Included Add-ons:</p> <ul> <li>50 high-resolution upscales</li> <li>25 style transfer operations</li> <li>10 custom style training sessions</li> <li>5 GB cloud storage</li> </ul> <p>Value Proposition: Complete AI content creation solution for business teams</p>"},{"location":"business/pricing/#business-plan-team","title":"Business Plan - \"Team\"","text":"<p>Price: $199/month (billed monthly) or $1,990/year (save 17%)</p> <p>Ideal For: Medium businesses, marketing departments, design agencies</p> <p>Features:</p> <ul> <li>5,000 AI generations per month</li> <li>Access to all models including beta releases</li> <li>Premium quality outputs (up to 8192x8192)</li> <li>Complete post-processing suite</li> <li>Priority support (12-hour response)</li> <li>Team collaboration (up to 25 users)</li> <li>Full API access (10,000 calls/month)</li> <li>Advanced analytics and reporting</li> <li>Brand management system</li> <li>Workflow automation</li> <li>Integration marketplace access</li> <li>Custom templates library</li> </ul> <p>Included Add-ons:</p> <ul> <li>200 high-resolution upscales</li> <li>100 style transfer operations</li> <li>50 custom style training sessions</li> <li>50 GB cloud storage</li> <li>White-label options</li> </ul> <p>Value Proposition: Comprehensive platform for business content creation at scale</p>"},{"location":"business/pricing/#enterprise-plan-custom","title":"Enterprise Plan - \"Custom\"","text":"<p>Price: Custom pricing starting at $999/month</p> <p>Ideal For: Large enterprises, corporations, agencies with high volume needs</p> <p>Features:</p> <ul> <li>Unlimited AI generations</li> <li>Early access to new models</li> <li>Custom model deployment</li> <li>Dedicated infrastructure</li> <li>24/7 phone and email support</li> <li>Unlimited team members</li> <li>Unlimited API access</li> <li>Custom analytics and reporting</li> <li>Advanced security features (SSO, RBAC)</li> <li>Dedicated customer success manager</li> <li>Custom integrations</li> <li>On-premise deployment options</li> <li>Service level agreements (SLA)</li> </ul> <p>Included Services:</p> <ul> <li>Custom onboarding and training</li> <li>Dedicated technical support</li> <li>Regular business reviews</li> <li>Custom feature development</li> <li>Priority feature requests</li> <li>Data export capabilities</li> </ul> <p>Value Proposition: Enterprise-grade AI platform with complete customization</p>"},{"location":"business/pricing/#usage-based-pricing","title":"Usage-Based Pricing","text":""},{"location":"business/pricing/#overage-pricing","title":"Overage Pricing","text":"<p>When monthly limits are exceeded:</p> Plan Overage Rate Free Not available (upgrade required) Starter $0.10 per generation Professional $0.08 per generation Business $0.06 per generation Enterprise $0.04 per generation"},{"location":"business/pricing/#pay-as-you-go-option","title":"Pay-As-You-Go Option","text":"<p>For users who prefer usage-based pricing:</p> <p>Base Rate: $0.15 per generation Volume Discounts:</p> <ul> <li>1,000+ generations: $0.12 per generation</li> <li>5,000+ generations: $0.10 per generation</li> <li>10,000+ generations: $0.08 per generation</li> <li>25,000+ generations: $0.06 per generation</li> </ul>"},{"location":"business/pricing/#model-specific-pricing","title":"Model-Specific Pricing","text":"<p>Different models have different costs:</p> Model Free/Starter Professional+ DALL-E 2 1 credit 1 credit Stable Diffusion 1 credit 1 credit DALL-E 3 2 credits 1.5 credits Midjourney 3 credits 2 credits Custom Models 4 credits 3 credits"},{"location":"business/pricing/#enterprise-pricing","title":"Enterprise Pricing","text":""},{"location":"business/pricing/#custom-pricing-factors","title":"Custom Pricing Factors","text":"<p>Enterprise pricing is determined by:</p> <ol> <li>Usage Volume: Expected monthly generations</li> <li>User Count: Number of team members</li> <li>Features Required: Specific enterprise features needed</li> <li>Support Level: Required support and SLA</li> <li>Infrastructure: Cloud, hybrid, or on-premise deployment</li> <li>Integration Complexity: Custom integrations required</li> <li>Contract Length: Annual, multi-year discounts available</li> </ol>"},{"location":"business/pricing/#sample-enterprise-pricing","title":"Sample Enterprise Pricing","text":"Users Monthly Generations Annual Price 25-50 10,000-25,000 $12,000-$24,000 50-100 25,000-50,000 $24,000-$48,000 100-250 50,000-100,000 $48,000-$90,000 250+ 100,000+ Custom quote"},{"location":"business/pricing/#enterprise-add-ons","title":"Enterprise Add-Ons","text":"Service Annual Price Dedicated Support Engineer $50,000 Custom Model Training $25,000-$100,000 On-Premise Deployment $100,000-$500,000 Advanced Security Package $25,000 Custom Integration Development $150-$300/hour"},{"location":"business/pricing/#add-on-services","title":"Add-On Services","text":""},{"location":"business/pricing/#quality-enhancement","title":"Quality Enhancement","text":"<p>High-Resolution Upscaling</p> <ul> <li>Starter: $0.50 per upscale</li> <li>Professional: $0.40 per upscale</li> <li>Business: $0.30 per upscale</li> </ul> <p>Style Transfer</p> <ul> <li>Starter: $1.00 per transfer</li> <li>Professional: $0.80 per transfer</li> <li>Business: $0.60 per transfer</li> </ul>"},{"location":"business/pricing/#custom-training","title":"Custom Training","text":"<p>Custom Style Training</p> <ul> <li>Basic style (1-10 examples): $25</li> <li>Advanced style (10-50 examples): $75</li> <li>Professional style (50+ examples): $150</li> </ul> <p>Custom Model Fine-tuning</p> <ul> <li>Small model: $500-$2,000</li> <li>Medium model: $2,000-$10,000</li> <li>Large model: $10,000-$50,000</li> </ul>"},{"location":"business/pricing/#storage-and-bandwidth","title":"Storage and Bandwidth","text":"<p>Additional Cloud Storage</p> <ul> <li>10 GB: $5/month</li> <li>50 GB: $20/month</li> <li>100 GB: $35/month</li> <li>500 GB: $150/month</li> </ul> <p>CDN and Bandwidth</p> <ul> <li>100 GB transfer: $10/month</li> <li>500 GB transfer: $40/month</li> <li>1 TB transfer: $75/month</li> </ul>"},{"location":"business/pricing/#priority-processing","title":"Priority Processing","text":"<p>Rush Processing</p> <ul> <li>2x speed: +50% of generation cost</li> <li>5x speed: +100% of generation cost</li> <li>10x speed: +200% of generation cost</li> </ul>"},{"location":"business/pricing/#billing-and-payment","title":"Billing and Payment","text":""},{"location":"business/pricing/#payment-methods","title":"Payment Methods","text":"<p>Accepted Payment Methods:</p> <ul> <li>Credit cards (Visa, MasterCard, American Express)</li> <li>PayPal</li> <li>Bank transfer (Enterprise only)</li> <li>Invoice billing (Business and Enterprise)</li> </ul>"},{"location":"business/pricing/#billing-cycles","title":"Billing Cycles","text":"<p>Available Billing Options:</p> <ul> <li>Monthly billing</li> <li>Annual billing (17% discount)</li> <li>Multi-year contracts (up to 25% discount for Enterprise)</li> </ul>"},{"location":"business/pricing/#usage-tracking","title":"Usage Tracking","text":"<p>Real-Time Monitoring:</p> <ul> <li>Live usage dashboard</li> <li>Daily usage reports</li> <li>Monthly billing summaries</li> <li>Overage alerts and notifications</li> <li>Usage forecasting and budgeting tools</li> </ul>"},{"location":"business/pricing/#invoice-management","title":"Invoice Management","text":"<p>Features Available:</p> <ul> <li>Detailed usage breakdowns</li> <li>Tax handling and compliance</li> <li>Multiple payment methods per account</li> <li>Automated billing and receipts</li> <li>Custom purchase orders (Enterprise)</li> </ul>"},{"location":"business/pricing/#pricing-calculator","title":"Pricing Calculator","text":""},{"location":"business/pricing/#interactive-calculator-inputs","title":"Interactive Calculator Inputs","text":"<p>Users can estimate costs based on:</p> <ol> <li>Expected Monthly Generations</li> <li>Required Models (affects credit consumption)</li> <li>Team Size</li> <li>Quality Requirements</li> <li>Add-On Services</li> <li>Support Level</li> </ol>"},{"location":"business/pricing/#sample-calculations","title":"Sample Calculations","text":""},{"location":"business/pricing/#small-marketing-agency","title":"Small Marketing Agency","text":"<p>Requirements:</p> <ul> <li>800 generations/month</li> <li>3 team members</li> <li>Mix of DALL-E 3 and Midjourney</li> <li>Professional support</li> </ul> <p>Recommended Plan: Professional ($79/month) Additional Costs: $32/month overage Total: $111/month</p>"},{"location":"business/pricing/#growing-e-commerce-company","title":"Growing E-commerce Company","text":"<p>Requirements:</p> <ul> <li>3,500 generations/month</li> <li>12 team members</li> <li>All models</li> <li>API integration</li> <li>Brand consistency</li> </ul> <p>Recommended Plan: Business ($199/month) Additional Costs: None (within limits) Total: $199/month</p>"},{"location":"business/pricing/#enterprise-corporation","title":"Enterprise Corporation","text":"<p>Requirements:</p> <ul> <li>25,000 generations/month</li> <li>100 team members</li> <li>Custom models</li> <li>Dedicated support</li> <li>On-premise deployment</li> </ul> <p>Recommended Plan: Enterprise (Custom) Estimated Cost: $15,000-$25,000/month</p>"},{"location":"business/pricing/#migration-and-upgrades","title":"Migration and Upgrades","text":""},{"location":"business/pricing/#plan-changes","title":"Plan Changes","text":"<p>Upgrade Process:</p> <ul> <li>Immediate access to new features</li> <li>Prorated billing for current period</li> <li>Usage history preserved</li> <li>Seamless transition</li> </ul> <p>Downgrade Process:</p> <ul> <li>Change effective at next billing cycle</li> <li>Grace period for feature access</li> <li>Data export options available</li> <li>Usage limits apply immediately</li> </ul>"},{"location":"business/pricing/#enterprise-migration","title":"Enterprise Migration","text":"<p>Migration Services:</p> <ul> <li>Dedicated migration specialist</li> <li>Data import/export assistance</li> <li>Custom integration support</li> <li>Training and onboarding</li> <li>Minimal downtime guarantee</li> </ul>"},{"location":"business/pricing/#regional-pricing","title":"Regional Pricing","text":""},{"location":"business/pricing/#purchasing-power-parity","title":"Purchasing Power Parity","text":"<p>Adjusted pricing for emerging markets:</p> Region Discount Latin America 30% Eastern Europe 25% Asia-Pacific (developing) 35% Africa 40% India 35%"},{"location":"business/pricing/#local-currency-support","title":"Local Currency Support","text":"<p>Supported Currencies:</p> <ul> <li>USD (United States Dollar)</li> <li>EUR (Euro)</li> <li>GBP (British Pound)</li> <li>CAD (Canadian Dollar)</li> <li>AUD (Australian Dollar)</li> <li>JPY (Japanese Yen)</li> <li>More currencies available upon request</li> </ul>"},{"location":"business/pricing/#educational-and-non-profit-discounts","title":"Educational and Non-Profit Discounts","text":""},{"location":"business/pricing/#educational-institutions","title":"Educational Institutions","text":"<p>Discount: 50% off all paid plans</p> <p>Eligibility Requirements:</p> <ul> <li>Accredited educational institutions</li> <li>Academic email verification</li> <li>Educational use only</li> <li>Annual verification required</li> </ul> <p>Application Process:</p> <ol> <li>Submit institution verification</li> <li>Provide academic email</li> <li>Describe intended use case</li> <li>Annual renewal required</li> </ol>"},{"location":"business/pricing/#non-profit-organizations","title":"Non-Profit Organizations","text":"<p>Discount: 40% off all paid plans</p> <p>Eligibility Requirements:</p> <ul> <li>Registered non-profit status</li> <li>501(c)(3) or equivalent</li> <li>Mission-aligned use cases</li> <li>Annual verification required</li> </ul> <p>Application Process:</p> <ol> <li>Submit non-profit documentation</li> <li>Provide organizational details</li> <li>Describe intended use case</li> <li>Annual renewal required</li> </ol>"},{"location":"business/pricing/#student-discounts","title":"Student Discounts","text":"<p>Discount: 60% off Starter and Professional plans</p> <p>Eligibility Requirements:</p> <ul> <li>Valid student ID</li> <li>Academic email address</li> <li>Full-time enrollment verification</li> <li>Personal use only</li> </ul>"},{"location":"business/pricing/#pricing-support","title":"Pricing Support","text":""},{"location":"business/pricing/#pricing-consultation","title":"Pricing Consultation","text":"<p>Available Services:</p> <ul> <li>Free pricing consultation for Business+ plans</li> <li>Custom quote generation</li> <li>ROI analysis and business case support</li> <li>Implementation planning</li> <li>Budget optimization recommendations</li> </ul>"},{"location":"business/pricing/#contact-information","title":"Contact Information","text":"<p>Sales Team:</p> <ul> <li>Email: sales@freepik-ai-orchestrator.com</li> <li>Phone: +1 (555) 123-4567</li> <li>Live chat: Available on website</li> <li>Schedule consultation: Online calendar booking</li> </ul> <p>Support Hours:</p> <ul> <li>Monday-Friday: 9 AM - 6 PM (EST)</li> <li>24/7 support for Enterprise customers</li> <li>International support available</li> </ul> <p>This comprehensive pricing structure is designed to provide flexibility and value for customers at every stage of their AI content creation journey, from individual creators to large enterprises.</p>"},{"location":"deployment/docker/","title":"Docker Deployment Guide","text":"<p>This guide provides comprehensive instructions for deploying the Freepik AI Orchestrator using Docker in various environments.</p>"},{"location":"deployment/docker/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Quick Start</li> <li>Docker Images</li> <li>Environment Configuration</li> <li>Single Container Deployment</li> <li>Multi-Container Deployment</li> <li>Development Setup</li> <li>Production Deployment</li> <li>Docker Compose Examples</li> <li>Scaling and Load Balancing</li> <li>Monitoring and Logging</li> <li>Troubleshooting</li> </ul>"},{"location":"deployment/docker/#quick-start","title":"Quick Start","text":""},{"location":"deployment/docker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker 20.10 or higher</li> <li>Docker Compose 2.0 or higher</li> <li>At least 4GB RAM available</li> <li>Valid API keys for AI services</li> </ul>"},{"location":"deployment/docker/#run-with-docker-compose","title":"Run with Docker Compose","text":"<pre><code># Clone repository\ngit clone https://github.com/freepik/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\n\n# Copy environment template\ncp .env.example .env\n\n# Edit environment variables\nnano .env\n\n# Start services\ndocker-compose up -d\n\n# Access application\nopen http://localhost:8501\n</code></pre>"},{"location":"deployment/docker/#docker-images","title":"Docker Images","text":""},{"location":"deployment/docker/#official-images","title":"Official Images","text":"<p>The project provides pre-built Docker images:</p> <pre><code># Pull latest image\ndocker pull freepik/ai-orchestrator:latest\n\n# Pull specific version\ndocker pull freepik/ai-orchestrator:v1.2.0\n\n# Pull development image\ndocker pull freepik/ai-orchestrator:develop\n</code></pre>"},{"location":"deployment/docker/#image-variants","title":"Image Variants","text":"Tag Description Size Use Case <code>latest</code> Latest stable release ~800MB Production <code>v1.x.x</code> Specific version ~800MB Production <code>develop</code> Development build ~900MB Testing <code>slim</code> Minimal dependencies ~400MB Resource-constrained <code>gpu</code> CUDA support ~2GB GPU acceleration"},{"location":"deployment/docker/#building-custom-images","title":"Building Custom Images","text":"<pre><code># Build standard image\ndocker build -t freepik-ai-orchestrator .\n\n# Build with custom tag\ndocker build -t freepik-ai-orchestrator:custom .\n\n# Build development image\ndocker build -f Dockerfile.dev -t freepik-ai-orchestrator:dev .\n\n# Build GPU-enabled image\ndocker build -f Dockerfile.gpu -t freepik-ai-orchestrator:gpu .\n</code></pre>"},{"location":"deployment/docker/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/docker/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file with required configuration:</p> <pre><code># Application Settings\nAPP_NAME=Freepik AI Orchestrator\nAPP_VERSION=1.0.0\nDEBUG=false\nLOG_LEVEL=INFO\n\n# API Keys\nOPENAI_API_KEY=sk-your-openai-key\nANTHROPIC_API_KEY=sk-ant-your-anthropic-key\nSTABILITY_API_KEY=sk-your-stability-key\n\n# Database Configuration\nDATABASE_URL=postgresql://user:password@postgres:5432/orchestrator\nREDIS_URL=redis://redis:6379/0\n\n# Security\nSECRET_KEY=your-secret-key-here\nJWT_SECRET=your-jwt-secret-here\nALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com\n\n# External Services\nWEBHOOK_URL=https://your-domain.com/webhooks\nSTORAGE_BACKEND=s3\nAWS_ACCESS_KEY_ID=your-aws-key\nAWS_SECRET_ACCESS_KEY=your-aws-secret\nAWS_S3_BUCKET=your-bucket-name\n\n# Performance\nMAX_WORKERS=4\nCACHE_TTL=3600\nREQUEST_TIMEOUT=300\n</code></pre>"},{"location":"deployment/docker/#docker-environment-variables","title":"Docker Environment Variables","text":"<pre><code># Set environment variables for Docker\nexport COMPOSE_PROJECT_NAME=freepik-orchestrator\nexport COMPOSE_FILE=docker-compose.yml\nexport DOCKER_BUILDKIT=1\n</code></pre>"},{"location":"deployment/docker/#single-container-deployment","title":"Single Container Deployment","text":""},{"location":"deployment/docker/#basic-deployment","title":"Basic Deployment","text":"<pre><code># Run single container\ndocker run -d \\\n  --name ai-orchestrator \\\n  -p 8501:8501 \\\n  -e OPENAI_API_KEY=sk-your-key \\\n  -e DATABASE_URL=sqlite:///app/data/orchestrator.db \\\n  -v $(pwd)/data:/app/data \\\n  freepik/ai-orchestrator:latest\n</code></pre>"},{"location":"deployment/docker/#with-persistent-storage","title":"With Persistent Storage","text":"<pre><code># Create volume for persistent data\ndocker volume create orchestrator-data\n\n# Run with persistent storage\ndocker run -d \\\n  --name ai-orchestrator \\\n  -p 8501:8501 \\\n  --env-file .env \\\n  -v orchestrator-data:/app/data \\\n  -v $(pwd)/logs:/app/logs \\\n  freepik/ai-orchestrator:latest\n</code></pre>"},{"location":"deployment/docker/#with-gpu-support","title":"With GPU Support","text":"<pre><code># Run with GPU acceleration\ndocker run -d \\\n  --name ai-orchestrator-gpu \\\n  --gpus all \\\n  -p 8501:8501 \\\n  --env-file .env \\\n  -v orchestrator-data:/app/data \\\n  freepik/ai-orchestrator:gpu\n</code></pre>"},{"location":"deployment/docker/#multi-container-deployment","title":"Multi-Container Deployment","text":""},{"location":"deployment/docker/#basic-docker-compose","title":"Basic Docker Compose","text":"<p>docker-compose.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    image: freepik/ai-orchestrator:latest\n    container_name: ai-orchestrator\n    ports:\n      - \"8501:8501\"\n    environment:\n      - DATABASE_URL=postgresql://postgres:password@postgres:5432/orchestrator\n      - REDIS_URL=redis://redis:6379/0\n    env_file:\n      - .env\n    depends_on:\n      - postgres\n      - redis\n    volumes:\n      - app-data:/app/data\n      - ./logs:/app/logs\n    restart: unless-stopped\n    networks:\n      - orchestrator-network\n\n  postgres:\n    image: postgres:15\n    container_name: ai-orchestrator-db\n    environment:\n      POSTGRES_DB: orchestrator\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: password\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./init.sql:/docker-entrypoint-initdb.d/init.sql\n    restart: unless-stopped\n    networks:\n      - orchestrator-network\n\n  redis:\n    image: redis:7-alpine\n    container_name: ai-orchestrator-cache\n    command: redis-server --appendonly yes\n    volumes:\n      - redis-data:/data\n    restart: unless-stopped\n    networks:\n      - orchestrator-network\n\n  nginx:\n    image: nginx:alpine\n    container_name: ai-orchestrator-proxy\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n      - ./ssl:/etc/nginx/ssl\n    depends_on:\n      - app\n    restart: unless-stopped\n    networks:\n      - orchestrator-network\n\nvolumes:\n  app-data:\n  postgres-data:\n  redis-data:\n\nnetworks:\n  orchestrator-network:\n    driver: bridge\n</code></pre>"},{"location":"deployment/docker/#commands","title":"Commands","text":"<pre><code># Start all services\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f\n\n# Scale application\ndocker-compose up -d --scale app=3\n\n# Stop services\ndocker-compose down\n\n# Remove volumes\ndocker-compose down -v\n</code></pre>"},{"location":"deployment/docker/#development-setup","title":"Development Setup","text":""},{"location":"deployment/docker/#development-docker-compose","title":"Development Docker Compose","text":"<p>docker-compose.dev.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    container_name: ai-orchestrator-dev\n    ports:\n      - \"8501:8501\"\n      - \"8000:8000\"  # API port\n    environment:\n      - DEBUG=true\n      - LOG_LEVEL=DEBUG\n      - RELOAD=true\n    env_file:\n      - .env.dev\n    volumes:\n      - .:/app\n      - /app/node_modules\n      - dev-data:/app/data\n    depends_on:\n      - postgres-dev\n      - redis-dev\n    restart: unless-stopped\n    networks:\n      - dev-network\n\n  postgres-dev:\n    image: postgres:15\n    container_name: ai-orchestrator-db-dev\n    environment:\n      POSTGRES_DB: orchestrator_dev\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: dev_password\n    ports:\n      - \"5433:5432\"\n    volumes:\n      - postgres-dev-data:/var/lib/postgresql/data\n    networks:\n      - dev-network\n\n  redis-dev:\n    image: redis:7-alpine\n    container_name: ai-orchestrator-cache-dev\n    ports:\n      - \"6380:6379\"\n    volumes:\n      - redis-dev-data:/data\n    networks:\n      - dev-network\n\n  mailhog:\n    image: mailhog/mailhog\n    container_name: ai-orchestrator-mail-dev\n    ports:\n      - \"1025:1025\"\n      - \"8025:8025\"\n    networks:\n      - dev-network\n\nvolumes:\n  dev-data:\n  postgres-dev-data:\n  redis-dev-data:\n\nnetworks:\n  dev-network:\n    driver: bridge\n</code></pre>"},{"location":"deployment/docker/#development-commands","title":"Development Commands","text":"<pre><code># Start development environment\ndocker-compose -f docker-compose.dev.yml up -d\n\n# Watch logs\ndocker-compose -f docker-compose.dev.yml logs -f app\n\n# Execute commands in container\ndocker-compose -f docker-compose.dev.yml exec app bash\ndocker-compose -f docker-compose.dev.yml exec app python manage.py migrate\n\n# Run tests\ndocker-compose -f docker-compose.dev.yml exec app pytest\n\n# Access database\ndocker-compose -f docker-compose.dev.yml exec postgres-dev psql -U postgres -d orchestrator_dev\n</code></pre>"},{"location":"deployment/docker/#production-deployment","title":"Production Deployment","text":""},{"location":"deployment/docker/#production-docker-compose","title":"Production Docker Compose","text":"<p>docker-compose.prod.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    image: freepik/ai-orchestrator:latest\n    deploy:\n      replicas: 3\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          cpus: '1'\n          memory: 2G\n    environment:\n      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/orchestrator\n      - REDIS_URL=redis://redis:6379/0\n      - DEBUG=false\n      - LOG_LEVEL=INFO\n    env_file:\n      - .env.prod\n    volumes:\n      - app-data:/app/data\n      - ./logs:/app/logs\n    networks:\n      - prod-network\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: orchestrator\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./backups:/backups\n    networks:\n      - prod-network\n    deploy:\n      restart_policy:\n        condition: on-failure\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    image: redis:7-alpine\n    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}\n    volumes:\n      - redis-data:/data\n    networks:\n      - prod-network\n    deploy:\n      restart_policy:\n        condition: on-failure\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.prod.conf:/etc/nginx/nginx.conf\n      - ./ssl:/etc/nginx/ssl\n      - ./static:/var/www/static\n    depends_on:\n      - app\n    networks:\n      - prod-network\n    deploy:\n      restart_policy:\n        condition: on-failure\n\n  backup:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n    volumes:\n      - ./backups:/backups\n      - ./backup-scripts:/scripts\n    command: /scripts/backup.sh\n    networks:\n      - prod-network\n    deploy:\n      restart_policy:\n        condition: on-failure\n\nvolumes:\n  app-data:\n  postgres-data:\n  redis-data:\n\nnetworks:\n  prod-network:\n    driver: overlay\n    encrypted: true\n\nsecrets:\n  postgres_password:\n    external: true\n  redis_password:\n    external: true\n</code></pre>"},{"location":"deployment/docker/#production-commands","title":"Production Commands","text":"<pre><code># Deploy to production\ndocker stack deploy -c docker-compose.prod.yml orchestrator\n\n# Update service\ndocker service update --image freepik/ai-orchestrator:v1.2.0 orchestrator_app\n\n# Scale service\ndocker service scale orchestrator_app=5\n\n# View service status\ndocker service ls\ndocker service ps orchestrator_app\n\n# View logs\ndocker service logs -f orchestrator_app\n</code></pre>"},{"location":"deployment/docker/#docker-compose-examples","title":"Docker Compose Examples","text":""},{"location":"deployment/docker/#minimal-setup","title":"Minimal Setup","text":"<pre><code>version: '3.8'\nservices:\n  app:\n    image: freepik/ai-orchestrator:latest\n    ports:\n      - \"8501:8501\"\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n    volumes:\n      - ./data:/app/data\n</code></pre>"},{"location":"deployment/docker/#with-monitoring","title":"With Monitoring","text":"<pre><code>version: '3.8'\nservices:\n  app:\n    image: freepik/ai-orchestrator:latest\n    ports:\n      - \"8501:8501\"\n    env_file: .env\n    depends_on:\n      - postgres\n      - redis\n\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: orchestrator\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: password\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n\n  redis:\n    image: redis:7-alpine\n    volumes:\n      - redis-data:/data\n\n  prometheus:\n    image: prom/prometheus\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n\n  grafana:\n    image: grafana/grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n    volumes:\n      - grafana-data:/var/lib/grafana\n\nvolumes:\n  postgres-data:\n  redis-data:\n  grafana-data:\n</code></pre>"},{"location":"deployment/docker/#scaling-and-load-balancing","title":"Scaling and Load Balancing","text":""},{"location":"deployment/docker/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># Scale application instances\ndocker-compose up -d --scale app=5\n\n# Using Docker Swarm\ndocker service scale orchestrator_app=5\n</code></pre>"},{"location":"deployment/docker/#load-balancer-configuration","title":"Load Balancer Configuration","text":"<p>nginx.conf:</p> <pre><code>upstream app_servers {\n    server app_1:8501 weight=1 max_fails=3 fail_timeout=30s;\n    server app_2:8501 weight=1 max_fails=3 fail_timeout=30s;\n    server app_3:8501 weight=1 max_fails=3 fail_timeout=30s;\n}\n\nserver {\n    listen 80;\n    server_name your-domain.com;\n\n    location / {\n        proxy_pass http://app_servers;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # WebSocket support for Streamlit\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n\n    location /health {\n        access_log off;\n        return 200 \"healthy\\n\";\n    }\n}\n</code></pre>"},{"location":"deployment/docker/#auto-scaling-with-docker-swarm","title":"Auto-scaling with Docker Swarm","text":"<pre><code>version: '3.8'\nservices:\n  app:\n    image: freepik/ai-orchestrator:latest\n    deploy:\n      replicas: 2\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\n      rollback_config:\n        parallelism: 1\n        delay: 10s\n      placement:\n        constraints:\n          - node.role == worker\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n</code></pre>"},{"location":"deployment/docker/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":"<p>Add health checks to your containers:</p> <pre><code>services:\n  app:\n    image: freepik/ai-orchestrator:latest\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n</code></pre>"},{"location":"deployment/docker/#logging-configuration","title":"Logging Configuration","text":"<p>docker-compose.yml:</p> <pre><code>services:\n  app:\n    image: freepik/ai-orchestrator:latest\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n        labels: \"service=ai-orchestrator\"\n</code></pre>"},{"location":"deployment/docker/#centralized-logging","title":"Centralized Logging","text":"<pre><code>services:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0\n    environment:\n      - discovery.type=single-node\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - elasticsearch-data:/usr/share/elasticsearch/data\n\n  logstash:\n    image: docker.elastic.co/logstash/logstash:8.5.0\n    volumes:\n      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf\n    depends_on:\n      - elasticsearch\n\n  kibana:\n    image: docker.elastic.co/kibana/kibana:8.5.0\n    ports:\n      - \"5601:5601\"\n    environment:\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  elasticsearch-data:\n</code></pre>"},{"location":"deployment/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker/#common-issues","title":"Common Issues","text":""},{"location":"deployment/docker/#container-wont-start","title":"Container Won't Start","text":"<pre><code># Check logs\ndocker-compose logs app\n\n# Check container status\ndocker ps -a\n\n# Inspect container\ndocker inspect ai-orchestrator\n\n# Check resource usage\ndocker stats\n</code></pre>"},{"location":"deployment/docker/#database-connection-issues","title":"Database Connection Issues","text":"<pre><code># Test database connectivity\ndocker-compose exec app ping postgres\n\n# Check database logs\ndocker-compose logs postgres\n\n# Connect to database manually\ndocker-compose exec postgres psql -U postgres -d orchestrator\n</code></pre>"},{"location":"deployment/docker/#permission-issues","title":"Permission Issues","text":"<pre><code># Fix ownership\nsudo chown -R $(id -u):$(id -g) ./data ./logs\n\n# Set correct permissions\nchmod 755 ./data ./logs\n</code></pre>"},{"location":"deployment/docker/#out-of-memory","title":"Out of Memory","text":"<pre><code># Check memory usage\ndocker stats\n\n# Increase memory limit\ndocker-compose down\n# Edit docker-compose.yml to add memory limits\ndocker-compose up -d\n</code></pre>"},{"location":"deployment/docker/#debugging-commands","title":"Debugging Commands","text":"<pre><code># Enter container shell\ndocker-compose exec app bash\n\n# Run commands inside container\ndocker-compose exec app python manage.py shell\n\n# Copy files from container\ndocker cp ai-orchestrator:/app/logs/app.log ./local-logs/\n\n# View real-time logs\ndocker-compose logs -f --tail=100 app\n\n# Check container processes\ndocker-compose exec app ps aux\n\n# Network diagnostics\ndocker network ls\ndocker network inspect orchestrator_default\n</code></pre>"},{"location":"deployment/docker/#performance-tuning","title":"Performance Tuning","text":""},{"location":"deployment/docker/#resource-limits","title":"Resource Limits","text":"<pre><code>services:\n  app:\n    image: freepik/ai-orchestrator:latest\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 4G\n        reservations:\n          cpus: '1.0'\n          memory: 2G\n</code></pre>"},{"location":"deployment/docker/#database-optimization","title":"Database Optimization","text":"<pre><code>services:\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: orchestrator\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: password\n    command: &gt;\n      postgres\n      -c shared_preload_libraries=pg_stat_statements\n      -c max_connections=200\n      -c shared_buffers=256MB\n      -c effective_cache_size=1GB\n      -c maintenance_work_mem=64MB\n      -c checkpoint_completion_target=0.9\n      -c wal_buffers=16MB\n      -c default_statistics_target=100\n</code></pre>"},{"location":"deployment/docker/#redis-optimization","title":"Redis Optimization","text":"<pre><code>services:\n  redis:\n    image: redis:7-alpine\n    command: &gt;\n      redis-server\n      --maxmemory 1gb\n      --maxmemory-policy allkeys-lru\n      --appendonly yes\n      --appendfsync everysec\n</code></pre> <p>For more deployment options and advanced configurations, see the Production Deployment Guide.</p>"},{"location":"deployment/production/","title":"Production Deployment Best Practices","text":"<p>This guide covers best practices and considerations for deploying the Freepik AI Orchestrator in production environments.</p>"},{"location":"deployment/production/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Production Readiness Checklist</li> <li>Infrastructure Requirements</li> <li>Security Hardening</li> <li>Performance Optimization</li> <li>Monitoring and Observability</li> <li>High Availability Setup</li> <li>Disaster Recovery</li> <li>CI/CD Pipeline</li> <li>Maintenance and Updates</li> <li>Cost Optimization</li> </ul>"},{"location":"deployment/production/#production-readiness-checklist","title":"Production Readiness Checklist","text":""},{"location":"deployment/production/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li> Security audit completed</li> <li> Load testing performed</li> <li> Backup strategy implemented</li> <li> Monitoring setup configured</li> <li> SSL certificates obtained</li> <li> Environment variables secured</li> <li> Database migrations tested</li> <li> API rate limiting configured</li> <li> Error tracking enabled</li> <li> Log aggregation setup</li> </ul>"},{"location":"deployment/production/#infrastructure","title":"Infrastructure","text":"<ul> <li> Auto-scaling configured</li> <li> Health checks implemented</li> <li> Resource limits set</li> <li> Network security groups configured</li> <li> CDN setup for static assets</li> <li> Database connection pooling</li> <li> Redis clustering (if needed)</li> <li> File storage configured</li> </ul>"},{"location":"deployment/production/#operations","title":"Operations","text":"<ul> <li> Deployment automation</li> <li> Rollback procedures documented</li> <li> Incident response plan</li> <li> Performance benchmarks established</li> <li> Documentation updated</li> <li> Team training completed</li> </ul>"},{"location":"deployment/production/#infrastructure-requirements","title":"Infrastructure Requirements","text":""},{"location":"deployment/production/#minimum-production-requirements","title":"Minimum Production Requirements","text":"Component Specification Recommendation CPU 4 cores 8+ cores RAM 8GB 16GB+ Storage 100GB SSD 500GB+ SSD Network 1Gbps 10Gbps Database PostgreSQL 12+ PostgreSQL 15+ Cache Redis 6+ Redis 7+"},{"location":"deployment/production/#recommended-architecture","title":"Recommended Architecture","text":"<pre><code>Internet\n    |\n[Load Balancer]\n    |\n[Web Application Firewall]\n    |\n[Application Servers] (3+ instances)\n    |\n[Database Cluster] (Primary + Replicas)\n    |\n[Cache Cluster] (Redis)\n    |\n[File Storage] (S3/MinIO)\n</code></pre>"},{"location":"deployment/production/#cloud-provider-configurations","title":"Cloud Provider Configurations","text":""},{"location":"deployment/production/#aws","title":"AWS","text":"<pre><code># EC2 Instance Recommendations\nInstance Type: c5.2xlarge or m5.2xlarge\nOS: Amazon Linux 2 or Ubuntu 20.04 LTS\nEBS: gp3 with 3000 IOPS\nVPC: Private subnets with NAT Gateway\nSecurity Groups: Restrictive inbound rules\n\n# RDS Configuration\nEngine: PostgreSQL 15\nInstance: db.r5.xlarge\nStorage: gp3 with 3000 IOPS\nMulti-AZ: Enabled\nBackup: 7-day retention\n\n# ElastiCache\nEngine: Redis 7\nNode: cache.r6g.large\nCluster Mode: Enabled\nBackup: Enabled\n</code></pre>"},{"location":"deployment/production/#azure","title":"Azure","text":"<pre><code># Virtual Machine\nSize: Standard_D4s_v3\nOS: Ubuntu 20.04 LTS\nDisk: Premium SSD P30\nNetwork: Virtual Network with NSG\nAvailability: Availability Set\n\n# Azure Database for PostgreSQL\nTier: General Purpose\nvCores: 4\nStorage: 500GB\nBackup: 7-day retention\nHigh Availability: Enabled\n\n# Azure Cache for Redis\nTier: Premium P1\nClustering: Enabled\nPersistence: Enabled\n</code></pre>"},{"location":"deployment/production/#google-cloud-platform","title":"Google Cloud Platform","text":"<pre><code># Compute Engine\nMachine Type: n2-standard-4\nOS: Ubuntu 20.04 LTS\nDisk: SSD Persistent Disk 500GB\nNetwork: VPC with Firewall Rules\nAvailability: Multi-zone\n\n# Cloud SQL\nVersion: PostgreSQL 15\nTier: db-custom-4-16384\nStorage: 500GB SSD\nHigh Availability: Regional\nBackup: Automated daily\n\n# Memorystore for Redis\nTier: Standard\nMemory: 5GB\nHigh Availability: Enabled\n</code></pre>"},{"location":"deployment/production/#security-hardening","title":"Security Hardening","text":""},{"location":"deployment/production/#network-security","title":"Network Security","text":""},{"location":"deployment/production/#firewall-configuration","title":"Firewall Configuration","text":"<pre><code># Allow HTTP/HTTPS only\niptables -A INPUT -p tcp --dport 80 -j ACCEPT\niptables -A INPUT -p tcp --dport 443 -j ACCEPT\n\n# Allow SSH from specific IPs only\niptables -A INPUT -p tcp -s 203.0.113.0/24 --dport 22 -j ACCEPT\n\n# Block all other incoming traffic\niptables -P INPUT DROP\niptables -P FORWARD DROP\n</code></pre>"},{"location":"deployment/production/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<p>nginx.conf:</p> <pre><code>server {\n    listen 443 ssl http2;\n    server_name your-domain.com;\n\n    # SSL Configuration\n    ssl_certificate /etc/ssl/certs/your-domain.crt;\n    ssl_certificate_key /etc/ssl/private/your-domain.key;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;\n    ssl_prefer_server_ciphers off;\n    ssl_dhparam /etc/ssl/certs/dhparam.pem;\n\n    # Security Headers\n    add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\";\n    add_header X-Frame-Options DENY;\n    add_header X-Content-Type-Options nosniff;\n    add_header X-XSS-Protection \"1; mode=block\";\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\";\n    add_header Content-Security-Policy \"default-src 'self'; script-src 'self' 'unsafe-inline'\";\n\n    # Rate Limiting\n    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n    limit_req zone=api burst=20 nodelay;\n\n    location / {\n        proxy_pass http://app_servers;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n\n# Redirect HTTP to HTTPS\nserver {\n    listen 80;\n    server_name your-domain.com;\n    return 301 https://$server_name$request_uri;\n}\n</code></pre>"},{"location":"deployment/production/#application-security","title":"Application Security","text":""},{"location":"deployment/production/#environment-variables-management","title":"Environment Variables Management","text":"<p>Use a secrets management system:</p> <pre><code># Using AWS Secrets Manager\naws secretsmanager create-secret \\\n    --name freepik-ai-orchestrator/prod \\\n    --secret-string '{\n        \"OPENAI_API_KEY\": \"sk-your-key\",\n        \"DATABASE_URL\": \"postgresql://...\",\n        \"SECRET_KEY\": \"your-secret-key\"\n    }'\n\n# Retrieve in application\nSECRET=$(aws secretsmanager get-secret-value \\\n    --secret-id freepik-ai-orchestrator/prod \\\n    --query SecretString --output text)\n</code></pre>"},{"location":"deployment/production/#api-security","title":"API Security","text":"<pre><code># Rate limiting implementation\nfrom flask_limiter import Limiter\nfrom flask_limiter.util import get_remote_address\n\nlimiter = Limiter(\n    app,\n    key_func=get_remote_address,\n    default_limits=[\"200 per day\", \"50 per hour\"]\n)\n\n@app.route(\"/api/v1/generate\")\n@limiter.limit(\"10 per minute\")\ndef generate():\n    # API implementation\n    pass\n\n# Input validation\nfrom marshmallow import Schema, fields, validate\n\nclass GenerationSchema(Schema):\n    prompt = fields.Str(required=True, validate=validate.Length(min=1, max=1000))\n    model = fields.Str(required=True, validate=validate.OneOf(['dall-e-3', 'midjourney']))\n    size = fields.Str(validate=validate.OneOf(['512x512', '1024x1024']))\n</code></pre>"},{"location":"deployment/production/#database-security","title":"Database Security","text":"<pre><code>-- Create limited user for application\nCREATE USER app_user WITH PASSWORD 'strong_password';\nGRANT CONNECT ON DATABASE orchestrator TO app_user;\nGRANT USAGE ON SCHEMA public TO app_user;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;\n\n-- Enable row-level security\nALTER TABLE generations ENABLE ROW LEVEL SECURITY;\nCREATE POLICY user_generations ON generations FOR ALL TO app_user USING (user_id = current_user_id());\n</code></pre>"},{"location":"deployment/production/#performance-optimization","title":"Performance Optimization","text":""},{"location":"deployment/production/#application-level","title":"Application Level","text":""},{"location":"deployment/production/#caching-strategy","title":"Caching Strategy","text":"<pre><code># Redis caching implementation\nimport redis\nimport json\nfrom functools import wraps\n\nredis_client = redis.Redis(host='redis', port=6379, db=0)\n\ndef cache_result(expiration=3600):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            # Create cache key\n            cache_key = f\"{func.__name__}:{hash(str(args) + str(kwargs))}\"\n\n            # Try to get from cache\n            cached = redis_client.get(cache_key)\n            if cached:\n                return json.loads(cached)\n\n            # Execute function and cache result\n            result = func(*args, **kwargs)\n            redis_client.setex(cache_key, expiration, json.dumps(result))\n            return result\n        return wrapper\n    return decorator\n\n@cache_result(expiration=1800)\ndef generate_content(prompt, model):\n    # Expensive generation operation\n    return result\n</code></pre>"},{"location":"deployment/production/#database-optimization","title":"Database Optimization","text":"<pre><code>-- Create indexes for frequently queried columns\nCREATE INDEX CONCURRENTLY idx_generations_user_id ON generations(user_id);\nCREATE INDEX CONCURRENTLY idx_generations_created_at ON generations(created_at);\nCREATE INDEX CONCURRENTLY idx_generations_model ON generations(model);\n\n-- Optimize queries with proper indexing\nCREATE INDEX CONCURRENTLY idx_generations_composite \n    ON generations(user_id, created_at DESC, model);\n\n-- Partition large tables\nCREATE TABLE generations_2024_01 PARTITION OF generations \n    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');\n</code></pre>"},{"location":"deployment/production/#connection-pooling","title":"Connection Pooling","text":"<pre><code># PostgreSQL connection pooling\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.pool import QueuePool\n\nengine = create_engine(\n    DATABASE_URL,\n    poolclass=QueuePool,\n    pool_size=20,\n    max_overflow=30,\n    pool_pre_ping=True,\n    pool_recycle=3600\n)\n</code></pre>"},{"location":"deployment/production/#infrastructure-level","title":"Infrastructure Level","text":""},{"location":"deployment/production/#load-balancing","title":"Load Balancing","text":"<pre><code># HAProxy configuration\nglobal\n    daemon\n    maxconn 4096\n\ndefaults\n    mode http\n    timeout connect 5000ms\n    timeout client 50000ms\n    timeout server 50000ms\n\nfrontend ai_orchestrator_frontend\n    bind *:80\n    bind *:443 ssl crt /etc/ssl/certs/your-domain.pem\n    redirect scheme https if !{ ssl_fc }\n    default_backend ai_orchestrator_backend\n\nbackend ai_orchestrator_backend\n    balance roundrobin\n    option httpchk GET /health\n    server app1 10.0.1.10:8501 check\n    server app2 10.0.1.11:8501 check\n    server app3 10.0.1.12:8501 check\n</code></pre>"},{"location":"deployment/production/#auto-scaling-configuration","title":"Auto-scaling Configuration","text":"<pre><code># Kubernetes HPA\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: ai-orchestrator-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: ai-orchestrator\n  minReplicas: 3\n  maxReplicas: 20\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n</code></pre>"},{"location":"deployment/production/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"deployment/production/#application-metrics","title":"Application Metrics","text":"<pre><code># Prometheus metrics\nfrom prometheus_client import Counter, Histogram, Gauge, start_http_server\n\n# Define metrics\nGENERATION_REQUESTS = Counter('generation_requests_total', 'Total generation requests', ['model', 'status'])\nGENERATION_DURATION = Histogram('generation_duration_seconds', 'Generation duration', ['model'])\nACTIVE_CONNECTIONS = Gauge('active_connections', 'Active connections')\n\n# Use in application\n@app.route('/api/v1/generate')\ndef generate():\n    start_time = time.time()\n    try:\n        result = perform_generation(prompt, model)\n        GENERATION_REQUESTS.labels(model=model, status='success').inc()\n        return result\n    except Exception as e:\n        GENERATION_REQUESTS.labels(model=model, status='error').inc()\n        raise\n    finally:\n        GENERATION_DURATION.labels(model=model).observe(time.time() - start_time)\n</code></pre>"},{"location":"deployment/production/#monitoring-stack","title":"Monitoring Stack","text":""},{"location":"deployment/production/#prometheus-configuration","title":"Prometheus Configuration","text":"<p>prometheus.yml:</p> <pre><code>global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nrule_files:\n  - \"alert_rules.yml\"\n\nscrape_configs:\n  - job_name: 'ai-orchestrator'\n    static_configs:\n      - targets: ['app:8000']\n    metrics_path: /metrics\n    scrape_interval: 5s\n\n  - job_name: 'node-exporter'\n    static_configs:\n      - targets: ['node-exporter:9100']\n\n  - job_name: 'postgres-exporter'\n    static_configs:\n      - targets: ['postgres-exporter:9187']\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n          - alertmanager:9093\n</code></pre>"},{"location":"deployment/production/#grafana-dashboards","title":"Grafana Dashboards","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"AI Orchestrator Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Generation Requests per Second\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(generation_requests_total[5m])\",\n            \"legendFormat\": \"{{model}} - {{status}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Average Generation Time\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(generation_duration_seconds_sum[5m]) / rate(generation_duration_seconds_count[5m])\",\n            \"legendFormat\": \"{{model}}\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"deployment/production/#alerting-rules","title":"Alerting Rules","text":"<p>alert_rules.yml:</p> <pre><code>groups:\n  - name: ai-orchestrator\n    rules:\n      - alert: HighErrorRate\n        expr: rate(generation_requests_total{status=\"error\"}[5m]) &gt; 0.1\n        for: 2m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value }} errors per second\"\n\n      - alert: HighResponseTime\n        expr: rate(generation_duration_seconds_sum[5m]) / rate(generation_duration_seconds_count[5m]) &gt; 30\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High response time detected\"\n          description: \"Average response time is {{ $value }} seconds\"\n\n      - alert: ServiceDown\n        expr: up == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Service is down\"\n          description: \"{{ $labels.instance }} has been down for more than 1 minute\"\n</code></pre>"},{"location":"deployment/production/#high-availability-setup","title":"High Availability Setup","text":""},{"location":"deployment/production/#database-high-availability","title":"Database High Availability","text":""},{"location":"deployment/production/#postgresql-streaming-replication","title":"PostgreSQL Streaming Replication","text":"<p>Primary Server:</p> <pre><code># postgresql.conf\nwal_level = replica\nmax_wal_senders = 3\nmax_replication_slots = 3\nsynchronous_commit = on\nsynchronous_standby_names = 'standby1'\n\n# pg_hba.conf\nhost replication replicator 10.0.1.0/24 md5\n</code></pre> <p>Standby Server:</p> <pre><code># recovery.conf (PostgreSQL &lt; 12) or postgresql.conf (PostgreSQL 12+)\nprimary_conninfo = 'host=10.0.1.10 port=5432 user=replicator password=password'\nhot_standby = on\n</code></pre>"},{"location":"deployment/production/#automatic-failover-with-patroni","title":"Automatic Failover with Patroni","text":"<p>patroni.yml:</p> <pre><code>scope: postgres-cluster\nnamespace: /service/\nname: postgres-1\n\nrestapi:\n  listen: 0.0.0.0:8008\n  connect_address: 10.0.1.10:8008\n\netcd:\n  hosts: 10.0.1.20:2379,10.0.1.21:2379,10.0.1.22:2379\n\nbootstrap:\n  dcs:\n    ttl: 30\n    loop_wait: 10\n    retry_timeout: 30\n    maximum_lag_on_failover: 1048576\n    postgresql:\n      use_pg_rewind: true\n      use_slots: true\n      parameters:\n        wal_level: replica\n        hot_standby: \"on\"\n        max_connections: 200\n        max_worker_processes: 8\n        max_wal_senders: 8\n        max_replication_slots: 8\n\npostgresql:\n  listen: 0.0.0.0:5432\n  connect_address: 10.0.1.10:5432\n  data_dir: /var/lib/postgresql/data\n  bin_dir: /usr/lib/postgresql/15/bin\n  pgpass: /tmp/pgpass\n  authentication:\n    replication:\n      username: replicator\n      password: replicator_password\n    superuser:\n      username: postgres\n      password: postgres_password\n</code></pre>"},{"location":"deployment/production/#redis-high-availability","title":"Redis High Availability","text":""},{"location":"deployment/production/#redis-sentinel-configuration","title":"Redis Sentinel Configuration","text":"<p>sentinel.conf:</p> <pre><code>port 26379\nsentinel monitor redis-cluster 10.0.1.30 6379 2\nsentinel down-after-milliseconds redis-cluster 5000\nsentinel failover-timeout redis-cluster 60000\nsentinel parallel-syncs redis-cluster 1\n</code></pre>"},{"location":"deployment/production/#application-configuration-for-redis-cluster","title":"Application Configuration for Redis Cluster","text":"<pre><code>import redis.sentinel\n\n# Redis Sentinel configuration\nsentinels = [\n    ('10.0.1.40', 26379),\n    ('10.0.1.41', 26379),\n    ('10.0.1.42', 26379)\n]\n\nsentinel = redis.sentinel.Sentinel(sentinels, socket_timeout=0.1)\n\n# Get master and slave connections\nredis_master = sentinel.master_for('redis-cluster', socket_timeout=0.1)\nredis_slave = sentinel.slave_for('redis-cluster', socket_timeout=0.1)\n</code></pre>"},{"location":"deployment/production/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"deployment/production/#backup-strategy","title":"Backup Strategy","text":""},{"location":"deployment/production/#database-backups","title":"Database Backups","text":"<pre><code>#!/bin/bash\n# backup.sh - Database backup script\n\nBACKUP_DIR=\"/backups\"\nDATE=$(date +%Y%m%d_%H%M%S)\nDB_NAME=\"orchestrator\"\n\n# Create backup\npg_dump -h localhost -U postgres -d $DB_NAME | gzip &gt; $BACKUP_DIR/db_backup_$DATE.sql.gz\n\n# Upload to S3\naws s3 cp $BACKUP_DIR/db_backup_$DATE.sql.gz s3://your-backup-bucket/database/\n\n# Cleanup old local backups (keep 7 days)\nfind $BACKUP_DIR -name \"db_backup_*.sql.gz\" -mtime +7 -delete\n\n# Verify backup integrity\ngunzip -t $BACKUP_DIR/db_backup_$DATE.sql.gz\nif [ $? -eq 0 ]; then\n    echo \"Backup successful: db_backup_$DATE.sql.gz\"\nelse\n    echo \"Backup verification failed!\" &gt;&amp;2\n    exit 1\nfi\n</code></pre>"},{"location":"deployment/production/#application-state-backup","title":"Application State Backup","text":"<pre><code>#!/bin/bash\n# app_backup.sh - Application state backup\n\nBACKUP_DIR=\"/backups\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\n# Backup configuration files\ntar -czf $BACKUP_DIR/config_backup_$DATE.tar.gz /app/config/\n\n# Backup user uploads\ntar -czf $BACKUP_DIR/uploads_backup_$DATE.tar.gz /app/uploads/\n\n# Backup logs\ntar -czf $BACKUP_DIR/logs_backup_$DATE.tar.gz /app/logs/\n\n# Upload to S3\naws s3 sync $BACKUP_DIR s3://your-backup-bucket/application/\n</code></pre>"},{"location":"deployment/production/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"deployment/production/#database-recovery","title":"Database Recovery","text":"<pre><code>#!/bin/bash\n# restore.sh - Database restore script\n\nBACKUP_FILE=$1\nDB_NAME=\"orchestrator\"\n\nif [ -z \"$BACKUP_FILE\" ]; then\n    echo \"Usage: $0 &lt;backup_file&gt;\"\n    exit 1\nfi\n\n# Stop application\ndocker-compose stop app\n\n# Drop and recreate database\npsql -h localhost -U postgres -c \"DROP DATABASE IF EXISTS $DB_NAME;\"\npsql -h localhost -U postgres -c \"CREATE DATABASE $DB_NAME;\"\n\n# Restore from backup\ngunzip -c $BACKUP_FILE | psql -h localhost -U postgres -d $DB_NAME\n\n# Start application\ndocker-compose start app\n\necho \"Database restored from $BACKUP_FILE\"\n</code></pre>"},{"location":"deployment/production/#testing-recovery-procedures","title":"Testing Recovery Procedures","text":"<pre><code>#!/bin/bash\n# test_recovery.sh - Test recovery procedures\n\n# Create test environment\ndocker-compose -f docker-compose.test.yml up -d\n\n# Restore backup to test environment\n./restore.sh /backups/db_backup_latest.sql.gz\n\n# Run verification tests\npython -m pytest tests/integration/test_recovery.py\n\n# Cleanup test environment\ndocker-compose -f docker-compose.test.yml down -v\n</code></pre>"},{"location":"deployment/production/#cicd-pipeline","title":"CI/CD Pipeline","text":""},{"location":"deployment/production/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<p>.github/workflows/deploy.yml:</p> <pre><code>name: Deploy to Production\n\non:\n  push:\n    branches: [main]\n    tags: ['v*']\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v3\n        with:\n          python-version: '3.9'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install -r requirements-test.txt\n\n      - name: Run tests\n        run: pytest --cov=freepik_ai_orchestrator\n\n      - name: Security scan\n        run: bandit -r freepik_ai_orchestrator/\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          tags: |\n            freepik/ai-orchestrator:latest\n            freepik/ai-orchestrator:${{ github.sha }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy to staging\n        run: |\n          echo \"${{ secrets.STAGING_SSH_KEY }}\" &gt; staging_key\n          chmod 600 staging_key\n          ssh -i staging_key -o StrictHostKeyChecking=no \\\n            deploy@staging.yourdomain.com \\\n            \"cd /app &amp;&amp; docker-compose pull &amp;&amp; docker-compose up -d\"\n\n      - name: Run smoke tests\n        run: |\n          sleep 30\n          curl -f https://staging.yourdomain.com/health\n\n      - name: Deploy to production\n        if: success()\n        run: |\n          echo \"${{ secrets.PRODUCTION_SSH_KEY }}\" &gt; production_key\n          chmod 600 production_key\n          ssh -i production_key -o StrictHostKeyChecking=no \\\n            deploy@production.yourdomain.com \\\n            \"cd /app &amp;&amp; docker-compose pull &amp;&amp; docker-compose up -d\"\n</code></pre>"},{"location":"deployment/production/#blue-green-deployment","title":"Blue-Green Deployment","text":"<pre><code>#!/bin/bash\n# deploy.sh - Blue-green deployment script\n\nNEW_VERSION=$1\nCURRENT_ENV=$(cat /app/current_env)\n\nif [ \"$CURRENT_ENV\" = \"blue\" ]; then\n    NEW_ENV=\"green\"\n    OLD_ENV=\"blue\"\nelse\n    NEW_ENV=\"blue\"\n    OLD_ENV=\"green\"\nfi\n\necho \"Deploying version $NEW_VERSION to $NEW_ENV environment\"\n\n# Update new environment\ndocker-compose -f docker-compose.$NEW_ENV.yml pull\ndocker-compose -f docker-compose.$NEW_ENV.yml up -d\n\n# Wait for health check\nsleep 30\nif curl -f http://localhost:808${NEW_ENV}/health; then\n    echo \"New environment is healthy, switching traffic\"\n\n    # Update load balancer\n    sed -i \"s/808${OLD_ENV}/808${NEW_ENV}/g\" /etc/nginx/nginx.conf\n    nginx -s reload\n\n    # Update current environment marker\n    echo $NEW_ENV &gt; /app/current_env\n\n    # Stop old environment\n    docker-compose -f docker-compose.$OLD_ENV.yml down\n\n    echo \"Deployment successful\"\nelse\n    echo \"New environment failed health check, rolling back\"\n    docker-compose -f docker-compose.$NEW_ENV.yml down\n    exit 1\nfi\n</code></pre>"},{"location":"deployment/production/#maintenance-and-updates","title":"Maintenance and Updates","text":""},{"location":"deployment/production/#rolling-updates","title":"Rolling Updates","text":"<pre><code>#!/bin/bash\n# rolling_update.sh - Perform rolling update\n\nNEW_IMAGE=$1\nINSTANCES=(\"app1\" \"app2\" \"app3\")\n\nfor instance in \"${INSTANCES[@]}\"; do\n    echo \"Updating $instance...\"\n\n    # Remove from load balancer\n    curl -X POST \"http://loadbalancer:8080/admin/disable/$instance\"\n\n    # Wait for connections to drain\n    sleep 30\n\n    # Update instance\n    docker service update --image $NEW_IMAGE orchestrator_$instance\n\n    # Wait for health check\n    while ! curl -f \"http://$instance:8501/health\"; do\n        echo \"Waiting for $instance to be healthy...\"\n        sleep 10\n    done\n\n    # Add back to load balancer\n    curl -X POST \"http://loadbalancer:8080/admin/enable/$instance\"\n\n    echo \"$instance updated successfully\"\ndone\n</code></pre>"},{"location":"deployment/production/#database-migrations","title":"Database Migrations","text":"<pre><code># migrations/migrate.py\nimport sys\nimport psycopg2\nfrom pathlib import Path\n\ndef run_migration(db_url, migration_file):\n    \"\"\"Run a single migration file.\"\"\"\n    conn = psycopg2.connect(db_url)\n    cursor = conn.cursor()\n\n    try:\n        with open(migration_file, 'r') as f:\n            migration_sql = f.read()\n\n        cursor.execute(migration_sql)\n        conn.commit()\n\n        # Record migration\n        cursor.execute(\n            \"INSERT INTO migrations (filename, applied_at) VALUES (%s, NOW())\",\n            (migration_file.name,)\n        )\n        conn.commit()\n\n        print(f\"Applied migration: {migration_file.name}\")\n\n    except Exception as e:\n        conn.rollback()\n        print(f\"Failed to apply migration {migration_file.name}: {e}\")\n        sys.exit(1)\n    finally:\n        cursor.close()\n        conn.close()\n\ndef main():\n    db_url = os.environ['DATABASE_URL']\n    migrations_dir = Path('migrations')\n\n    # Get applied migrations\n    conn = psycopg2.connect(db_url)\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT filename FROM migrations\")\n    applied = {row[0] for row in cursor.fetchall()}\n    cursor.close()\n    conn.close()\n\n    # Apply pending migrations\n    for migration_file in sorted(migrations_dir.glob('*.sql')):\n        if migration_file.name not in applied:\n            run_migration(db_url, migration_file)\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"deployment/production/#cost-optimization","title":"Cost Optimization","text":""},{"location":"deployment/production/#resource-optimization","title":"Resource Optimization","text":""},{"location":"deployment/production/#auto-scaling-configuration_1","title":"Auto-scaling Configuration","text":"<pre><code># Kubernetes VPA (Vertical Pod Autoscaler)\napiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: ai-orchestrator-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: ai-orchestrator\n  updatePolicy:\n    updateMode: \"Auto\"\n  resourcePolicy:\n    containerPolicies:\n    - containerName: ai-orchestrator\n      maxAllowed:\n        cpu: 2000m\n        memory: 4Gi\n      minAllowed:\n        cpu: 100m\n        memory: 256Mi\n</code></pre>"},{"location":"deployment/production/#spot-instance-usage","title":"Spot Instance Usage","text":"<pre><code># AWS Auto Scaling Group with Spot Instances\nResources:\n  AutoScalingGroup:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    Properties:\n      MixedInstancesPolicy:\n        InstancesDistribution:\n          OnDemandPercentage: 20\n          SpotAllocationStrategy: diversified\n        LaunchTemplate:\n          LaunchTemplateSpecification:\n            LaunchTemplateId: !Ref LaunchTemplate\n            Version: !GetAtt LaunchTemplate.LatestVersionNumber\n          Overrides:\n            - InstanceType: c5.large\n            - InstanceType: c5.xlarge\n            - InstanceType: m5.large\n            - InstanceType: m5.xlarge\n</code></pre>"},{"location":"deployment/production/#cost-monitoring","title":"Cost Monitoring","text":"<pre><code># cost_monitor.py - Monitor and alert on costs\nimport boto3\nimport datetime\nfrom decimal import Decimal\n\ndef get_monthly_cost():\n    \"\"\"Get current month's AWS costs.\"\"\"\n    client = boto3.client('ce')\n\n    start = datetime.date.today().replace(day=1).strftime('%Y-%m-%d')\n    end = datetime.date.today().strftime('%Y-%m-%d')\n\n    response = client.get_cost_and_usage(\n        TimePeriod={\n            'Start': start,\n            'End': end\n        },\n        Granularity='MONTHLY',\n        Metrics=['BlendedCost'],\n        GroupBy=[\n            {\n                'Type': 'DIMENSION',\n                'Key': 'SERVICE'\n            }\n        ]\n    )\n\n    total_cost = Decimal('0')\n    for result in response['ResultsByTime']:\n        for group in result['Groups']:\n            amount = Decimal(group['Metrics']['BlendedCost']['Amount'])\n            total_cost += amount\n            service = group['Keys'][0]\n            print(f\"{service}: ${amount:.2f}\")\n\n    print(f\"Total monthly cost: ${total_cost:.2f}\")\n    return total_cost\n\ndef cost_alert(threshold=1000):\n    \"\"\"Send alert if cost exceeds threshold.\"\"\"\n    cost = get_monthly_cost()\n    if cost &gt; threshold:\n        # Send alert (email, Slack, etc.)\n        send_alert(f\"Monthly cost ${cost:.2f} exceeds threshold ${threshold}\")\n\nif __name__ == '__main__':\n    cost_alert()\n</code></pre> <p>This comprehensive production deployment guide covers all aspects of running the Freepik AI Orchestrator in a production environment, ensuring security, reliability, performance, and cost-effectiveness.</p>"},{"location":"development/architecture/","title":"Architecture Overview","text":"<p>Learn about the technical architecture and design principles behind the Freepik AI Orchestrator.</p>"},{"location":"development/architecture/#system-architecture","title":"System Architecture","text":"<p>The Freepik AI Orchestrator follows a modular, microservices-inspired architecture designed for scalability, maintainability, and extensibility.</p>"},{"location":"development/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    UI[Streamlit UI] --&gt; API[API Layer]\n    API --&gt; LLM[LLM Orchestrator]\n    API --&gt; FREEPIK[Freepik Client]\n    LLM --&gt; OPENAI[OpenAI/Anthropic]\n    FREEPIK --&gt; MODELS[AI Models]\n    API --&gt; DB[(Database)]\n    API --&gt; CACHE[(Redis Cache)]\n    API --&gt; QUEUE[Task Queue]\n    WEBHOOK[Webhook Handler] --&gt; API\n\n    subgraph \"AI Models\"\n        IMAGEN3[Imagen3]\n        MYSTIC[Mystic]\n        FLUX[Flux Dev]\n        CLASSIC[Classic Fast]\n    end\n\n    MODELS --&gt; IMAGEN3\n    MODELS --&gt; MYSTIC\n    MODELS --&gt; FLUX\n    MODELS --&gt; CLASSIC\n</code></pre>"},{"location":"development/architecture/#core-components","title":"Core Components","text":""},{"location":"development/architecture/#1-user-interface-layer","title":"1. User Interface Layer","text":"<p>Streamlit Frontend - Interactive web interface - Real-time updates and feedback - Responsive design - Custom CSS styling</p> <p>Key Features: - Image generation interface - Gallery management - Analytics dashboard - Settings and configuration</p>"},{"location":"development/architecture/#2-api-layer","title":"2. API Layer","text":"<p>FastAPI Backend - RESTful API endpoints - Async request handling - Input validation and sanitization - Rate limiting and authentication</p> <p>Endpoints: - <code>/generate</code> - Image generation - <code>/status/{task_id}</code> - Status checking - <code>/workflows</code> - Workflow management - <code>/analytics</code> - Usage analytics</p>"},{"location":"development/architecture/#3-llm-orchestrator","title":"3. LLM Orchestrator","text":"<p>Prompt Enhancement Engine - Multi-provider LLM support (OpenAI, Anthropic) - Intelligent prompt optimization - Context-aware enhancements - Model selection logic</p> <p>Features: - Prompt analysis and categorization - Technical detail injection - Style and quality optimization - Provider fallback mechanisms</p>"},{"location":"development/architecture/#4-freepik-integration","title":"4. Freepik Integration","text":"<p>API Client - Robust API communication - Error handling and retries - Webhook processing - Result caching</p> <p>Capabilities: - Multi-model support - Async generation handling - Progress tracking - Image downloading and storage</p>"},{"location":"development/architecture/#5-post-processing-pipeline","title":"5. Post-Processing Pipeline","text":"<p>Image Enhancement - AI-powered upscaling - Background manipulation - Lighting adjustments - Style transfers</p> <p>Processing Chain: - Input validation - Enhancement application - Quality optimization - Output formatting</p>"},{"location":"development/architecture/#6-data-layer","title":"6. Data Layer","text":"<p>Database (PostgreSQL/SQLite) - Generation history - User preferences - Analytics data - Workflow configurations</p> <p>Caching (Redis) - API response caching - Session state management - Temporary data storage - Rate limiting counters</p>"},{"location":"development/architecture/#design-principles","title":"Design Principles","text":""},{"location":"development/architecture/#1-modularity","title":"1. Modularity","text":"<p>Each component is designed as an independent module with clear interfaces:</p> <pre><code># Clear separation of concerns\nclass LLMOrchestrator:\n    \"\"\"Handles LLM interactions\"\"\"\n\nclass FreepikClient:\n    \"\"\"Manages Freepik API communication\"\"\"\n\nclass PostProcessor:\n    \"\"\"Handles image post-processing\"\"\"\n</code></pre>"},{"location":"development/architecture/#2-async-first-design","title":"2. Async-First Design","text":"<p>Built for high-concurrency scenarios:</p> <pre><code># Async operations throughout\nasync def generate_image(prompt: str) -&gt; dict:\n    enhanced_prompt = await llm_orchestrator.enhance_prompt(prompt)\n    result = await freepik_client.generate_async(enhanced_prompt)\n    return result\n</code></pre>"},{"location":"development/architecture/#3-configuration-management","title":"3. Configuration Management","text":"<p>Environment-based configuration with validation:</p> <pre><code>from pydantic import BaseSettings\n\nclass Settings(BaseSettings):\n    freepik_api_key: str\n    openai_api_key: Optional[str]\n    database_url: str = \"sqlite:///app.db\"\n\n    class Config:\n        env_file = \".env\"\n</code></pre>"},{"location":"development/architecture/#4-error-handling","title":"4. Error Handling","text":"<p>Comprehensive error handling with user-friendly messages:</p> <pre><code>class FreepikOrchestratorError(Exception):\n    \"\"\"Base exception with error codes\"\"\"\n\nclass APIError(FreepikOrchestratorError):\n    \"\"\"API-specific errors with retry logic\"\"\"\n</code></pre>"},{"location":"development/architecture/#5-observability","title":"5. Observability","text":"<p>Built-in logging, metrics, and monitoring:</p> <pre><code>import structlog\n\nlogger = structlog.get_logger()\n\n@metrics.timer(\"generation.duration\")\nasync def generate_image(prompt: str):\n    logger.info(\"Starting generation\", prompt=prompt)\n    # ... generation logic\n    logger.info(\"Generation completed\", task_id=task_id)\n</code></pre>"},{"location":"development/architecture/#data-flow","title":"Data Flow","text":""},{"location":"development/architecture/#1-image-generation-flow","title":"1. Image Generation Flow","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant UI as Streamlit UI\n    participant API as API Layer\n    participant LLM as LLM Orchestrator\n    participant FC as Freepik Client\n    participant FA as Freepik API\n    participant DB as Database\n\n    U-&gt;&gt;UI: Enter prompt\n    UI-&gt;&gt;API: POST /generate\n    API-&gt;&gt;LLM: enhance_prompt()\n    LLM-&gt;&gt;API: enhanced_prompt\n    API-&gt;&gt;FC: generate_image()\n    FC-&gt;&gt;FA: API request\n    FA-&gt;&gt;FC: task_id\n    FC-&gt;&gt;API: task_id\n    API-&gt;&gt;DB: save_generation()\n    API-&gt;&gt;UI: task_id\n    UI-&gt;&gt;U: Show progress\n\n    FA-&gt;&gt;FC: webhook callback\n    FC-&gt;&gt;API: update_status()\n    API-&gt;&gt;DB: update_generation()\n    API-&gt;&gt;UI: notify_completion()\n    UI-&gt;&gt;U: Show result\n</code></pre>"},{"location":"development/architecture/#2-data-storage-strategy","title":"2. Data Storage Strategy","text":"<p>Hot Data (Active Operations) - Redis cache for active tasks - Session state in memory - Real-time metrics</p> <p>Warm Data (Recent History) - PostgreSQL for recent generations - User preferences and settings - Analytics aggregates</p> <p>Cold Data (Archive) - Cloud storage for images - Long-term analytics data - Backup and compliance data</p>"},{"location":"development/architecture/#3-caching-strategy","title":"3. Caching Strategy","text":"<p>Multi-Level Caching</p> <pre><code># L1: Application cache\n@lru_cache(maxsize=100)\ndef get_prompt_template(category: str) -&gt; str:\n    return load_template(category)\n\n# L2: Redis cache\n@cache.memoize(timeout=3600)\ndef get_model_capabilities(model: str) -&gt; dict:\n    return fetch_model_info(model)\n\n# L3: CDN cache\n# Static assets and generated images\n</code></pre>"},{"location":"development/architecture/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"development/architecture/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Stateless Design - No server-side session storage - Shared state in Redis/Database - Load balancer friendly</p> <p>Container Architecture <pre><code># Multiple API instances\napi:\n  replicas: 3\n  resources:\n    limits:\n      cpu: \"1\"\n      memory: \"2Gi\"\n\n# Separate worker processes\nworker:\n  replicas: 5\n  resources:\n    limits:\n      cpu: \"500m\"\n      memory: \"1Gi\"\n</code></pre></p>"},{"location":"development/architecture/#vertical-scaling","title":"Vertical Scaling","text":"<p>Resource Optimization - Async I/O for API operations - Connection pooling for database - Memory-efficient image processing - CPU optimization for LLM operations</p>"},{"location":"development/architecture/#database-scaling","title":"Database Scaling","text":"<p>Read Replicas <pre><code># Read from replica for analytics\nanalytics_engine = create_engine(ANALYTICS_DB_URL)\n\n# Write to primary for operations\noperations_engine = create_engine(PRIMARY_DB_URL)\n</code></pre></p> <p>Partitioning Strategy <pre><code>-- Partition generations by date\nCREATE TABLE generations_2024_01 PARTITION OF generations\nFOR VALUES FROM ('2024-01-01') TO ('2024-02-01');\n</code></pre></p>"},{"location":"development/architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"development/architecture/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<p>API Key Management <pre><code>class APIKeyAuth:\n    async def authenticate(self, api_key: str) -&gt; User:\n        # Validate and return user context\n        pass\n</code></pre></p> <p>Role-Based Access Control <pre><code>class RBACMiddleware:\n    def check_permissions(self, user: User, resource: str, action: str) -&gt; bool:\n        return user.has_permission(resource, action)\n</code></pre></p>"},{"location":"development/architecture/#data-protection","title":"Data Protection","text":"<p>Encryption at Rest - Database encryption - File system encryption - Secrets management</p> <p>Encryption in Transit - TLS 1.3 for all communications - Certificate pinning - HSTS headers</p> <p>Input Validation <pre><code>from pydantic import BaseModel, validator\n\nclass GenerationRequest(BaseModel):\n    prompt: str\n    model: Optional[str]\n\n    @validator('prompt')\n    def validate_prompt(cls, v):\n        if len(v) &gt; 1000:\n            raise ValueError('Prompt too long')\n        return sanitize_input(v)\n</code></pre></p>"},{"location":"development/architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"development/architecture/#metrics-collection","title":"Metrics Collection","text":"<p>Application Metrics <pre><code>from prometheus_client import Counter, Histogram\n\ngeneration_counter = Counter('generations_total', 'Total generations')\ngeneration_duration = Histogram('generation_duration_seconds', 'Generation time')\n\n@generation_duration.time()\nasync def generate_image(prompt: str):\n    generation_counter.inc()\n    # ... generation logic\n</code></pre></p> <p>Business Metrics - Generation success rate - User engagement metrics - Cost per generation - Model performance metrics</p>"},{"location":"development/architecture/#logging-strategy","title":"Logging Strategy","text":"<p>Structured Logging <pre><code>import structlog\n\nlogger = structlog.configure(\n    processors=[\n        structlog.stdlib.add_log_level,\n        structlog.processors.JSONRenderer()\n    ]\n)\n\nlogger.info(\n    \"Generation started\",\n    user_id=user_id,\n    prompt_length=len(prompt),\n    model=model\n)\n</code></pre></p>"},{"location":"development/architecture/#health-checks","title":"Health Checks","text":"<p>Application Health <pre><code>@app.get(\"/health\")\nasync def health_check():\n    checks = {\n        \"database\": await check_database(),\n        \"redis\": await check_redis(),\n        \"freepik_api\": await check_freepik_api(),\n        \"llm_provider\": await check_llm_provider()\n    }\n\n    status = \"healthy\" if all(checks.values()) else \"unhealthy\"\n    return {\"status\": status, \"checks\": checks}\n</code></pre></p>"},{"location":"development/architecture/#development-architecture","title":"Development Architecture","text":""},{"location":"development/architecture/#code-organization","title":"Code Organization","text":"<pre><code>freepik-ai-orchestrator/\n\u251c\u2500\u2500 core/                    # Core business logic\n\u2502   \u251c\u2500\u2500 llm_orchestrator.py\n\u2502   \u251c\u2500\u2500 freepik_client.py\n\u2502   \u2514\u2500\u2500 post_processor.py\n\u251c\u2500\u2500 api/                     # API layer\n\u2502   \u251c\u2500\u2500 routes/\n\u2502   \u251c\u2500\u2500 middleware/\n\u2502   \u2514\u2500\u2500 dependencies.py\n\u251c\u2500\u2500 ui/                      # User interface\n\u2502   \u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 pages/\n\u2502   \u2514\u2500\u2500 styles/\n\u251c\u2500\u2500 database/                # Data layer\n\u2502   \u251c\u2500\u2500 models.py\n\u2502   \u251c\u2500\u2500 migrations/\n\u2502   \u2514\u2500\u2500 db.py\n\u251c\u2500\u2500 config/                  # Configuration\n\u2502   \u251c\u2500\u2500 settings.py\n\u2502   \u2514\u2500\u2500 logging.py\n\u251c\u2500\u2500 utils/                   # Utilities\n\u2502   \u251c\u2500\u2500 image_utils.py\n\u2502   \u2514\u2500\u2500 prompt_templates.py\n\u2514\u2500\u2500 tests/                   # Test suite\n    \u251c\u2500\u2500 unit/\n    \u251c\u2500\u2500 integration/\n    \u2514\u2500\u2500 e2e/\n</code></pre>"},{"location":"development/architecture/#testing-strategy","title":"Testing Strategy","text":"<p>Unit Tests <pre><code>def test_prompt_enhancement():\n    orchestrator = LLMOrchestrator()\n    result = orchestrator.enhance_prompt(\"cat\")\n    assert len(result) &gt; len(\"cat\")\n    assert \"cat\" in result.lower()\n</code></pre></p> <p>Integration Tests <pre><code>async def test_full_generation_flow():\n    async with TestClient() as client:\n        response = await client.post(\"/generate\", \n                                   json={\"prompt\": \"test\"})\n        assert response.status_code == 200\n        task_id = response.json()[\"task_id\"]\n\n        # Wait for completion\n        result = await wait_for_completion(task_id)\n        assert result[\"status\"] == \"completed\"\n</code></pre></p> <p>End-to-End Tests <pre><code>def test_ui_generation_flow():\n    with pytest_streamlit.run_app():\n        # Simulate user interaction\n        st.text_input(\"prompt\").send_keys(\"test prompt\")\n        st.button(\"Generate\").click()\n\n        # Verify UI updates\n        assert st.success.called\n</code></pre></p>"},{"location":"development/architecture/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>Build Process <pre><code># .github/workflows/build.yml\nname: Build and Test\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.11\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n      - name: Run tests\n        run: pytest tests/\n      - name: Build Docker image\n        run: docker build -t freepik-orchestrator .\n</code></pre></p> <p>Deployment Process - Automated testing on all branches - Staging deployment on develop branch - Production deployment on main branch - Rollback capabilities - Blue-green deployment strategy</p>"},{"location":"development/architecture/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"development/architecture/#database-optimization","title":"Database Optimization","text":"<p>Query Optimization <pre><code>-- Efficient pagination\nSELECT * FROM generations \nWHERE created_at &lt; ?\nORDER BY created_at DESC \nLIMIT 50;\n\n-- Proper indexing\nCREATE INDEX idx_user_created ON generations(user_id, created_at);\n</code></pre></p> <p>Connection Pooling <pre><code>from sqlalchemy.pool import QueuePool\n\nengine = create_engine(\n    DATABASE_URL,\n    poolclass=QueuePool,\n    pool_size=20,\n    max_overflow=30,\n    pool_timeout=30\n)\n</code></pre></p>"},{"location":"development/architecture/#async-processing","title":"Async Processing","text":"<p>Task Queue <pre><code>from celery import Celery\n\ncelery_app = Celery('freepik_orchestrator')\n\n@celery_app.task\nasync def process_generation(task_id: str):\n    # Background processing\n    pass\n</code></pre></p> <p>Batch Operations <pre><code>async def batch_generate(prompts: List[str]) -&gt; List[dict]:\n    tasks = [generate_image(prompt) for prompt in prompts]\n    results = await asyncio.gather(*tasks)\n    return results\n</code></pre></p>"},{"location":"development/architecture/#caching-optimization","title":"Caching Optimization","text":"<p>Smart Cache Invalidation <pre><code>from functools import wraps\n\ndef cache_with_invalidation(timeout=3600):\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            cache_key = f\"{func.__name__}:{hash(args)}\"\n            result = await redis.get(cache_key)\n\n            if result is None:\n                result = await func(*args, **kwargs)\n                await redis.setex(cache_key, timeout, result)\n\n            return result\n        return wrapper\n    return decorator\n</code></pre></p>"},{"location":"development/architecture/#future-architecture-considerations","title":"Future Architecture Considerations","text":""},{"location":"development/architecture/#microservices-migration","title":"Microservices Migration","text":"<p>Service Boundaries - User Management Service - Generation Service - Analytics Service - Notification Service</p> <p>Service Communication - REST APIs for synchronous communication - Message queues for async communication - Event sourcing for data consistency</p>"},{"location":"development/architecture/#event-driven-architecture","title":"Event-Driven Architecture","text":"<p>Event Bus <pre><code>class EventBus:\n    async def publish(self, event: Event):\n        # Publish to all subscribers\n        pass\n\n    async def subscribe(self, event_type: str, handler: Callable):\n        # Register event handler\n        pass\n</code></pre></p> <p>Domain Events <pre><code>@dataclass\nclass GenerationCompleted(Event):\n    task_id: str\n    user_id: str\n    image_url: str\n    model_used: str\n</code></pre></p> <p>This architecture provides a solid foundation for building a scalable, maintainable, and high-performance AI image generation platform. The modular design allows for easy extension and modification as requirements evolve.</p>"},{"location":"development/contributing/","title":"Contributing to Freepik AI Orchestrator","text":"<p>Thank you for your interest in contributing to the Freepik AI Orchestrator! This guide will help you get started with contributing to the project.</p>"},{"location":"development/contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Code of Conduct</li> <li>Getting Started</li> <li>Development Setup</li> <li>Contributing Guidelines</li> <li>Pull Request Process</li> <li>Issue Reporting</li> <li>Development Workflow</li> <li>Code Standards</li> <li>Testing</li> <li>Documentation</li> </ul>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to abide by our Code of Conduct:</p> <ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers and help them learn</li> <li>Focus on constructive feedback</li> <li>Respect different viewpoints and experiences</li> <li>Show empathy towards other community members</li> </ul>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher</li> <li>Node.js 16+ (for frontend development)</li> <li>Docker (optional, for containerized development)</li> <li>Git</li> </ul>"},{"location":"development/contributing/#fork-and-clone","title":"Fork and Clone","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally:</li> </ol> <pre><code>git clone https://github.com/your-username/freepik-ai-orchestrator.git\ncd freepik-ai-orchestrator\n</code></pre> <ol> <li>Add the upstream repository:</li> </ol> <pre><code>git remote add upstream https://github.com/freepik/freepik-ai-orchestrator.git\n</code></pre>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":""},{"location":"development/contributing/#local-development","title":"Local Development","text":"<ol> <li>Create a virtual environment:</li> </ol> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre> <ol> <li>Install dependencies:</li> </ol> <pre><code>pip install -r requirements.txt\npip install -r requirements-dev.txt\n</code></pre> <ol> <li>Set up environment variables:</li> </ol> <pre><code>cp .env.example .env\n# Edit .env with your configuration\n</code></pre> <ol> <li>Run the development server:</li> </ol> <pre><code>streamlit run app.py\n</code></pre>"},{"location":"development/contributing/#docker-development","title":"Docker Development","text":"<ol> <li>Build the development container:</li> </ol> <pre><code>docker-compose -f docker-compose.dev.yml build\n</code></pre> <ol> <li>Start the development environment:</li> </ol> <pre><code>docker-compose -f docker-compose.dev.yml up\n</code></pre>"},{"location":"development/contributing/#contributing-guidelines","title":"Contributing Guidelines","text":""},{"location":"development/contributing/#types-of-contributions","title":"Types of Contributions","text":"<p>We welcome various types of contributions:</p> <ul> <li>Bug fixes: Fix issues and improve stability</li> <li>Features: Add new functionality or enhance existing features</li> <li>Documentation: Improve docs, tutorials, and examples</li> <li>Tests: Add or improve test coverage</li> <li>Performance: Optimize code and improve efficiency</li> <li>Refactoring: Clean up code structure and organization</li> </ul>"},{"location":"development/contributing/#before-you-start","title":"Before You Start","text":"<ol> <li>Check existing issues and pull requests</li> <li>Create an issue to discuss major changes</li> <li>Ensure your idea aligns with project goals</li> <li>Follow the development workflow</li> </ol>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development/contributing/#1-create-a-branch","title":"1. Create a Branch","text":"<p>Create a feature branch from <code>main</code>:</p> <pre><code>git checkout main\ngit pull upstream main\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"development/contributing/#branch-naming-convention","title":"Branch Naming Convention","text":"<ul> <li><code>feature/description</code> - New features</li> <li><code>fix/description</code> - Bug fixes</li> <li><code>docs/description</code> - Documentation updates</li> <li><code>test/description</code> - Test improvements</li> <li><code>refactor/description</code> - Code refactoring</li> </ul>"},{"location":"development/contributing/#2-make-your-changes","title":"2. Make Your Changes","text":"<ul> <li>Write clean, readable code</li> <li>Follow existing code style</li> <li>Add tests for new functionality</li> <li>Update documentation as needed</li> <li>Keep commits focused and atomic</li> </ul>"},{"location":"development/contributing/#3-commit-guidelines","title":"3. Commit Guidelines","text":"<p>Write clear, descriptive commit messages:</p> <pre><code>git commit -m \"feat: add support for new AI model integration\n\n- Add MidJourney API integration\n- Update model selection interface\n- Add comprehensive error handling\n- Include unit tests for new functionality\"\n</code></pre> <p>Commit Message Format:</p> <pre><code>type(scope): brief description\n\nDetailed explanation of changes (optional)\n\n- Key change 1\n- Key change 2\n- Key change 3\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation - <code>test</code>: Tests - <code>refactor</code>: Code refactoring - <code>style</code>: Code style changes - <code>perf</code>: Performance improvements - <code>chore</code>: Maintenance tasks</p>"},{"location":"development/contributing/#4-test-your-changes","title":"4. Test Your Changes","text":"<p>Run the full test suite:</p> <pre><code># Unit tests\npython -m pytest tests/\n\n# Integration tests\npython -m pytest tests/integration/\n\n# Code quality checks\nflake8 .\nblack --check .\nmypy .\n\n# Frontend tests (if applicable)\nnpm test\n</code></pre>"},{"location":"development/contributing/#5-update-documentation","title":"5. Update Documentation","text":"<ul> <li>Update relevant documentation</li> <li>Add docstrings for new functions/classes</li> <li>Update API documentation if needed</li> <li>Add examples for new features</li> </ul>"},{"location":"development/contributing/#6-submit-pull-request","title":"6. Submit Pull Request","text":"<ol> <li>Push your branch:</li> </ol> <pre><code>git push origin feature/your-feature-name\n</code></pre> <ol> <li>Create a pull request on GitHub</li> <li>Fill out the PR template completely</li> <li>Link any related issues</li> <li>Request review from maintainers</li> </ol>"},{"location":"development/contributing/#pull-request-template","title":"Pull Request Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Documentation update\n- [ ] Code refactoring\n- [ ] Performance improvement\n\n## Testing\n- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n- [ ] New tests added\n\n## Documentation\n- [ ] Code comments updated\n- [ ] API documentation updated\n- [ ] User documentation updated\n- [ ] Changelog updated\n\n## Related Issues\nCloses #123\nRelated to #456\n</code></pre>"},{"location":"development/contributing/#issue-reporting","title":"Issue Reporting","text":""},{"location":"development/contributing/#bug-reports","title":"Bug Reports","text":"<p>Include the following information:</p> <ul> <li>Environment: OS, Python version, dependencies</li> <li>Steps to reproduce: Clear, step-by-step instructions</li> <li>Expected behavior: What should happen</li> <li>Actual behavior: What actually happens</li> <li>Screenshots: If applicable</li> <li>Logs: Relevant error messages or logs</li> </ul>"},{"location":"development/contributing/#feature-requests","title":"Feature Requests","text":"<p>Include the following information:</p> <ul> <li>Problem: What problem does this solve?</li> <li>Proposed solution: Detailed description</li> <li>Alternatives: Other solutions considered</li> <li>Use cases: How would this be used?</li> <li>Priority: How important is this feature?</li> </ul>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#setting-up-development-environment","title":"Setting Up Development Environment","text":"<ol> <li>Install pre-commit hooks:</li> </ol> <pre><code>pip install pre-commit\npre-commit install\n</code></pre> <ol> <li>Configure IDE settings:</li> <li>Enable auto-formatting with Black</li> <li>Set up linting with flake8</li> <li>Configure type checking with mypy</li> </ol>"},{"location":"development/contributing/#code-review-process","title":"Code Review Process","text":"<ol> <li>Self-review: Review your own code first</li> <li>Automated checks: Ensure CI passes</li> <li>Peer review: Address reviewer feedback</li> <li>Maintainer review: Final review by maintainers</li> <li>Merge: Approved PRs are merged</li> </ol>"},{"location":"development/contributing/#code-standards","title":"Code Standards","text":""},{"location":"development/contributing/#python-code-style","title":"Python Code Style","text":"<p>We follow PEP 8 with some modifications:</p> <ul> <li>Line length: 88 characters (Black default)</li> <li>Formatting: Use Black for consistent formatting</li> <li>Imports: Use isort for import organization</li> <li>Type hints: Use type hints for all functions</li> <li>Docstrings: Use Google-style docstrings</li> </ul>"},{"location":"development/contributing/#example-code-style","title":"Example Code Style","text":"<pre><code>from typing import Dict, List, Optional, Union\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass AIOrchestrator:\n    \"\"\"Main orchestrator for AI model management.\n\n    This class handles coordination between different AI models\n    and provides a unified interface for content generation.\n\n    Args:\n        config: Configuration dictionary\n        debug: Enable debug logging\n\n    Attributes:\n        models: Available AI models\n        analytics: Analytics tracker\n    \"\"\"\n\n    def __init__(\n        self, \n        config: Dict[str, str], \n        debug: bool = False\n    ) -&gt; None:\n        self.config = config\n        self.debug = debug\n        self.models: List[str] = []\n\n    def generate_content(\n        self, \n        prompt: str, \n        model: str,\n        **kwargs\n    ) -&gt; Optional[Dict[str, Union[str, float]]]:\n        \"\"\"Generate content using specified AI model.\n\n        Args:\n            prompt: Text prompt for generation\n            model: AI model to use\n            **kwargs: Additional model-specific parameters\n\n        Returns:\n            Generated content metadata or None if failed\n\n        Raises:\n            ModelNotFoundError: If model is not available\n            GenerationError: If generation fails\n        \"\"\"\n        try:\n            result = self._process_generation(prompt, model, **kwargs)\n            logger.info(f\"Generated content using {model}\")\n            return result\n        except Exception as e:\n            logger.error(f\"Generation failed: {e}\")\n            raise\n</code></pre>"},{"location":"development/contributing/#javascripttypescript-style","title":"JavaScript/TypeScript Style","text":"<ul> <li>Use TypeScript for type safety</li> <li>Follow Prettier formatting</li> <li>Use ESLint for code quality</li> <li>Prefer functional components</li> <li>Use modern ES6+ features</li> </ul>"},{"location":"development/contributing/#testing","title":"Testing","text":""},{"location":"development/contributing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/                 # Unit tests\n\u2502   \u251c\u2500\u2500 test_orchestrator.py\n\u2502   \u251c\u2500\u2500 test_models.py\n\u2502   \u2514\u2500\u2500 test_utils.py\n\u251c\u2500\u2500 integration/          # Integration tests\n\u2502   \u251c\u2500\u2500 test_api.py\n\u2502   \u2514\u2500\u2500 test_workflows.py\n\u251c\u2500\u2500 e2e/                 # End-to-end tests\n\u2502   \u2514\u2500\u2500 test_app.py\n\u2514\u2500\u2500 fixtures/            # Test data\n    \u251c\u2500\u2500 sample_responses.json\n    \u2514\u2500\u2500 test_images/\n</code></pre>"},{"location":"development/contributing/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom unittest.mock import Mock, patch\nfrom freepik_ai_orchestrator import AIOrchestrator\n\n\nclass TestAIOrchestrator:\n    \"\"\"Test cases for AIOrchestrator class.\"\"\"\n\n    @pytest.fixture\n    def orchestrator(self):\n        \"\"\"Create orchestrator instance for testing.\"\"\"\n        config = {\"api_key\": \"test-key\"}\n        return AIOrchestrator(config)\n\n    def test_generate_content_success(self, orchestrator):\n        \"\"\"Test successful content generation.\"\"\"\n        with patch('freepik_ai_orchestrator.models.DallE3') as mock_model:\n            mock_model.generate.return_value = {\"url\": \"test.jpg\"}\n\n            result = orchestrator.generate_content(\n                prompt=\"test prompt\",\n                model=\"dall-e-3\"\n            )\n\n            assert result is not None\n            assert \"url\" in result\n            mock_model.generate.assert_called_once()\n\n    def test_generate_content_invalid_model(self, orchestrator):\n        \"\"\"Test generation with invalid model.\"\"\"\n        with pytest.raises(ModelNotFoundError):\n            orchestrator.generate_content(\n                prompt=\"test prompt\",\n                model=\"invalid-model\"\n            )\n</code></pre>"},{"location":"development/contributing/#test-coverage","title":"Test Coverage","text":"<p>Maintain test coverage above 90%:</p> <pre><code># Generate coverage report\npython -m pytest --cov=freepik_ai_orchestrator --cov-report=html\n\n# View coverage\nopen htmlcov/index.html\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#code-documentation","title":"Code Documentation","text":"<ul> <li>Docstrings: All public functions and classes</li> <li>Type hints: All function parameters and returns</li> <li>Comments: Complex logic and algorithms</li> <li>Examples: Usage examples in docstrings</li> </ul>"},{"location":"development/contributing/#user-documentation","title":"User Documentation","text":"<ul> <li>API docs: Keep API reference up to date</li> <li>Tutorials: Add examples for new features</li> <li>Guides: Update deployment and usage guides</li> <li>Changelog: Document all changes</li> </ul>"},{"location":"development/contributing/#building-documentation","title":"Building Documentation","text":"<pre><code># Install MkDocs\npip install mkdocs mkdocs-material\n\n# Serve documentation locally\nmkdocs serve\n\n# Build documentation\nmkdocs build\n</code></pre>"},{"location":"development/contributing/#release-process","title":"Release Process","text":""},{"location":"development/contributing/#version-management","title":"Version Management","text":"<p>We use Semantic Versioning:</p> <ul> <li>MAJOR: Breaking changes</li> <li>MINOR: New features (backward compatible)</li> <li>PATCH: Bug fixes (backward compatible)</li> </ul>"},{"location":"development/contributing/#release-checklist","title":"Release Checklist","text":"<ul> <li> Update version numbers</li> <li> Update CHANGELOG.md</li> <li> Run full test suite</li> <li> Update documentation</li> <li> Create release tag</li> <li> Deploy to staging</li> <li> Deploy to production</li> </ul>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":""},{"location":"development/contributing/#resources","title":"Resources","text":"<ul> <li>Documentation: Full documentation</li> <li>API Reference: API docs</li> <li>Examples: Usage examples</li> <li>Troubleshooting: Common issues</li> </ul>"},{"location":"development/contributing/#community","title":"Community","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>Discussions: Ask questions and share ideas</li> <li>Discord: Real-time chat with community</li> <li>Stack Overflow: Tag questions with <code>freepik-ai-orchestrator</code></li> </ul>"},{"location":"development/contributing/#contact","title":"Contact","text":"<ul> <li>Maintainers: @maintainer1, @maintainer2</li> <li>Email: ai-orchestrator@freepik.com</li> <li>Security: security@freepik.com</li> </ul> <p>Thank you for contributing to Freepik AI Orchestrator! \ud83d\ude80</p>"},{"location":"development/testing/","title":"Testing Strategy and Guide","text":"<p>This document outlines the comprehensive testing strategy for the Freepik AI Orchestrator project, including test types, frameworks, and best practices.</p>"},{"location":"development/testing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Testing Philosophy</li> <li>Test Types</li> <li>Testing Framework</li> <li>Test Structure</li> <li>Writing Tests</li> <li>Running Tests</li> <li>Test Coverage</li> <li>Continuous Integration</li> <li>Performance Testing</li> <li>Security Testing</li> </ul>"},{"location":"development/testing/#testing-philosophy","title":"Testing Philosophy","text":"<p>Our testing approach follows these principles:</p> <ul> <li>Test-Driven Development (TDD): Write tests before implementation</li> <li>Comprehensive Coverage: Aim for 90%+ code coverage</li> <li>Fast Feedback: Tests should run quickly and provide immediate feedback</li> <li>Reliable: Tests should be deterministic and not flaky</li> <li>Maintainable: Tests should be easy to read and maintain</li> <li>Realistic: Use realistic test data and scenarios</li> </ul>"},{"location":"development/testing/#test-types","title":"Test Types","text":""},{"location":"development/testing/#1-unit-tests","title":"1. Unit Tests","text":"<p>Test individual components in isolation.</p> <p>Scope: - Individual functions and methods - Class behavior - Edge cases and error conditions - Business logic</p> <p>Example:</p> <pre><code>import pytest\nfrom unittest.mock import Mock, patch\nfrom freepik_ai_orchestrator.core import AIOrchestrator\nfrom freepik_ai_orchestrator.exceptions import ModelNotFoundError\n\n\nclass TestAIOrchestrator:\n    \"\"\"Unit tests for AIOrchestrator class.\"\"\"\n\n    @pytest.fixture\n    def mock_config(self):\n        \"\"\"Mock configuration for testing.\"\"\"\n        return {\n            \"openai_api_key\": \"test-key\",\n            \"default_model\": \"dall-e-3\",\n            \"timeout\": 30\n        }\n\n    @pytest.fixture\n    def orchestrator(self, mock_config):\n        \"\"\"Create orchestrator instance for testing.\"\"\"\n        return AIOrchestrator(mock_config)\n\n    def test_initialization(self, orchestrator, mock_config):\n        \"\"\"Test proper initialization of orchestrator.\"\"\"\n        assert orchestrator.config == mock_config\n        assert orchestrator.default_model == \"dall-e-3\"\n        assert len(orchestrator.available_models) &gt; 0\n\n    @patch('freepik_ai_orchestrator.models.dalle.OpenAI')\n    def test_generate_success(self, mock_openai, orchestrator):\n        \"\"\"Test successful content generation.\"\"\"\n        # Setup mock\n        mock_response = Mock()\n        mock_response.data = [Mock(url=\"https://example.com/image.jpg\")]\n        mock_openai.return_value.images.generate.return_value = mock_response\n\n        # Execute\n        result = orchestrator.generate(\n            prompt=\"A beautiful sunset\",\n            model=\"dall-e-3\"\n        )\n\n        # Assert\n        assert result is not None\n        assert \"image_url\" in result\n        assert result[\"image_url\"] == \"https://example.com/image.jpg\"\n        assert result[\"model\"] == \"dall-e-3\"\n\n    def test_generate_invalid_model(self, orchestrator):\n        \"\"\"Test generation with invalid model raises exception.\"\"\"\n        with pytest.raises(ModelNotFoundError) as exc_info:\n            orchestrator.generate(\n                prompt=\"Test prompt\",\n                model=\"invalid-model\"\n            )\n\n        assert \"invalid-model\" in str(exc_info.value)\n\n    @pytest.mark.parametrize(\"prompt,expected_length\", [\n        (\"Short prompt\", 50),\n        (\"A\" * 1000, 1000),\n        (\"\", 0)\n    ])\n    def test_prompt_validation(self, orchestrator, prompt, expected_length):\n        \"\"\"Test prompt validation with various inputs.\"\"\"\n        validated = orchestrator._validate_prompt(prompt)\n        assert len(validated) &lt;= 1000  # Max length check\n</code></pre>"},{"location":"development/testing/#2-integration-tests","title":"2. Integration Tests","text":"<p>Test component interactions and API endpoints.</p> <p>Scope: - API endpoint functionality - Database interactions - External service integration - Workflow testing</p> <p>Example:</p> <pre><code>import pytest\nimport requests\nfrom fastapi.testclient import TestClient\nfrom freepik_ai_orchestrator.api import app\nfrom freepik_ai_orchestrator.database import get_db\n\n\n@pytest.fixture\ndef client():\n    \"\"\"Create test client.\"\"\"\n    return TestClient(app)\n\n\n@pytest.fixture\ndef test_db():\n    \"\"\"Create test database session.\"\"\"\n    # Setup test database\n    yield test_session\n    # Cleanup\n\n\nclass TestGenerationAPI:\n    \"\"\"Integration tests for generation API.\"\"\"\n\n    def test_generate_endpoint_success(self, client):\n        \"\"\"Test successful generation through API.\"\"\"\n        response = client.post(\n            \"/api/v1/generate\",\n            json={\n                \"prompt\": \"A beautiful landscape\",\n                \"model\": \"dall-e-3\",\n                \"size\": \"1024x1024\"\n            },\n            headers={\"Authorization\": \"Bearer test-token\"}\n        )\n\n        assert response.status_code == 200\n        data = response.json()\n        assert \"id\" in data\n        assert \"image_url\" in data\n        assert data[\"model\"] == \"dall-e-3\"\n\n    def test_generate_endpoint_unauthorized(self, client):\n        \"\"\"Test generation without authentication.\"\"\"\n        response = client.post(\n            \"/api/v1/generate\",\n            json={\n                \"prompt\": \"Test prompt\",\n                \"model\": \"dall-e-3\"\n            }\n        )\n\n        assert response.status_code == 401\n\n    def test_generate_endpoint_validation_error(self, client):\n        \"\"\"Test generation with invalid input.\"\"\"\n        response = client.post(\n            \"/api/v1/generate\",\n            json={\n                \"prompt\": \"\",  # Empty prompt\n                \"model\": \"dall-e-3\"\n            },\n            headers={\"Authorization\": \"Bearer test-token\"}\n        )\n\n        assert response.status_code == 422\n        assert \"prompt\" in response.json()[\"detail\"][0][\"loc\"]\n\n\nclass TestWorkflowIntegration:\n    \"\"\"Test complete workflows.\"\"\"\n\n    def test_generate_and_store_workflow(self, client, test_db):\n        \"\"\"Test complete generation and storage workflow.\"\"\"\n        # Generate content\n        response = client.post(\n            \"/api/v1/generate\",\n            json={\n                \"prompt\": \"Test workflow\",\n                \"model\": \"dall-e-3\",\n                \"store_result\": True\n            },\n            headers={\"Authorization\": \"Bearer test-token\"}\n        )\n\n        assert response.status_code == 200\n        generation_id = response.json()[\"id\"]\n\n        # Verify storage\n        stored_response = client.get(\n            f\"/api/v1/generations/{generation_id}\",\n            headers={\"Authorization\": \"Bearer test-token\"}\n        )\n\n        assert stored_response.status_code == 200\n        assert stored_response.json()[\"id\"] == generation_id\n</code></pre>"},{"location":"development/testing/#3-end-to-end-tests","title":"3. End-to-End Tests","text":"<p>Test complete user workflows through the UI.</p> <p>Scope: - User interface functionality - Complete user journeys - Cross-browser compatibility - Performance under load</p> <p>Example:</p> <pre><code>import pytest\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\n\n@pytest.fixture\ndef driver():\n    \"\"\"Setup WebDriver for testing.\"\"\"\n    options = webdriver.ChromeOptions()\n    options.add_argument(\"--headless\")\n    driver = webdriver.Chrome(options=options)\n    yield driver\n    driver.quit()\n\n\nclass TestStreamlitApp:\n    \"\"\"End-to-end tests for Streamlit application.\"\"\"\n\n    def test_generate_image_workflow(self, driver):\n        \"\"\"Test complete image generation workflow.\"\"\"\n        # Navigate to app\n        driver.get(\"http://localhost:8501\")\n\n        # Wait for page load\n        wait = WebDriverWait(driver, 10)\n        prompt_input = wait.until(\n            EC.presence_of_element_located((By.CSS_SELECTOR, \"textarea\"))\n        )\n\n        # Enter prompt\n        prompt_input.send_keys(\"A beautiful sunset over mountains\")\n\n        # Select model\n        model_select = driver.find_element(By.CSS_SELECTOR, \"select\")\n        model_select.click()\n        model_option = driver.find_element(By.XPATH, \"//option[text()='DALL-E 3']\")\n        model_option.click()\n\n        # Generate image\n        generate_button = driver.find_element(By.XPATH, \"//button[text()='Generate']\")\n        generate_button.click()\n\n        # Wait for result\n        result_image = wait.until(\n            EC.presence_of_element_located((By.CSS_SELECTOR, \"img[src*='generated']\"))\n        )\n\n        assert result_image.is_displayed()\n\n    def test_analytics_dashboard(self, driver):\n        \"\"\"Test analytics dashboard functionality.\"\"\"\n        driver.get(\"http://localhost:8501\")\n\n        # Navigate to analytics\n        analytics_tab = driver.find_element(By.XPATH, \"//span[text()='Analytics']\")\n        analytics_tab.click()\n\n        # Verify charts are loaded\n        wait = WebDriverWait(driver, 10)\n        chart_element = wait.until(\n            EC.presence_of_element_located((By.CSS_SELECTOR, \".stPlotlyChart\"))\n        )\n\n        assert chart_element.is_displayed()\n</code></pre>"},{"location":"development/testing/#testing-framework","title":"Testing Framework","text":""},{"location":"development/testing/#primary-tools","title":"Primary Tools","text":"<ul> <li>pytest: Main testing framework</li> <li>pytest-cov: Coverage reporting</li> <li>pytest-mock: Mocking utilities</li> <li>pytest-asyncio: Async test support</li> <li>hypothesis: Property-based testing</li> <li>factory_boy: Test data factories</li> </ul>"},{"location":"development/testing/#installation","title":"Installation","text":"<pre><code>pip install pytest pytest-cov pytest-mock pytest-asyncio hypothesis factory_boy selenium\n</code></pre>"},{"location":"development/testing/#configuration","title":"Configuration","text":"<p>pytest.ini:</p> <pre><code>[tool:pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts = \n    --cov=freepik_ai_orchestrator\n    --cov-report=html\n    --cov-report=term-missing\n    --cov-fail-under=90\n    --strict-markers\n    --disable-warnings\nmarkers =\n    unit: Unit tests\n    integration: Integration tests\n    e2e: End-to-end tests\n    slow: Slow running tests\n    external: Tests requiring external services\n</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures and configuration\n\u251c\u2500\u2500 unit/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_orchestrator.py\n\u2502   \u251c\u2500\u2500 test_models/\n\u2502   \u2502   \u251c\u2500\u2500 test_dalle.py\n\u2502   \u2502   \u251c\u2500\u2500 test_midjourney.py\n\u2502   \u2502   \u2514\u2500\u2500 test_stable_diffusion.py\n\u2502   \u251c\u2500\u2500 test_utils/\n\u2502   \u2502   \u251c\u2500\u2500 test_image_processing.py\n\u2502   \u2502   \u2514\u2500\u2500 test_analytics.py\n\u2502   \u2514\u2500\u2500 test_api/\n\u2502       \u251c\u2500\u2500 test_auth.py\n\u2502       \u2514\u2500\u2500 test_endpoints.py\n\u251c\u2500\u2500 integration/             # Integration tests\n\u2502   \u251c\u2500\u2500 test_api_integration.py\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u2514\u2500\u2500 test_workflows.py\n\u251c\u2500\u2500 e2e/                     # End-to-end tests\n\u2502   \u251c\u2500\u2500 test_streamlit_app.py\n\u2502   \u2514\u2500\u2500 test_user_journeys.py\n\u251c\u2500\u2500 performance/             # Performance tests\n\u2502   \u251c\u2500\u2500 test_load.py\n\u2502   \u2514\u2500\u2500 test_stress.py\n\u251c\u2500\u2500 security/                # Security tests\n\u2502   \u251c\u2500\u2500 test_auth_security.py\n\u2502   \u2514\u2500\u2500 test_input_validation.py\n\u251c\u2500\u2500 fixtures/                # Test data and fixtures\n\u2502   \u251c\u2500\u2500 sample_images/\n\u2502   \u251c\u2500\u2500 mock_responses.json\n\u2502   \u2514\u2500\u2500 test_data.py\n\u2514\u2500\u2500 utils/                   # Test utilities\n    \u251c\u2500\u2500 factories.py\n    \u251c\u2500\u2500 helpers.py\n    \u2514\u2500\u2500 mocks.py\n</code></pre>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"development/testing/#test-fixtures","title":"Test Fixtures","text":"<p>conftest.py:</p> <pre><code>import pytest\nimport tempfile\nfrom unittest.mock import Mock\nfrom freepik_ai_orchestrator.core import AIOrchestrator\nfrom freepik_ai_orchestrator.database import Base, engine\n\n\n@pytest.fixture(scope=\"session\")\ndef test_config():\n    \"\"\"Test configuration.\"\"\"\n    return {\n        \"openai_api_key\": \"test-key\",\n        \"anthropic_api_key\": \"test-key\",\n        \"default_model\": \"dall-e-3\",\n        \"database_url\": \"sqlite:///test.db\",\n        \"redis_url\": \"redis://localhost:6379/1\"\n    }\n\n\n@pytest.fixture\ndef temp_directory():\n    \"\"\"Create temporary directory for test files.\"\"\"\n    with tempfile.TemporaryDirectory() as temp_dir:\n        yield temp_dir\n\n\n@pytest.fixture\ndef mock_openai_response():\n    \"\"\"Mock OpenAI API response.\"\"\"\n    mock_response = Mock()\n    mock_response.data = [\n        Mock(url=\"https://example.com/generated_image.jpg\")\n    ]\n    return mock_response\n\n\n@pytest.fixture(scope=\"function\")\ndef test_database():\n    \"\"\"Create test database.\"\"\"\n    Base.metadata.create_all(bind=engine)\n    yield\n    Base.metadata.drop_all(bind=engine)\n</code></pre>"},{"location":"development/testing/#data-factories","title":"Data Factories","text":"<p>tests/utils/factories.py:</p> <pre><code>import factory\nfrom factory import fuzzy\nfrom datetime import datetime\nfrom freepik_ai_orchestrator.models import Generation, User\n\n\nclass UserFactory(factory.Factory):\n    \"\"\"Factory for User model.\"\"\"\n\n    class Meta:\n        model = User\n\n    id = factory.Sequence(lambda n: f\"user_{n}\")\n    email = factory.LazyAttribute(lambda obj: f\"{obj.id}@example.com\")\n    api_key = factory.LazyFunction(lambda: f\"sk-{factory.Faker('uuid4')}\")\n    created_at = factory.LazyFunction(datetime.utcnow)\n    is_active = True\n\n\nclass GenerationFactory(factory.Factory):\n    \"\"\"Factory for Generation model.\"\"\"\n\n    class Meta:\n        model = Generation\n\n    id = factory.LazyFunction(lambda: factory.Faker('uuid4').generate())\n    prompt = factory.Faker('sentence', nb_words=10)\n    model = fuzzy.FuzzyChoice(['dall-e-3', 'midjourney', 'stable-diffusion'])\n    image_url = factory.LazyAttribute(\n        lambda obj: f\"https://example.com/{obj.id}.jpg\"\n    )\n    user = factory.SubFactory(UserFactory)\n    created_at = factory.LazyFunction(datetime.utcnow)\n    processing_time = fuzzy.FuzzyFloat(1.0, 30.0)\n    cost = fuzzy.FuzzyFloat(0.01, 1.0)\n</code></pre>"},{"location":"development/testing/#property-based-testing","title":"Property-Based Testing","text":"<pre><code>from hypothesis import given, strategies as st\nfrom freepik_ai_orchestrator.utils import validate_prompt\n\n\nclass TestPromptValidation:\n    \"\"\"Property-based tests for prompt validation.\"\"\"\n\n    @given(st.text(min_size=1, max_size=1000))\n    def test_validate_prompt_length(self, prompt):\n        \"\"\"Test prompt validation with various string lengths.\"\"\"\n        result = validate_prompt(prompt)\n        assert len(result) &lt;= 1000\n        assert isinstance(result, str)\n\n    @given(st.text().filter(lambda x: len(x.strip()) == 0))\n    def test_validate_empty_prompt(self, empty_prompt):\n        \"\"\"Test validation rejects empty prompts.\"\"\"\n        with pytest.raises(ValueError):\n            validate_prompt(empty_prompt)\n\n    @given(st.text(alphabet=st.characters(blacklist_categories=['Cc'])))\n    def test_validate_prompt_characters(self, prompt):\n        \"\"\"Test prompt validation handles various characters.\"\"\"\n        if len(prompt.strip()) &gt; 0:\n            result = validate_prompt(prompt)\n            assert result is not None\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#local-testing","title":"Local Testing","text":"<pre><code># Run all tests\npytest\n\n# Run specific test type\npytest tests/unit/\npytest tests/integration/\npytest tests/e2e/\n\n# Run with coverage\npytest --cov=freepik_ai_orchestrator\n\n# Run specific test file\npytest tests/unit/test_orchestrator.py\n\n# Run specific test method\npytest tests/unit/test_orchestrator.py::TestAIOrchestrator::test_generate_success\n\n# Run tests with specific markers\npytest -m \"unit\"\npytest -m \"not slow\"\npytest -m \"integration and not external\"\n\n# Run tests in parallel\npytest -n auto\n\n# Run tests with verbose output\npytest -v\n\n# Stop on first failure\npytest -x\n</code></pre>"},{"location":"development/testing/#test-environment-variables","title":"Test Environment Variables","text":"<pre><code># Set test environment\nexport TESTING=true\nexport TEST_DATABASE_URL=sqlite:///test.db\nexport TEST_REDIS_URL=redis://localhost:6379/1\n\n# Disable external API calls\nexport MOCK_EXTERNAL_APIS=true\n</code></pre>"},{"location":"development/testing/#test-coverage","title":"Test Coverage","text":""},{"location":"development/testing/#coverage-configuration","title":"Coverage Configuration","text":"<p>.coveragerc:</p> <pre><code>[run]\nsource = freepik_ai_orchestrator\nomit = \n    */tests/*\n    */venv/*\n    */migrations/*\n    setup.py\n    conftest.py\n\n[report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise AssertionError\n    raise NotImplementedError\n    if __name__ == .__main__.:\n    if TYPE_CHECKING:\n\n[html]\ndirectory = htmlcov\n</code></pre>"},{"location":"development/testing/#coverage-targets","title":"Coverage Targets","text":"<ul> <li>Overall: 90% minimum</li> <li>Critical modules: 95% minimum</li> <li>New code: 100% coverage required</li> </ul>"},{"location":"development/testing/#viewing-coverage","title":"Viewing Coverage","text":"<pre><code># Generate HTML coverage report\npytest --cov=freepik_ai_orchestrator --cov-report=html\n\n# Open coverage report\nopen htmlcov/index.html\n\n# Generate console report\npytest --cov=freepik_ai_orchestrator --cov-report=term-missing\n</code></pre>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#github-actions-configuration","title":"GitHub Actions Configuration","text":"<p>.github/workflows/test.yml:</p> <pre><code>name: Tests\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main, develop ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.9, 3.10, 3.11]\n\n    services:\n      redis:\n        image: redis:6\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 6379:6379\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v3\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-test.txt\n\n    - name: Lint with flake8\n      run: |\n        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88\n\n    - name: Type check with mypy\n      run: mypy freepik_ai_orchestrator/\n\n    - name: Test with pytest\n      run: |\n        pytest --cov=freepik_ai_orchestrator --cov-report=xml\n      env:\n        TESTING: true\n        REDIS_URL: redis://localhost:6379/1\n\n    - name: Upload coverage to Codecov\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n        fail_ci_if_error: true\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing/#load-testing","title":"Load Testing","text":"<pre><code>import pytest\nimport asyncio\nimport aiohttp\nfrom concurrent.futures import ThreadPoolExecutor\n\n\nclass TestPerformance:\n    \"\"\"Performance tests for API endpoints.\"\"\"\n\n    @pytest.mark.slow\n    def test_generation_performance(self):\n        \"\"\"Test generation endpoint performance under load.\"\"\"\n        import time\n\n        def make_request():\n            response = requests.post(\n                \"http://localhost:8000/api/v1/generate\",\n                json={\n                    \"prompt\": \"Performance test\",\n                    \"model\": \"dall-e-3\"\n                },\n                headers={\"Authorization\": \"Bearer test-token\"}\n            )\n            return response.elapsed.total_seconds()\n\n        # Measure response times\n        with ThreadPoolExecutor(max_workers=10) as executor:\n            futures = [executor.submit(make_request) for _ in range(100)]\n            times = [future.result() for future in futures]\n\n        # Assert performance criteria\n        avg_time = sum(times) / len(times)\n        max_time = max(times)\n\n        assert avg_time &lt; 5.0  # Average under 5 seconds\n        assert max_time &lt; 15.0  # Max under 15 seconds\n        assert sum(1 for t in times if t &lt; 2.0) / len(times) &gt; 0.8  # 80% under 2s\n\n    @pytest.mark.asyncio\n    async def test_concurrent_generations(self):\n        \"\"\"Test concurrent generation handling.\"\"\"\n        async def make_async_request(session):\n            async with session.post(\n                \"http://localhost:8000/api/v1/generate\",\n                json={\n                    \"prompt\": \"Concurrent test\",\n                    \"model\": \"dall-e-3\"\n                },\n                headers={\"Authorization\": \"Bearer test-token\"}\n            ) as response:\n                return await response.json()\n\n        async with aiohttp.ClientSession() as session:\n            tasks = [make_async_request(session) for _ in range(50)]\n            results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Verify all requests succeeded\n        successful = [r for r in results if not isinstance(r, Exception)]\n        assert len(successful) &gt;= 45  # At least 90% success rate\n</code></pre>"},{"location":"development/testing/#memory-and-resource-testing","title":"Memory and Resource Testing","text":"<pre><code>import psutil\nimport pytest\nfrom memory_profiler import profile\n\n\nclass TestResourceUsage:\n    \"\"\"Test memory and resource usage.\"\"\"\n\n    def test_memory_usage_generation(self):\n        \"\"\"Test memory usage during generation.\"\"\"\n        process = psutil.Process()\n        initial_memory = process.memory_info().rss\n\n        # Perform multiple generations\n        for i in range(10):\n            result = orchestrator.generate(\n                prompt=f\"Test generation {i}\",\n                model=\"dall-e-3\"\n            )\n\n        final_memory = process.memory_info().rss\n        memory_increase = final_memory - initial_memory\n\n        # Memory increase should be reasonable (under 100MB)\n        assert memory_increase &lt; 100 * 1024 * 1024\n\n    @profile\n    def test_memory_profile_generation(self):\n        \"\"\"Profile memory usage during generation.\"\"\"\n        # This will output memory usage line by line\n        result = orchestrator.generate(\n            prompt=\"Memory profile test\",\n            model=\"dall-e-3\"\n        )\n        return result\n</code></pre>"},{"location":"development/testing/#security-testing","title":"Security Testing","text":""},{"location":"development/testing/#input-validation-tests","title":"Input Validation Tests","text":"<pre><code>class TestSecurityValidation:\n    \"\"\"Security tests for input validation.\"\"\"\n\n    @pytest.mark.parametrize(\"malicious_input\", [\n        \"&lt;script&gt;alert('xss')&lt;/script&gt;\",\n        \"'; DROP TABLE users; --\",\n        \"{{config.__class__.__init__.__globals__}}\",\n        \"../../../etc/passwd\",\n        \"\\x00\\x01\\x02\\x03\"\n    ])\n    def test_malicious_input_rejection(self, client, malicious_input):\n        \"\"\"Test rejection of malicious inputs.\"\"\"\n        response = client.post(\n            \"/api/v1/generate\",\n            json={\n                \"prompt\": malicious_input,\n                \"model\": \"dall-e-3\"\n            },\n            headers={\"Authorization\": \"Bearer test-token\"}\n        )\n\n        # Should either reject with 422 or sanitize the input\n        if response.status_code == 200:\n            # If accepted, verify input was sanitized\n            result = response.json()\n            assert malicious_input not in str(result)\n        else:\n            assert response.status_code == 422\n\n    def test_authentication_required(self, client):\n        \"\"\"Test that authentication is required.\"\"\"\n        response = client.post(\n            \"/api/v1/generate\",\n            json={\n                \"prompt\": \"Test prompt\",\n                \"model\": \"dall-e-3\"\n            }\n        )\n\n        assert response.status_code == 401\n\n    def test_rate_limiting(self, client):\n        \"\"\"Test rate limiting protection.\"\"\"\n        # Make many requests quickly\n        responses = []\n        for i in range(100):\n            response = client.post(\n                \"/api/v1/generate\",\n                json={\n                    \"prompt\": f\"Rate limit test {i}\",\n                    \"model\": \"dall-e-3\"\n                },\n                headers={\"Authorization\": \"Bearer test-token\"}\n            )\n            responses.append(response)\n\n        # Should see some rate limiting responses\n        rate_limited = [r for r in responses if r.status_code == 429]\n        assert len(rate_limited) &gt; 0\n</code></pre>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":""},{"location":"development/testing/#1-test-organization","title":"1. Test Organization","text":"<ul> <li>Group related tests in classes</li> <li>Use descriptive test names</li> <li>Follow AAA pattern (Arrange, Act, Assert)</li> <li>Keep tests independent and isolated</li> </ul>"},{"location":"development/testing/#2-mock-external-dependencies","title":"2. Mock External Dependencies","text":"<pre><code>@patch('freepik_ai_orchestrator.external.openai_client')\ndef test_with_mocked_openai(mock_client):\n    \"\"\"Test with mocked external dependency.\"\"\"\n    mock_client.generate.return_value = {\"url\": \"test.jpg\"}\n    # Test implementation\n</code></pre>"},{"location":"development/testing/#3-use-parameterized-tests","title":"3. Use Parameterized Tests","text":"<pre><code>@pytest.mark.parametrize(\"model,expected_provider\", [\n    (\"dall-e-3\", \"openai\"),\n    (\"midjourney\", \"midjourney\"),\n    (\"stable-diffusion\", \"stability\")\n])\ndef test_model_providers(model, expected_provider):\n    \"\"\"Test model provider mapping.\"\"\"\n    provider = get_provider_for_model(model)\n    assert provider == expected_provider\n</code></pre>"},{"location":"development/testing/#4-test-edge-cases","title":"4. Test Edge Cases","text":"<ul> <li>Empty inputs</li> <li>Maximum/minimum values</li> <li>Invalid data types</li> <li>Network failures</li> <li>Timeouts</li> </ul>"},{"location":"development/testing/#5-performance-considerations","title":"5. Performance Considerations","text":"<ul> <li>Mark slow tests appropriately</li> <li>Use fixtures for expensive setup</li> <li>Clean up resources properly</li> <li>Consider parallel test execution</li> </ul>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#running-specific-tests","title":"Running Specific Tests","text":"<pre><code># Run failed tests only\npytest --lf\n\n# Run tests with debugging\npytest --pdb\n\n# Run with extra verbose output\npytest -vvv\n\n# Disable capturing for debugging\npytest -s\n</code></pre>"},{"location":"development/testing/#test-debugging-tools","title":"Test Debugging Tools","text":"<pre><code># Use pytest debugging\ndef test_debug_example():\n    import pdb; pdb.set_trace()  # Debugger breakpoint\n    # Test code here\n\n# Use logging in tests\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\ndef test_with_logging():\n    logger = logging.getLogger(__name__)\n    logger.debug(\"Debug information\")\n    # Test code here\n</code></pre> <p>This comprehensive testing strategy ensures high-quality, reliable software with good coverage and proper validation of all functionality.</p>"}]}